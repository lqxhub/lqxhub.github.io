[{"content":"前段时间，使用C++协程+liburing实现了一个简单的 echo server，文章地址。\n都说使用 uring 可以获得更好的性能，但是究竟能提升多少呢？接下来，我们来对比一下 liburing 和 epoll 的性能。\n测试方式 在原来的 echo server 基础上改动了一下，把 echo server 改成了一个简单的 HTTP server，返回一个固定的 HTML 内容。\n然后使用 go-stress-testing 这个工具进行压力测试。\n测试工具在windows 10 上。HTTP 服务运行这个windows 10 的 VM虚拟机上。系统是 debian13，linux内核是 6.12.41-amd64\n编译器使用 clang-18 编译参数 -O2 stdlib=libc++ -std=c++23 进行编译。\nuring 服务和 epoll 服务都是单线程模型，单线程处理所有连接。\n测试代码 这里就不贴所有代码了，主要贴一下关键部分。\nuring 版本 1Task\u0026lt;false\u0026gt; IoUring::startSession(int fd, uint64_t connId) { 2 std::string buffer; 3 buffer.resize(1024); 4 bool closed = false; 5 while (!closed) { 6 auto aRead = AwaitableRead(this, fd, buffer); 7 while (true) { 8 int res = co_await aRead; 9 if (res \u0026lt;= 0) { // 连接关闭或者读取错误 10 closed = true; 11 break; 12 } 13 if (res == 1) { // 读完了 14 break; 15 } 16 } 17 if (closed) { 18 break; 19 } 20 21 // std::cout \u0026lt;\u0026lt; \u0026#34;Received data: \u0026#34;; 22 23 std::string response; 24 std::string body = 25 \u0026#34;\u0026lt;!DOCTYPE html\u0026gt;\u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;Test Page\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt;\u0026lt;body\u0026gt;\u0026#34; 26 \u0026#34;\u0026lt;p\u0026gt;Hello, this is a test HTML content for HTTP response.\u0026lt;/p\u0026gt;\u0026#34; 27 \u0026#34;\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026#34;; 28 response.reserve(128 + body.size()); // 减少拷贝 29 30 response += \u0026#34;HTTP/1.1 200 OK\\r\\n\u0026#34; 31 \u0026#34;Content-Length: \u0026#34; + 32 std::to_string(body.size()) + 33 \u0026#34;\\r\\n\u0026#34; 34 \u0026#34;Content-Type: text/html; charset=UTF-8\\r\\n\u0026#34; 35 \u0026#34;Connection: close\\r\\n\u0026#34; 36 \u0026#34;Date: Mon, 21 Oct 2024 13:24:24 GMT\\r\\n\\r\\n\u0026#34;; 37 response += body; 38 39 auto aWrite = AwaitableWrite(this, fd, std::move(std::string(response))); 40 while (true) { 41 int res = co_await aWrite; 42 if (res \u0026lt; 0) { // 写出错了 43 closed = true; 44 break; 45 } 46 if (res == 0) { // 写完了 47 break; 48 } 49 } 50 } 51 close(fd); 52 co_return; 53} 在原来的 echo server 基础上，改成了 HTTP server。然后使用协程处理每个连接。\nepoll 版本 1void Epoll::run() 2{ 3 std::cout \u0026lt;\u0026lt; \u0026#34;Epoll::run\u0026#34; \u0026lt;\u0026lt; std::endl; 4 epoll_event events[EVENT_SIZE]; 5 while (true) 6 { 7 int nfds = epoll_wait(ePollFd_, events, EVENT_SIZE, -1); 8 if (nfds \u0026lt; 0) 9 { 10 std::cerr \u0026lt;\u0026lt; \u0026#34;epoll_wait failed nfds:\u0026#34; \u0026lt;\u0026lt; nfds \u0026lt;\u0026lt; \u0026#34;errno:\u0026#34; \u0026lt;\u0026lt; errno \u0026lt;\u0026lt; std::endl; 11 break; 12 } 13 if (errno == EINTR) 14 { 15 // 系统调用被中断，继续重试 16 continue; 17 } 18 for (int i = 0; i \u0026lt; nfds; ++i) 19 { 20 if (events[i].events \u0026amp; EPOLLERR || events[i].events \u0026amp; EPOLLHUP) 21 { 22 std::cout \u0026lt;\u0026lt; \u0026#34;epoll_wait failed errno:\u0026#34; \u0026lt;\u0026lt; errno \u0026lt;\u0026lt; std::endl; 23 delFd(events[i].data.fd); 24 close(events[i].data.fd); 25 continue; 26 } 27 if (events[i].events \u0026amp; EPOLLIN) 28 { 29 if (events[i].data.fd == listenFd_) 30 { 31 sockaddr_in cliAddr{}; 32 socklen_t length = sizeof(cliAddr); 33 int clientFd = accept4(listenFd_, reinterpret_cast\u0026lt;sockaddr*\u0026gt;(\u0026amp;cliAddr), \u0026amp;length, 34 0); 35 if (clientFd \u0026lt; 0) 36 { 37 std::cerr \u0026lt;\u0026lt; \u0026#34;accept failed fd:\u0026#34; \u0026lt;\u0026lt; clientFd \u0026lt;\u0026lt; \u0026#34;errno:\u0026#34; \u0026lt;\u0026lt; errno \u0026lt;\u0026lt; std::endl; 38 continue; 39 } 40 std::cout \u0026lt;\u0026lt; \u0026#34;new client fd\u0026#34; \u0026lt;\u0026lt; clientFd \u0026lt;\u0026lt; std::endl; 41 addRead(clientFd); 42 } 43 else 44 { 45 char buff[1024]; 46 int n = ::read(events[i].data.fd, buff, sizeof(buff)); 47 if (n \u0026lt;= 0) 48 { 49 std::cout \u0026lt;\u0026lt; \u0026#34;close fd:\u0026#34; \u0026lt;\u0026lt; events[i].data.fd \u0026lt;\u0026lt; std::endl; 50 delFd(events[i].data.fd); 51 close(events[i].data.fd); 52 continue; 53 } 54 std::string response; 55 response.reserve(128 + image.size()); // 减少拷贝 56 response += \u0026#34;HTTP/1.1 200 OK\\r\\n\u0026#34; 57 \u0026#34;Content-Length: \u0026#34; + std::to_string(image.size()) + \u0026#34;\\r\\n\u0026#34; 58 \u0026#34;Content-Type: image/jpeg\\r\\n\u0026#34; 59 \u0026#34;Connection: close\\r\\n\u0026#34; 60 \u0026#34;Date: Mon, 21 Oct 2024 13:24:24 GMT\\r\\n\\r\\n\u0026#34;; 61 response += image; 62 write(events[i].data.fd, response.data(), response.size()); 63 } 64 } 65 } 66 } 67} epoll 版本没有使用协程，直接在事件循环中处理所有连接。两个HTTP server 处理逻辑是一样的，都是读取请求，然后返回一个固定的 HTML 内容。\n测试结果 本次测试 io_uring使用 中断模式\n中断模式也是 io_uring 的默认模式，关于 io_uring 的两种模式，中断模式 轮询模式 和 内核轮询模式 的区别， 先挖个坑，后续再写一篇文章进行介绍。\n这个HTTP server 返回一个简单的 HTML 内容：\n1\u0026lt;!DOCTYPE html\u0026gt;\u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;Test Page\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt;\u0026lt;body\u0026gt; 2 \u0026lt;p\u0026gt;Hello, this is a test HTML content for HTTP response.\u0026lt;/p\u0026gt; 3\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt; 使用 go-stress-testing 进行压力测试，测试命令如下：\n开启 100 个并发连接，每个连接发送 100 次请求。\n1go-stress-testing-win.exe -u \u0026#34;http://192.168.1.19:8088\u0026#34; -c 100 -n 100 uring 版本测试结果\n可以看到 QPS 达到了 4800+，平均响应时间 20ms。\nepoll 版本测试结果\n可以看到 QPS 只有 4000+，平均响应时间 23ms。\nuring 版本的性能比 epoll 版本提升了 20% 左右。\n测试2 上面的测试中，HTML返回了一个简单的网页，现在改成返回一个148KB 的图片，为了防止网络成为瓶颈，这次并发数改成 50，连接数改成 50。\n在进程启动的时候，把图片读到内存中，避免每次都读磁盘，然后每次请求都返回这个图片。\n这个改动比较小，只一下 response 的内容：\n1 response.reserve(128 + image.size()); // 减少拷贝 2 3 response += \u0026#34;HTTP/1.1 200 OK\\r\\n\u0026#34; 4 \u0026#34;Content-Length: \u0026#34; + 5 std::to_string(image.size()) + 6 \u0026#34;\\r\\n\u0026#34; 7 \u0026#34;Content-Type: image/jpeg\\r\\n\u0026#34; 8 \u0026#34;Connection: close\\r\\n\u0026#34; 9 \u0026#34;Date: Mon, 21 Oct 2024 13:24:24 GMT\\r\\n\\r\\n\u0026#34;; 10 response += image; 使用 go-stress-testing 进行压力测试，测试命令如下：\n1go-stress-testing-win.exe -u \u0026#34;http://192.168.1.19:8088\u0026#34; -c 50 -n 50 开启 50 个并发连接，每个连接发送 50 次请求。\nuring 版本测试结果\n可以看到 QPS 达到了 1300+，平均响应时间 37ms。\nepoll 版本测试结果\n可以看到 QPS 只有 520+，平均响应时间 93ms。\n可以看到，uring 版本的性能是 epoll 版本的 2.5 倍左右。这个提升还是非常明显的。\n总结 通过上面的测试，可以看到 liburing 相比 epoll 在高并发场景下，不管是 QPS 还是 响应耗时，性能提升还是比较明显的。\n具体来说，uring 版本在处理小文件时的 QPS 比 epoll 版本高出 20% 左右，而在处理大文件时的 QPS 则高出 2.5 倍左右。这些测试结果表明，liburing 在高并发场景下具有更好的性能表现，尤其是在读取和写入大的数据时，优势更加明显。这还是提前从文件中读取到内存中，避免了磁盘 I/O 的影响。如果是每次都从磁盘读取，使用 liburing 异步读取和普通的 read 函数读取对比，性能差距可能会更大。 这也是因为 liburing 能够更高效地利用内核的异步 I/O 能力，减少了系统调用的开销，从而提升了整体的吞吐量和响应速度。\n","date":"2025-09-13T19:04:48+08:00","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/1ca5f47363ab61f726ef725e58827790e00be3f7.jpg","permalink":"https://lqxhub.github.io/posts/6da4ad2d/","title":"使用C++协程+liburing的HTTP server 和 epoll 的 HTTP server 性能对比"},{"content":"先聊一下什么是SSH隧道转发吧，隧道转发也被称作是SSH 端口转发，是一种通过SSH协议将本地端口转发到远程主机的技术。它可以实现安全的网络连接，常用于穿越防火墙或访问内网服务。\nSSH隧道转发的工作原理是，在SSH连接建立后，通过SSH协议将本地端口的流量加密后转发到远程主机的指定端口。这样，用户就可以通过本地端口访问远程主机的服务，而不必直接暴露远程主机的端口。最常见的应用场景是在本地连接云服务的数据库，或者访问公司内网的资源。一般云MySQL数据库都是不开放公网的，只能在内网中访问，为了在公网能访问这些资源，就需要使用SSH隧道转发。\n在 Navicat 中连接MySQL 数据库时，可以通过SSH隧道转发来连接没有公网IP的数据库，连接配置如下图\n为什么要用go实现一个SSH 隧道转发代理呢？主要是我们公司的很多redis实例都在云上，无法直接在公网中访问。通过SSH隧道转发，可以实现在公网中访问这些云上的redis实例。为什么不用现成的工具呢？\n首先 redis-cli 工具不支持SSH隧道转发，要解决问题，有两种选择\n选择一些GUI的redis客户端工具，但是这些工具往往需要额外的配置，使用起来不够方便。所以考虑自己写一个简单的命令行工具来实现这个功能。 直接使用SSH命令进行端口转发，然后再使用redis-cli连接本地端口。这种方式比较简单，但需要手动管理SSH连接 使用这两个方案还有一个问题，要对所有人公开SSH机器的账号密码，存在安全隐患。\n所以自己实现一个简单的 支持 SSH 隧道转发的 redis-cli 工具是一个不错的选择，正好可以借这个机会学习一下相关的技术。这个工具要有以下功能：\n支持通过SSH隧道连接到远程Redis实例 对使用者透明SSH连接的建立和断开 支持配置文件，或者直接把SSH相关的信息编译在代码中 大概的原理如图：\ntun redis-cli 是要通过SSH隧道连接到远程Redis实例的工具。 SSH server 是我们用来建立SSH连接的中间服务器。 redis server 是我们要访问的远程Redis实例。\ntun redis-cli 通过 SSH 先连接到 具有公网IP的 SSH server 上，然后再通过 SSH 隧道连接到 redis server。\n下面开始撸代码，实现这个工具\nSSH 隧道转发 先来实现最核心的功能，SSH 隧道转发。我们需要使用 Go 的 golang.org/x/crypto/ssh 包来实现 SSH 连接和端口转发。\n1package main 2 3import ( 4\t\u0026#34;errors\u0026#34; 5\t\u0026#34;fmt\u0026#34; 6\t\u0026#34;golang.org/x/crypto/ssh\u0026#34; 7\t\u0026#34;os\u0026#34; 8) 9 10type SSHConfig struct { 11\tSSHHost string //SSH服务器地址 12\tSSHUser string //SSH用户名 13\tSSHPassword string //SSH密码 14\tSSHKey string //秘钥文件路径 15} 16 17func GetSSHClient(config *SSHConfig) (*ssh.Client, error) { 18\tif config.SSHHost == \u0026#34;\u0026#34; { 19\treturn nil, errors.New(\u0026#34;SSHHost must be provided\u0026#34;) 20\t} 21\tif config.SSHUser == \u0026#34;\u0026#34; { 22\treturn nil, errors.New(\u0026#34;SSHUser must be provided\u0026#34;) 23\t} 24\tif config.SSHKey == \u0026#34;\u0026#34; \u0026amp;\u0026amp; config.SSHPassword == \u0026#34;\u0026#34; { 25\treturn nil, errors.New(\u0026#34;SSHKey or SSHPassword must be provided\u0026#34;) 26\t} 27 28\tsshConfig := \u0026amp;ssh.ClientConfig{ 29\tUser: config.SSHUser, 30\tHostKeyCallback: ssh.InsecureIgnoreHostKey(), 31\t} 32 33\tif config.SSHPassword != \u0026#34;\u0026#34; { 34\tsshConfig.Auth = []ssh.AuthMethod{ssh.Password(config.SSHPassword)} 35\t} else { 36\tif config.SSHKey != \u0026#34;\u0026#34; { 37\tkeyContent, err := os.ReadFile(config.SSHKey) 38\tif err != nil { 39\treturn nil, fmt.Errorf(\u0026#34;failed to read SSH key file:%s: error:%w\u0026#34;, config.SSHKey, err) 40\t} 41\tsigner, err := ssh.ParsePrivateKey(keyContent) 42\tif err != nil { 43\treturn nil, fmt.Errorf(\u0026#34;failed to parse SSH key: %w\u0026#34;, err) 44\t} 45\tsshConfig.Auth = append(sshConfig.Auth, ssh.PublicKeys(signer)) 46\t} 47\t} 48 49\tsshConfig.HostKeyCallback = ssh.InsecureIgnoreHostKey() 50 51\tclient, err := ssh.Dial(\u0026#34;tcp\u0026#34;, config.SSHHost, sshConfig) 52\tif err != nil { 53\treturn nil, err 54\t} 55\treturn client, nil 56} 上面的代码定义了一个 SSHConfig 结构体来存储 SSH 连接的配置信息，包括 SSH 服务器地址、用户名、密码和秘钥文件路径。GetSSHClient 函数根据这些配置信息创建并返回一个 SSH 客户端。\nssh有多种身份验证方式，包括密码验证和公钥验证。在本例中，我们支持这两种方式。用户可以通过设置 SSHPassword 或 SSHKey 字段来选择身份验证方式。如果同时设置了这两个字段，程序将优先使用密码验证。\n现在已经创建好了一个SSH的客户端，可以用来进行后续的操作，建立 redis 连接。\n1type RedisClient struct { 2\tconn net.Conn 3\twriteBuff *bytes.Buffer 4\tread *bufio.Reader 5\toutPut *bytes.Buffer 6} 7 8// GetRedisClient 创建一个 RedisClient 实例 9// address 是 Redis 服务器的地址, IP:port 格式 10func GetRedisClient(sshClient *ssh.Client, address string) (*RedisClient, error) { 11\tif sshClient == nil { 12\treturn nil, errors.New(\u0026#34;SSH client is nil\u0026#34;) 13\t} 14\tremoteConn, err := sshClient.Dial(\u0026#34;tcp\u0026#34;, address) 15\tif err != nil { 16\treturn nil, fmt.Errorf(\u0026#34;failed to connect to Redis server at %s: %w\u0026#34;, address, err) 17\t} 18\tredisCli := \u0026amp;RedisClient{ 19\tconn: remoteConn, 20\twriteBuff: bytes.NewBuffer(make([]byte, 0, 1024)), 21\tread: bufio.NewReaderSize(remoteConn, 4096), 22\toutPut: bytes.NewBuffer(make([]byte, 0, 4096)), 23\t} 24\treturn redisCli, nil 25} 通过SSH客户端的 Dial 方法，可以连接到内网的 Redis 服务器。GetRedisClient 函数接受一个 SSH 客户端和 Redis 服务器地址，返回一个 RedisClient 实例。RedisClient 结构体封装了与 Redis 服务器的连接，并提供了读写操作的缓冲区。\n到这，基本实现了 SSH 隧道转发的功能，可以访问内网的redis服务了。但是还缺少redis协议解析功能。\nredis 协议解析 redis 协议简称 RESP，是 Redis 使用的通信协议。RESP 协议简单高效，易于解析。 RESP协议现在有 RESP2 和 RESP3 两个版本。现在常用的还是 RESP2。\nRESP2 协议有五种数据类型：\n简单字符串：以 + 开头，直到 \\r\\n 结束。 错误：以 - 开头，直到 \\r\\n 结束。 整数：以 : 开头，直到 \\r\\n 结束。 数组：以 * 开头，后接数组长度，直到 \\r\\n 结束。数组中的每个元素都是一个 RESP 类型。 二进制安全字符串：以 $ 开头，后接字符串长度，直到 \\r\\n 结束。 下面就自己实现一个简单的 RESP 协议解析器。\n1func (r *RedisClient) Read() error { 2\tb, err := r.read.ReadBytes(\u0026#39;\\n\u0026#39;) 3\tif err != nil { 4\treturn fmt.Errorf(\u0026#34;failed to read from Redis connection: %w\u0026#34;, err) 5\t} 6\tif len(b) \u0026lt;= 2 || b[len(b)-2] != \u0026#39;\\r\u0026#39; || b[len(b)-1] != \u0026#39;\\n\u0026#39; { 7\treturn errors.New(\u0026#34;invalid Redis response format\u0026#34;) 8\t} 9\tbf := b[0] 10\tb = b[1 : len(b)-2] // Remove the trailing \\r\\n 11\tswitch bf { 12\tcase \u0026#39;+\u0026#39;: 13\t// Simple string reply 14\tr.outPut.Write(b) 15\tcase \u0026#39;-\u0026#39;: 16\t// Error reply 17\tr.outPut.WriteString(\u0026#34;(error) ERR \u0026#34;) 18\tr.outPut.Write(b) 19\tcase \u0026#39;:\u0026#39;: 20\t// Integer reply 21\tr.outPut.WriteString(\u0026#34;(integer) \u0026#34;) 22\tr.outPut.Write(b) 23\tcase \u0026#39;$\u0026#39;: 24\tl, err := strconv.Atoi(string(b)) 25\tif err != nil { 26\treturn fmt.Errorf(\u0026#34;failed to parse bulk string length: %w\u0026#34;, err) 27\t} 28\tif l == -1 { 29\tr.outPut.WriteString(\u0026#34;(nil)\u0026#34;) 30\treturn nil 31\t} 32\trl := l + 2 // +2 for \\r\\n 33\tbulkData := make([]byte, rl) 34\trl = 0 35\tfor rl \u0026lt; l { 36\tn, err := r.read.Read(bulkData[rl:]) 37\tif err != nil { 38\treturn fmt.Errorf(\u0026#34;failed to read bulk string data: %w\u0026#34;, err) 39\t} 40\trl += n 41\tif rl \u0026gt;= l { 42\tbreak 43\t} 44\t} 45\tr.outPut.Write(bulkData[:l]) // Write only the bulk string data 46 47\tcase \u0026#39;*\u0026#39;: 48\tl, err := strconv.Atoi(string(b)) 49\tif err != nil { 50\treturn fmt.Errorf(\u0026#34;failed to parse array length: %w\u0026#34;, err) 51\t} 52\tif l == -1 { 53\tr.outPut.WriteString(\u0026#34;(nil)\u0026#34;) 54\treturn nil 55\t} 56\tr.outPut.WriteString(\u0026#34;(array)\\n\u0026#34;) 57\tif l == 0 { 58\tr.outPut.WriteString(\u0026#34;[]\u0026#34;) 59\treturn nil 60\t} 61\tfor i := 0; i \u0026lt; l; i++ { 62\tif err = r.Read(); err != nil { 63\treturn err 64\t} 65\tif i \u0026lt; l-1 { 66\tr.outPut.WriteByte(\u0026#39;\\n\u0026#39;) 67\t} 68\t} 69\tdefault: 70\treturn fmt.Errorf(\u0026#34;unknown Redis response type: %c\u0026#34;, bf) 71\t} 72\treturn nil 73} 74 75//把用户输入的命令写入 Redis 76func (r *RedisClient) Write(str string) error { 77\tsplit := strings.Split(str, \u0026#34; \u0026#34;) 78\tr.writeBuff.Reset() 79\tfor i, s := range split { 80\tr.writeBuff.WriteString(s) 81\tif i \u0026lt; len(split)-1 { 82\tr.writeBuff.WriteByte(\u0026#39; \u0026#39;) 83\t} 84\t} 85\tr.writeBuff.WriteString(\u0026#34;\\r\\n\u0026#34;) 86 87\t_, err := r.conn.Write(r.writeBuff.Bytes()) 88\treturn err 89} 90 91//输出 Redis 响应结果 92func (r *RedisClient) Print() { 93\tfmt.Printf(\u0026#34;%s\\n\u0026#34;, r.outPut.String()) 94\tr.outPut.Reset() 95} 把redis协议的解析功能集成到 RedisClient 结构体中。Read 方法读取并解析 Redis 服务器的响应，Write 方法将用户输入的命令发送到 Redis 服务器，Print 方法输出解析后的结果。在解析数据时，把需要实现的内容同步写入到 outPut 中。\n命令行的输入数据因目前不会涉及到复杂的命令，一般就是查询指定key的内容，所以可以直接用 RESP 的 inline 命令格式，比如 SET key value，GET key，HGETALL key 等等。\n整合 基本功能模块完成后，就可以把这些功能组合起来，然后测试了\n1package main 2 3import ( 4\t\u0026#34;bufio\u0026#34; 5\t\u0026#34;flag\u0026#34; 6\t\u0026#34;fmt\u0026#34; 7\t\u0026#34;io\u0026#34; 8\t\u0026#34;os\u0026#34; 9\t\u0026#34;strings\u0026#34; 10) 11 12var sshHost = flag.String(\u0026#34;sshHost\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;SSH server address\u0026#34;) 13var sshUser = flag.String(\u0026#34;sshUser\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;SSH username\u0026#34;) 14var sshPassword = flag.String(\u0026#34;sshPassword\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;SSH password\u0026#34;) 15var sshKey = flag.String(\u0026#34;sshKey\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;Path to SSH private key file path\u0026#34;) 16 17var redisHost = flag.String(\u0026#34;h\u0026#34;, \u0026#34;127.0.0.1\u0026#34;, \u0026#34;Redis server address\u0026#34;) 18var redisPort = flag.Int(\u0026#34;p\u0026#34;, 6379, \u0026#34;Redis server port\u0026#34;) 19 20func main() { 21\tflag.Parse() 22\tif *redisHost == \u0026#34;\u0026#34; || *redisPort == 0 { 23\tfmt.Println(\u0026#34;Redis server address and port must be provided\u0026#34;) 24\tos.Exit(1) 25\t} 26\tsshConfig := GetSSHConfig() 27 28\tsshClient, err := GetSSHClient(sshConfig) 29\tif err != nil { 30\tfmt.Printf(\u0026#34;Failed to create SSH client: %v\\n\u0026#34;, err) 31\tos.Exit(1) 32\t} 33\tfmt.Printf(\u0026#34;Connecting to SSH server at %s\\r\u0026#34;, *sshHost) 34\tdefer sshClient.Close() 35 36\tredisClient, err := GetRedisClient(sshClient, fmt.Sprintf(\u0026#34;%s:%d\u0026#34;, *redisHost, *redisPort)) 37\tif err != nil { 38\tfmt.Printf(\u0026#34;Failed to connect to Redis server: %v\\n\u0026#34;, err) 39\tos.Exit(1) 40\t} 41\tdefer redisClient.Close() 42 43\tfmt.Printf(\u0026#34;Connected to Redis server at %s:%d via SSH\\r\u0026#34;, *redisHost, *redisPort) 44 45\tfmt.Printf(\u0026#34;input \u0026#39;exit\u0026#39; or \u0026#39;quit\u0026#39; to exiting process!!!\\n\u0026#34;) 46 47\t//从标准输入读取数据 48\treader := bufio.NewReader(os.Stdin) 49\tfor { 50\tline, err := reader.ReadString(\u0026#39;\\n\u0026#39;) 51\tif err != nil { 52\tif err == io.EOF { 53\tfmt.Println(\u0026#34;Exiting...\u0026#34;) 54\tbreak 55\t} 56\t_, _ = fmt.Fprintf(os.Stderr, \u0026#34;读取错误: %v\\n\u0026#34;, err) 57\t} 58\tline = strings.TrimSpace(line) 59\tif line == \u0026#34;\u0026#34; { 60\tcontinue // Skip empty lines 61\t} 62\tif line == \u0026#34;exit\u0026#34; || line == \u0026#34;quit\u0026#34; { 63\tfmt.Println(\u0026#34;Exiting...\u0026#34;) 64\tbreak 65\t} 66\t//处理输入的命令 67\tif err = redisClient.Write(line); err != nil { 68\t_, _ = fmt.Fprintf(os.Stderr, \u0026#34;写入错误: %v\\n\u0026#34;, err) 69\tcontinue 70\t} 71\tredisClient.outPut.Reset() 72\tif err = redisClient.Read(); err != nil { 73\t_, _ = fmt.Fprintf(os.Stderr, \u0026#34;读取错误: %v\\n\u0026#34;, err) 74\tcontinue 75\t} 76 77\tredisClient.Print() 78\t} 79} 80 81func GetSSHConfig() *SSHConfig { 82\tsshConfig := \u0026amp;SSHConfig{ 83\tSSHHost: *sshHost, 84\tSSHUser: *sshUser, 85\tSSHPassword: *sshPassword, 86\tSSHKey: *sshKey, 87\t} 88\treturn sshConfig 89} 通过命令行获取相关的参数，循环读取用户输入的命令并处理，最终将redis返回的数据输出到标准输出。\n到这，一个简单的 SSH 隧道转发的 redis-cli 工具就完成了。\n最后附上 go.mod 文件的内容：\n1module tun_redis_cli 2 3go 1.23.1 4 5require ( 6\tgolang.org/x/crypto v0.41.0 // indirect 7\tgolang.org/x/sys v0.35.0 // indirect 8) ","date":"2025-09-07T15:48:48+08:00","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/a44968f29f6744f2fe0b1d4b640fd6e70776356e.jpg","permalink":"https://lqxhub.github.io/posts/61c8dafe/","title":"用go实现一个支持SSH隧道转发 (SSH port forwarding) 的 redis-cli 工具"},{"content":"前两天写了一篇 C++协程 + io_uring 的 文章 ，里面介绍了如何在 C++ 中结合使用协程和 io_uring 来实现异步 I/O 操作。写完自己在审阅时，回想起来自己刚接触 linux 网络编程时走过的一些弯路，一些错误的理解。所有就想着写一篇 I/O 的文章总结一下。 所以今天我们就来聊聊常见的IO类型，同步 I/O ，异步 I/O ，阻塞 I/O ，非阻塞 I/O 还有 IO 多路复用。\n一开始我错误的认为，非阻塞 I/O 就是异步 I/O ，阻塞 I/O 就是同步 I/O 。后来才发现，原来并不是这样的。IO 的分类有两个维度，一个是按调用方式分为：同步 和 异步；另一个是按等待方式分为：阻塞 和 非阻塞。\n简单说 阻塞/非阻塞 是指 函数调用时的返回行为 ，而 同步/异步 是指 I/O的完成通知 。 而 I/O多路复用 则是一种特殊的技术，是提升效率的一种机制，它允许单个线程同时管理多个 I/O 操作。通过使用 select、poll 或 epoll 等系统调用，应用程序可以在多个文件描述符上等待事件的发生，从而实现高效的 I/O 处理。I/O多路复用通常与非阻塞 I/O 结合使用，以提高性能和响应能力。\n模型 应用行为 等待位置 优缺点 同步 I/O 等待完成 应用自己阻塞 简单，但效率低 异步 I/O 发起请求立刻返回，完成后通知 内核异步完成 最理想，但实现复杂 阻塞 I/O 调用阻塞直到数据就绪 应用阻塞 编程简单，但浪费等待时间 非阻塞 I/O 数据没好立即返回，需要轮询 应用层轮询 避免阻塞，但效率差 I/O 多路复用 统一等待多个 I/O 就绪 内核等待，应用一次醒来处理 高效，常用于高并发服务器 下面用 C 为每种 I/O 类型写一个简单的例子，来帮助理解。\n在linux中，一切都是文件，包括网络连接和设备。通过文件描述符，应用程序可以以统一的方式进行I/O操作，所以有些例子中，使用 open、read 和 close 等系统调用来进行文件的读取操作。对于网络 I/O，应用程序可以使用相同的接口来进行数据的发送和接收。\n阻塞I/O 1#include \u0026lt;stdio.h\u0026gt; 2#include \u0026lt;stdlib.h\u0026gt; 3#include \u0026lt;unistd.h\u0026gt; 4#include \u0026lt;fcntl.h\u0026gt; 5 6int main() { 7 char buffer[1024]; 8 int fd = open(\u0026#34;file.txt\u0026#34;, O_RDONLY); 9 if (fd == -1) { 10 perror(\u0026#34;open\u0026#34;); 11 return 1; 12 } 13 ssize_t bytesRead = read(fd, buffer, sizeof(buffer)); 14 if (bytesRead == -1) { 15 perror(\u0026#34;read\u0026#34;); 16 close(fd); 17 return 1; 18 } 19 printf(\u0026#34;Read %zd bytes: %.*s\\n\u0026#34;, bytesRead, (int)bytesRead, buffer); 20 close(fd); 21 return 0; 22} read 函数 操作默认的 文件描述符 (fd) 是阻塞的，也就是说，如果没有数据可读，它会一直等待，直到有数据可读为止。这种方式在某些情况下是合适的，但在高并发的网络应用中，可能会导致性能瓶颈。 优势就是这种阻塞方式编程简单，容易理解。\n非阻塞I/O 1#include \u0026lt;stdio.h\u0026gt; 2#include \u0026lt;unistd.h\u0026gt; 3#include \u0026lt;fcntl.h\u0026gt; 4#include \u0026lt;errno.h\u0026gt; 5#include \u0026lt;string.h\u0026gt; 6 7int main() { 8 char buf[100]; 9 int flags = fcntl(STDIN_FILENO, F_GETFL, 0); 10 fcntl(STDIN_FILENO, F_SETFL, flags | O_NONBLOCK); // 设置非阻塞 11 12 printf(\u0026#34;非阻塞输入（没有输入时立即返回）：\\n\u0026#34;); 13 while (1) { 14 ssize_t n = read(STDIN_FILENO, buf, sizeof(buf)-1); 15 if (n \u0026gt; 0) { 16 buf[n] = \u0026#39;\\0\u0026#39;; 17 printf(\u0026#34;你输入了：%s\\n\u0026#34;, buf); 18 break; 19 } else if (n \u0026lt; 0 \u0026amp;\u0026amp; errno == EAGAIN) { 20 printf(\u0026#34;暂时没有输入，干点别的事...\\n\u0026#34;); 21 sleep(1); 22 } else { 23 break; 24 } 25 } 26 return 0; 27} 这次使用 标准输入（STDIN_FILENO）进行非阻塞读取。\n使用 fcntl 函数设置文件描述符的标志位为非阻塞。 后续使用 read 函数操作 这个文件描述符时，就会变成 非阻塞I/O 了。 在没有数据可读时会立即返回，而不是阻塞等待。使用非阻塞I/O 编程时，需要判断 errno 的值来判断当前 fd 的状态。\n常见的错误码有：\nEAGAIN：表示当前没有数据可读，非阻塞I/O模式下会立即返回。 EINTR：表示系统调用被信号中断，可能需要重试。 EINVAL：表示无效的文件描述符或参数。 ENETDOWN：表示网络关闭。 EIO：表示 I/O 错误。 ETIMEDOUT：表示操作超时。 在网络编程中，可以使用 accept4 函数来创建非阻塞的 socket。\n函数定义\n1int accept4(int sockfd, struct sockaddr *addr,socklen_t *addrlen, int flags); sockfd：监听socket fd（必须是 listen 状态）。 addr：返回对端地址（客户端 IP + 端口）。如果不关心，可以传 NULL。 addrlen：输入输出参数，传入时为 addr 的大小，返回时表示实际长度。 flags：额外选项，可以是以下的 按位或： SOCK_NONBLOCK 设置新 socket 为非阻塞模式。 SOCK_CLOEXEC 设置 FD_CLOEXEC（执行 exec 时自动关闭 fd）。 调用方式\n1struct sockaddr_in cliaddr; 2socklen_t clilen = sizeof(cliaddr); 3int fd = accept4(listenfd,(struct sockaddr*)\u0026amp;cliaddr,\u0026amp;clilen, SOCK_NONBLOCK | SOCK_CLOEXEC); 使用非阻塞I/O 可以避免应用程序在等待 I/O 操作完成时被阻塞，从而提高整体的响应能力和并发处理能力。\n一般来说，非阻塞I/O 适用于对响应时间要求较高的场景，比如网络服务、实时数据处理等。而阻塞I/O 则更适合对性能要求不高的场景，比如简单的文件读取等。\n非阻塞I/O 需要搭配 多路复用技术一起使用，才能发挥出更好的性能。通过使用 select、poll 或 epoll 等系统调用，应用程序可以在多个文件描述符上等待事件的发生，从而实现高效的 I/O 处理，关于多路复用，后面会介绍\n同步 I/O 在 POSIX 语义里，阻塞 I/O 本质就是同步 I/O。还有上面提到的非阻塞 I/O，虽然它的返回行为是非阻塞的，但在数据准备好之前，应用程序仍然需要主动去查询状态，这种行为在某种程度上也可以视为一种同步。\n所以就不再重复这些内容了。\n异步 I/O 所谓的 异步 I/O ，是指应用程序发起 I/O 请求后，不需要等待操作完成，而是可以继续执行其他任务。当 I/O 操作完成后，内核会通过某种机制（如信号、回调函数或事件通知）来通知应用程序。\n在 Linux 5.1 版本中，引入了新的异步 I/O 接口（io_uring），它提供了一种更高效的方式来进行异步 I/O 操作。通过 io_uring，应用程序可以将 I/O 请求提交到内核，并在请求完成时获得通知，从而实现真正的异步 I/O。\n举一个简单的例子，我去麦当劳点餐。\n同步 I/O： 我走到柜台前，告诉服务员我要点什么，然后站在那里等着，直到小姐姐把我的餐给我为止。在这个过程中我只能在柜台前等待，我不能做其他事情，只能等待。\n异步 I/O： 我走到柜台前，告诉服务员我要点什么，然后就去找地方坐着玩手机了，甚至可以去上个厕所。当餐点准备好后，小姐姐会通过某种方式通知我取餐，比如喊一声XXX号餐好了。\n回到程序中，同步 I/O 应用程序发起 I/O 请求后，必须等待内核完成操作才能继续执行后续代码。而异步 I/O 则允许应用程序在发起请求后立即返回，继续执行其他任务，内核会在操作完成后通过回调或信号的方式通知应用程序。\n异步 I/O 的代码比较多，就不在这里展示了，可以去 io_uring 和 C++协程+io_uring 查看相关内容。\n多路复用 乍一听这个名字还挺高大上的，其实它的核心思想就是让一个线程同时管理多个 I/O 操作，从而提高效率。最早的网络编程中，通常是为每个连接创建一个线程，这样虽然简单，但在高并发场景下会导致线程数量激增，系统资源耗尽。所有有了 C10K 连接的问题。\n很多程序就是使用这种每个线程处理一个连接的方式，像是 Apache HTTP Server，MySQL 社区版（听说付费版使用了多路复用）等。\n为了解决这个问题，出现了 I/O 多路复用技术。它允许一个线程同时监视多个 I/O 流，并在其中任何一个流准备好时进行处理。常见的 I/O 多路复用机制有 select、poll、 epoll 和 kqueue。\nselect select 是 最常见的一种 多路复用技术，几乎所有的操作系统都支持。\n1#include \u0026lt;stdio.h\u0026gt; 2#include \u0026lt;unistd.h\u0026gt; 3#include \u0026lt;sys/select.h\u0026gt; 4#include \u0026lt;string.h\u0026gt; 5 6int main() { 7 char buf[100]; 8 fd_set rfds; 9 10 printf(\u0026#34;多路复用等待输入 (5秒超时)：\\n\u0026#34;); 11 FD_ZERO(\u0026amp;rfds); 12 FD_SET(STDIN_FILENO, \u0026amp;rfds); 13 14 struct timeval tv = {5, 0}; // 5秒超时 15 int ret = select(STDIN_FILENO+1, \u0026amp;rfds, NULL, NULL, \u0026amp;tv); 16 if (ret \u0026gt; 0 \u0026amp;\u0026amp; FD_ISSET(STDIN_FILENO, \u0026amp;rfds)) { 17 ssize_t n = read(STDIN_FILENO, buf, sizeof(buf)-1); 18 buf[n] = \u0026#39;\\0\u0026#39;; 19 printf(\u0026#34;你输入了：%s\\n\u0026#34;, buf); 20 } else if (ret == 0) { 21 printf(\u0026#34;5秒内没有输入，超时！\\n\u0026#34;); 22 } else { 23 perror(\u0026#34;select 出错\u0026#34;); 24 } 25 return 0; 26} select 也有不足之处，比如：\n性能问题：select 在每次调用时都需要把被监控的fds集合从用户态空间拷贝到内核态空间，这在文件描述符数量较多时会导致性能下降。 文件描述符数量限制：select 对文件描述符的数量有限制（通常是 1024），这在大量连接的场景下可能成为瓶颈。 返回的文件描述符集合需要遍历：select 返回后，应用程序需要遍历整个文件描述符集合来检查哪些文件描述符准备好了，这在文件描述符数量较多时效率较低。 poll 后来为了解决 select 的一些不足之处，出现了 poll。poll 的使用方式与 select 类似，但它不再使用固定大小的文件描述符集合，而是使用一个数组来表示所有待监视的文件描述符。这使得 poll 可以支持更多的文件描述符。但是，poll 仍然需要在每次调用时遍历整个数组，性能上仍然不够理想。\nepoll epoll 是 Linux 2.6 开始支持的一种多路复用技术，它克服了 select 和 poll 的一些缺点。epoll 使用事件通知机制，可以在文件描述符状态发生变化时立即通知应用程序，而不需要轮询。这使得 epoll 在处理大量并发连接时具有更好的性能。\n缺点就是带来了更高的复杂性，使用起来相对较为复杂。\nepoll server 和 epoll 惊群问题 这两篇文章详细介绍了 epoll 的使用和注意事项。\nkqueue kqueue 是 BSD 系统特有的一种多路复用技术，它与 epoll 类似，使用事件通知机制来提高性能。kqueue 可以监视文件描述符、信号、定时器等多种事件，并在事件发生时通知应用程序。\nkqueue 是 BSD 系统特有的技术，无法在 Linux 上使用。我平时主要在 Linux 上进行开发，所以就不在这里贴代码了。想要了解可以去看 redis 的源码，里面有使用 kqueue 的例子。\nredis kqueue 源码\n我之前为 kiwi 数据库写过一套跨平台的网络库，里面也有 kqueue 的实现。 kqueue\n不同多路复用区别 特性 select poll epoll kqueue fd 上限 1024 (FD_SETSIZE) 无固定上限 无固定上限 无固定上限 fd 集合管理 位图，每次重置 数组，每次重置 内核维护红黑树 内核维护 返回结果 遍历所有 fd 遍历所有 fd 直接返回活跃 fd 直接返回活跃 fd 时间复杂度 O(n) O(n) O(活跃 fd) O(活跃 fd) 触发方式 水平触发 水平触发 水平 + 边缘触发 水平 + 边缘触发 epoll，kqueue 比 select，poll 更加高效的原因。\n事件驱动机制：epoll 和 kqueue 都是基于事件驱动的模型，内核会在事件发生时通知应用程序，而且只关注那些已经就绪的fd即可，而不是像 select 和 poll 每次都需要遍历所有 fd 避免频繁的数据拷贝：每次调用 select 或 poll 时，都需要将整个 fd 集合从用户态复制到内核态，调用结束后再将结果从内核态复制回用户态。这种频繁的数据拷贝在高并发场景下会带来较大的性能开销。epoll 和 kqueue 使用了内存映射，内核态和用户态可以访问同一块物理内存，避免了这种频繁的数据拷贝，提升了性能。 支持大规模并发：epoll 和 kqueue 都可以支持大量的并发连接，而 select 和 poll 在文件描述符数量较多时会出现性能瓶颈。 更灵活的触发方式：epoll 和 kqueue 支持水平触发和边缘触发，应用程序可以根据需要选择合适的触发方式，从而提高性能。 再来聊一下 水平触发（LT） 和 边缘触发（ET） 的区别。\n水平触发（LT）：当文件描述符的状态发生变化时，内核会通知应用程序。应用程序需要在每次调用时检查文件描述符的状态，如果状态仍然就绪，则会重复接收通知。这种方式简单易用，但在高并发场景下可能导致大量重复通知，浪费 CPU 资源。\n边缘触发（ET）：只有当文件描述符的状态发生变化时，内核才会通知应用程序。应用程序在接收到通知后，需要立即读取所有可用数据，直到返回 EAGAIN 错误。这种方式可以减少重复通知，提高性能，但实现起来相对复杂。\n总结 以上就是对阻塞 I/O、非阻塞 I/O、同步 I/O、异步 I/O 和多路复用等概念的介绍。通过对比不同 I/O 模型的优缺点和适用场景，可以在实际开发中选择合适的 I/O 模型，以提高应用程序的性能和响应能力。\n没有万能的解决方案，只有最合适的选择，目前我了解到的，完全用异步 I/O 的服务端还是比较少，比较常用的还是 非阻塞 I/O+多路复用技术。\n以上都是用 C/C++ 编程时，自己手写的I/O操作示例。因为 C++ STL 没有提供网络库，IO库，所以需要手动实现这些功能。\n如果是使用 golang 这些新的语言，很多I/O操作都被封装好了，直接调用就行了。根本不用关心底层的实现细节。\n但是这些底层的知识多了解一点还是有用处的。\n","date":"2025-08-24T15:09:50+08:00","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/6d6b0bc8be14ed7f83dc3fc00e09b7e1490f76d1.jpg","permalink":"https://lqxhub.github.io/posts/fad3c120/","title":"一文讲清楚所有IO，同步IO，异步IO，阻塞IO，非阻塞IO，IO多路复用，网络编程"},{"content":"前两天刚写了一篇文章，怎样在C++中使用协程 传送门。那个只是一个简单的例子，今天我们来聊聊如何将协程与 io_uring 结合起来使用，实现真正的异步 I/O 操作。 我个人觉得，C++协程最好的使用场景就是配合异步 I/O。\n以前也写过一篇关于 io_uring 的文章 传送门，里面介绍了 io_uring 的基本概念和使用方法。今天我们就基于那个例子，来实现一个简单的 echo 服务器，使用协程来处理客户端的连接和数据收发。\n简单画一个图，每一个 Awaitable 都是一个协程，在一个进程中，每一个连接都有两个协程（一个用于读，一个用于写）。还有一个特殊的协程 AwaitableAccept 用来处理接受连接的操作。 同一时刻，最多只能有一个协程在执行。其他的协程会被挂起，等待当前协程完成后再恢复执行。\n因为协程可以让我们以同步的方式编写异步代码，避免传统的“回调函数地狱”，从而提高代码的可读性和可维护性。而 io_uring 则是 Linux 提供的一种高性能异步 I/O 接口，可以与协程结合使用，进一步提升性能。\n因为代码量有点大，就不全贴在这里了，已经上传到GitHub上，可以去这里查看 传送门。\n不废话了，直接上代码\ncoroutine handle 1#ifndef TASK_H 2#define TASK_H 3 4#include \u0026lt;coroutine\u0026gt; 5#include \u0026lt;exception\u0026gt; 6#include \u0026lt;functional\u0026gt; 7 8template \u0026lt;bool initialSuspend\u0026gt; struct Task { 9 struct promise_type { 10 std::coroutine_handle\u0026lt;\u0026gt; handle; 11 std::function\u0026lt;void()\u0026gt; onDone; // 协程结束时调用的清理回调 12 13 auto get_return_object() { return Task{*this}; } 14 15 auto initial_suspend() { 16 if constexpr (initialSuspend) { 17 return std::suspend_always{}; 18 } else { 19 return std::suspend_never{}; 20 } 21 } 22 23 auto final_suspend() noexcept { 24 struct Awaiter { 25 bool await_ready() noexcept { return false; } 26 27 void await_suspend(std::coroutine_handle\u0026lt;promise_type\u0026gt; h) noexcept { 28 if (h.promise().onDone) { 29 h.promise().onDone(); 30 } 31 } 32 33 void await_resume() noexcept {} 34 }; 35 return Awaiter{}; 36 } 37 38 void unhandled_exception() { std::terminate(); } 39 40 void return_void() {} 41 42 promise_type() = default; 43 ~promise_type() = default; 44 }; 45 46 explicit Task(promise_type \u0026amp;promise) 47 : handle_(std::coroutine_handle\u0026lt;promise_type\u0026gt;::from_promise(promise)) {} 48 49 Task(Task \u0026amp;\u0026amp;other) noexcept : handle_(other.handle_) { 50 other.handle_ = nullptr; 51 } 52 53 Task \u0026amp;operator=(Task \u0026amp;\u0026amp;other) noexcept { 54 if (this != \u0026amp;other) { 55 if (handle_ \u0026amp;\u0026amp; !handle_.done()) 56 handle_.destroy(); 57 handle_ = other.handle_; 58 other.handle_ = nullptr; 59 } 60 return *this; 61 } 62 63 Task(const Task \u0026amp;) = delete; 64 Task \u0026amp;operator=(const Task \u0026amp;) = delete; 65 66 ~Task() { 67 if (handle_ \u0026amp;\u0026amp; !handle_.done()) 68 handle_.destroy(); 69 } 70 71 void resume() { handle_.resume(); } 72 73 void setOnDone(std::function\u0026lt;void()\u0026gt; onDone) { 74 handle_.promise().onDone = std::move(onDone); 75 } 76 77private: 78 std::coroutine_handle\u0026lt;promise_type\u0026gt; handle_; 79}; 80 81#endif // TASK_H 简单说一下几个关键点：\n使用模板变量，来控制协程的初始挂起状态。\n在协程结束时，可以通过 onDone 回调来执行清理操作。 在协程结束时，可以调用这个函数，完成一些自定义操作，后面会用到。\n协程结束时会自动调用 final_suspend，可以在这里进行一些收尾工作。 final_suspend中定义了一个 Awaiter，用于在协程结束时执行清理操作。当协程结束时，Awaiter 会被唤醒，从而调用 onDone 回调。当 onDone 执行完成后，协程的资源会被释放。\nio_uring wrapper 1class IoUring { 2public: 3 explicit IoUring(int port) : port_(port) {} 4 5 IoUring(const IoUring \u0026amp;) = delete; 6 IoUring \u0026amp;operator=(const IoUring \u0026amp;) = delete; 7 IoUring(IoUring \u0026amp;\u0026amp;) = delete; 8 IoUring \u0026amp;operator=(IoUring \u0026amp;\u0026amp;) = delete; 9 10 ~IoUring() = default; 11 12 void Stop() { running_.store(false); } 13 14 io_uring \u0026amp;Uring() { return ring_; } 15 16 std::expected\u0026lt;bool, std::string\u0026gt; Init();//初始化io_uring和网络 17 void run();//运行io_uring事件循环 18 Task\u0026lt;true\u0026gt; acceptServer();//接受客户端连接 19 20 Task\u0026lt;false\u0026gt; startSession(int fd, uint64_t connId);//处理客户端会话 21 22private: 23 std::expected\u0026lt;bool, std::string\u0026gt; createListenSocket();//创建监听socket 24 25 static int set_nonblocking(int fd) {//设置socket为非阻塞IO 26 return fcntl(fd, F_SETFL, fcntl(fd, F_GETFL, 0) | O_NONBLOCK); 27 } 28 29 uint64_t getConnId() { return ++connId; } 30 31 io_uring ring_{}; 32 uint16_t port_; 33 int listenFd_ = -1; 34 const int entries_ = 256; // Default number of entries 35 std::atomic\u0026lt;bool\u0026gt; running_ = true; 36 37 uint64_t connId = 0; // Connection ID for tracking connections 38 39 std::unordered_map\u0026lt;uint64_t, Task\u0026lt;false\u0026gt;\u0026gt; sessions_; 40}; 以上就是对 io_uring 的一个简单封装，下面挑几个关键的函数来聊一下\nIoUring::run 1void IoUring::run() { 2 while (running_.load()) { 3 io_uring_cqe *cqe = nullptr; 4 int ret = io_uring_wait_cqe(\u0026amp;ring_, \u0026amp;cqe); 5 if (ret \u0026lt; 0) { 6 if (ret == -EINTR) 7 continue; 8 break; 9 } 10 // user_data 保存着 Op 指针 11 auto *op = reinterpret_cast\u0026lt;AwaitableBaseOp *\u0026gt;(cqe-\u0026gt;user_data); 12 if (!op) { 13 io_uring_cqe_seen(\u0026amp;ring_, cqe); 14 continue; 15 } 16 op-\u0026gt;SetRes(cqe-\u0026gt;res);//设置操作结果 17 io_uring_cqe_seen(\u0026amp;ring_, cqe); 18 19 op-\u0026gt;resume();//恢复协程执行 20 } 21} 循环遍历 io_uring 的完成队列，处理每个完成的操作。\nAwaitableBaseOp 是所有可等待操作的基类，负责管理协程的状态和生命周期，后面会用到。\nop-\u0026gt;SetRes(cqe-\u0026gt;res); 把io_uring的结果传递给操作对象。\n在 op-\u0026gt;resume() 被调用时，协程会继续执行，直至下一个挂起点。\nIoUring::startSession 1Task\u0026lt;false\u0026gt; IoUring::startSession(int fd, uint64_t connId) { 2 std::string buffer; 3 buffer.resize(1024); 4 while (true) { 5 auto res = co_await AwaitableRead(this, fd, buffer); 6 if (res \u0026lt;= 0) { 7 break; 8 } 9 std::cout \u0026lt;\u0026lt; \u0026#34;Received data: \u0026#34;; 10 std::cout.write(buffer.data(), res); 11 std::cout \u0026lt;\u0026lt; std::endl; 12 res = co_await AwaitableWrite(this, fd, std::move(std::string(buffer))); 13 if (res \u0026lt;= 0) { 14 break; 15 } 16 } 17 close(fd); 18 co_return; 19} 启动一个客户端会话，处理数据的读取和写入。\n使用 co_await 关键字来等待异步操作的完成。\nco_await AwaitableRead 这里会把当前协程挂起，然后当读取操作完成时，协程会被唤醒，并且可以获取到读取的结果。\nco_await AwaitableWrite 这里同样会把当前协程挂起，等待写入操作完成。\nIoUring::acceptServer 1Task\u0026lt;true\u0026gt; IoUring::acceptServer() { 2 while (true) { 3 auto clientFd = co_await AwaitableAccept(this, listenFd_); 4 std::cout \u0026lt;\u0026lt; clientFd \u0026lt;\u0026lt; std::endl; 5 if (clientFd \u0026lt; 0) 6 break; 7 8 set_nonblocking(clientFd); 9 auto connId = getConnId(); 10 auto t = startSession(clientFd, connId);//启动一个客户端会话，处理数据的读取和写入。 11 t.setOnDone([connId, this]() { sessions_.erase(connId); }); 12 sessions_.emplace(connId, std::move(t)); 13 } 14 close(listenFd_); 15 co_return; 16} 开始一个服务器端的会话，接受客户端连接。\nco_await AwaitableAccept 这里会把当前协程挂起，当有客户端连接时，协程会被唤醒，并且可以获取到接受的结果。\nauto t = startSession(clientFd, connId); 这里会启动一个协程，处理数据的读取和写入。 这里有个关键点，startSession 会返回一个协程的句柄，一定要妥善保管这个句柄，如果没有保存，当 while 循环结束时，协程会被销毁，导致异常。 所以要把协程的句柄保存在 sessions_ 这个 map 中，以便后续管理。\nt.setOnDone([connId, this]() { sessions_.erase(connId); }); 在这里，通过设置回调函数，设置了协程完成后的清理工作。\nAwaitableBaseOp 1class AwaitableBaseOp { 2public: 3 explicit AwaitableBaseOp(std::coroutine_handle\u0026lt;\u0026gt; h) : coro_(h) {} 4 5 virtual ~AwaitableBaseOp() = default; 6 7 void resume() { 8 if (coro_ \u0026amp;\u0026amp; !coro_.done()) { 9 coro_.resume(); 10 } 11 } 12 13 void SetRes(int res) { res_ = res; } 14 15 int GetRes() const { return res_; } 16 17protected: 18 std::coroutine_handle\u0026lt;\u0026gt; coro_; 19 int res_ = 0; 20}; 定义了协程的基本操作，包括恢复协程和设置结果。这个类的实例的指针会被传递给 io_uring_sqe 的 user_data 中。 当 io_uring 的异步操作完成时，io_uring 通过得到 io_uring_cqe AwaitableBaseOp 的指针，调用 SetRes 来设置结果，然后调用 resume 来恢复协程。\nAwaitable 需要到 accept read write 的操作都可以封装成一个 Awaitable 类，方便管理协程的状态和生命周期。\naccept 1class AwaitableAccept { 2 IoUring *uring_ = nullptr; 3 sockaddr_storage addr_{}; 4 socklen_t addrlen_{}; 5 int serverFd_ = 0; 6 7 AwaitableBaseOp *op = nullptr; 8 9public: 10 //省略部分代码 11 12 ~AwaitableAccept() = default; 13 14 bool await_ready() const noexcept { return false; } 15 16 void await_suspend(std::coroutine_handle\u0026lt;\u0026gt; h) { 17 op = new AwaitableBaseOp(h); 18 19 io_uring_sqe *sqe = io_uring_get_sqe(\u0026amp;uring_-\u0026gt;Uring()); 20 io_uring_prep_accept(sqe, serverFd_, reinterpret_cast\u0026lt;sockaddr *\u0026gt;(\u0026amp;addr_), 21 \u0026amp;addrlen_, 0); 22 io_uring_sqe_set_data(sqe, op); 23 io_uring_submit(\u0026amp;uring_-\u0026gt;Uring()); 24 } 25 26 int await_resume() const noexcept { 27 int res = op-\u0026gt;GetRes(); 28 delete op; 29 return res; 30 } 31}; 这是 AwaitableAccept 类的实现，封装了对 io_uring 的 accept 操作。通过使用协程，可以方便地管理异步 I/O 操作的状态和生命周期。\nawait_suspend 函数会在协程挂起时（co_await 操作）被调用，负责将协程的句柄与 io_uring 的请求关联起来。 在函数内部，创建一个 AwaitableBaseOp 对象，并将协程的句柄传递给它。然后，准备一个 io_uring 的提交请求，并将 AwaitableBaseOp 对象的指针设置为请求的用户数据。最后，提交请求到 io_uring。\nawait_resume 函数会在协程恢复时（调用 resume）被调用，负责获取异步操作的结果并清理资源。 这里 return 最后返回结果。这里 return 的值会被 co_await 表达式的调用者获取到。\nread 1class AwaitableRead { 2 IoUring *uring_ = nullptr; 3 int fd_ = 0; 4 std::string \u0026amp;buffer_; 5 6 AwaitableBaseOp *op_ = nullptr; 7 8public: 9 //省略部分代码 10 void await_suspend(std::coroutine_handle\u0026lt;\u0026gt; h) { 11 op_ = new AwaitableBaseOp(h); 12 13 io_uring_sqe *sqe = io_uring_get_sqe(\u0026amp;uring_-\u0026gt;Uring()); 14 io_uring_prep_recv(sqe, fd_, buffer_.data(), buffer_.size(), 0); 15 io_uring_sqe_set_data(sqe, op_); 16 io_uring_submit(\u0026amp;uring_-\u0026gt;Uring()); 17 } 18 //省略部分代码 19}; AwaitableRead 类的实现，封装了对 io_uring 的读取操作。\n中间省略了一些代码细节，但整体思路就是通过 AwaitableRead 类来简化异步读取操作的实现。\nawait_suspend 函数内部，将协程的句柄与 io_uring 的请求关联起来。然后，准备一个 io_uring 的提交请求，并将 AwaitableBaseOp 对象的指针设置为请求的用户数据。最后，提交请求到 io_uring。\nawait_resume 函数会在协程恢复时被调用，负责获取异步操作的结果并清理资源。这里 return 最后返回结果。这里 return 的值会被 co_await 表达式的调用者获取到。\nwrite 1class AwaitableWrite { 2 IoUring *uring_ = nullptr; 3 int fd_ = 0; 4 std::string buffer_; 5 AwaitableBaseOp *op_ = nullptr; 6 7public: 8 //省略部分代码 9 10 void await_suspend(std::coroutine_handle\u0026lt;\u0026gt; h) { 11 op_ = new AwaitableBaseOp(h); 12 13 io_uring_sqe *sqe = io_uring_get_sqe(\u0026amp;uring_-\u0026gt;Uring()); 14 io_uring_prep_write(sqe, fd_, buffer_.data(), buffer_.size(), 0); 15 io_uring_sqe_set_data(sqe, op_); 16 io_uring_submit(\u0026amp;uring_-\u0026gt;Uring()); 17 } 18 //省略部分代码 19}; AwaitableWrite 类的实现，封装了对 io_uring 的写入操作。基本和 AwaitableRead 类类似，通过协程的方式简化了异步写入的流程。await_suspend 函数负责将协程的句柄与 io_uring 的请求关联起来，并提交写入请求。await_resume 函数则负责获取写入操作的结果并清理资源。\nrun 1int main() { 2 IoUring ioUring(8088); 3 if (auto ret = ioUring.Init(); !ret) { 4 std::cout \u0026lt;\u0026lt; \u0026#34;uring init fail\u0026#34; \u0026lt;\u0026lt; ret.error() \u0026lt;\u0026lt; std::endl; 5 return -1; 6 } 7 auto t = ioUring.acceptServer(); 8 std::cout \u0026lt;\u0026lt; \u0026#34;Server started on port 8088.\u0026#34; \u0026lt;\u0026lt; std::endl; 9 t.resume(); 10 ioUring.run(); 11 return 0; 12} 运行这个程序\n创建一个 IoUring 对象，监听8088端口。 调用 IoUring::Init 初始化 io_uring。 调用 IoUring::acceptServer 开始接受连接。 调用 IoUring::run 进入事件循环。 到这，整个协程与 io_uring 的结合就完成了。通过这种方式，我们可以在 C++ 中优雅地处理异步 I/O 操作，充分利用协程的优势，提高代码的可读性和可维护性。 可能会有人问，怎么没看到有关线程 std::thread 的代码？因为这个例子是单线程内使用协程的，所有的操作都是在同一个线程中完成的。所谓的异步是通过协程的挂起和恢复来实现的，而不是通过多线程并发执行。通过异步 I/O 读写时，不会阻塞当前线程，当读写完成后，通知当前线程，来实现的异步。\n那这样设计的好处是什么呢？首先，它避免了多线程编程中的许多复杂性，比如线程安全、锁竞争等问题。其次，协程的上下文切换比线程轻量得多，性能开销更小。最后，协程可以让异步代码看起来像同步代码，极大地提高了可读性和可维护性。\n如果要使用多线程来充分利用多核 CPU 的性能，可以在每个线程中创建一个 IoUring 对象，并使用协程来处理每个线程中的异步 I/O 操作。这样可以在保持代码简洁的同时，充分利用多核 CPU 的优势。\n","date":"2025-08-23T17:04:05+08:00","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/cc0fd96def7c84c2e2b5d6a00915b3b8175116cf.jpg","permalink":"https://lqxhub.github.io/posts/d26369fd/","title":"linux中io_uring和C++协程的结合，实现真正的异步I/O。简单的TCP echo server"},{"content":"差不多有半年没有写东西了，主要是这段时间太忙了，一直没空，这两周开始有了一点空闲时间，重新捡起了C++协程相关的知识，又学了一下，写篇文章，做点笔记。 去年就了解了一点C++协程相关的知识，但是当时只是浅显的了解了一下，很多东西没有弄清楚，这次整理了一些概念，写了一些demo。\nC++的协程是C++20开始支持的，协程也不是什么新鲜东西了，诞生于2009年的golang出生就带协程。使用过golang协程的可能都深有体会，协程在异步编程中提供了很好的支持，可以大幅度简化代码逻辑。但是说实话，C++这版本的协程只是实现了基础功能，对于写具体业务代码来说，还是很不方便的，太多的东西需要自己解决。不像golang的协程，一个 go 关键字就行了。所以很多人开玩笑说，这版本的协程是给库作者的，不是给普通开发者的。这样也有好处，给了使用者更多的灵活性和控制权。\n在学习之前，先明确一个知识点，C++20的协程，如果没有自己实现多线程的调度逻辑，都是在单线程中执行的。只是 并发 不是 并行 。golang的协程能做到并行，是因为go的runtime实现了多线程的调度逻辑，而C++20的协程只是提供了协程的语法和基本的状态机支持，并没有提供多线程的调度逻辑。C++的协程，是通过函数的状态切换（把暂时不需要使用CPU的函数暂停，等到合适的时机再恢复执行）提高了CPU的利用效率，看上去像是异步执行了。\nC++协程的实现方式，后面会浅显介绍一下。因为太深入的我也了解不多。目前了解到的，C++的协程是基于状态机的实现的，编译器在编译协程时，会将协程转换为状态机的形式，从而实现协程的调度和切换。\n说到协程，首先要了解的是协程的两种基本类型：有栈协程和无栈协程。\n有栈协程和无栈协程 有栈协程： 协程在执行时会使用自己的栈空间，协程的调用和返回都是通过栈来实现的。这种方式的优点是实现简单，性能较好，但缺点是栈空间有限，容易导致栈溢出。go语言的协程就是有栈协程的一个典型例子。\n无栈协程： 协程在执行时不使用自己的栈空间，而是将所有的状态信息保存在堆上。这种方式的优点是可以支持更大的协程栈，但缺点是实现复杂。C#的协程就是无栈协程的一个典型例子。\n既然是聊C++的协程（没有特殊说明，下文中所提到的C++协程都是指C++20的原生协程），那关注点就要放在C++的协程实现上，C++的协程采用的就是无栈协程，当然也有一些第三方协程库是有栈协程，这个不在本次讨论范围。C++的协程是基于状态机的实现的，编译器在编译协程时，会将协程转换为状态机的形式，从而实现协程的调度和切换。\n说的通俗一点，就是编译器在编译代码时，把协程函数编译成一个特殊的函数，这个函数有很多状态，可以被挂起（让出CPU资源，也叫暂停执行），恢复执行等等。这样的函数也叫做可重入函数。协程的状态信息（如局部变量、返回地址等）保存在堆上，而不是栈上。\n画一下协程的状态机图，可能会更清晰一些：\n从这个图中可以看出，协程函数可以被挂起（暂停执行）和恢复执行，协程函数可以在多个状态之间切换，这些状态包括挂起、恢复和完成等。这样的设计使得协程能够在执行过程中灵活地让出控制权。\n至于协程函数是怎样被挂起和恢复的，主要是通过编译器生成的状态机来实现的。当协程函数被挂起时，编译器会保存当前的执行状态（如局部变量、返回地址等），并将控制权交回给调用者。当协程函数被恢复时，编译器会恢复之前保存的执行状态，从而实现协程的继续执行。\n下面将一点点来分析协程函数的控制。\nC++协程函数 C++协程函数的实现主要依赖于编译器的支持。在编写协程函数时，开发者只需使用 co_await、co_yield 和 co_return 等关键字来定义协程的行为。编译器会根据这些关键字生成相应的状态机代码，从而实现协程的挂起和恢复。\n具体来说，当协程函数被调用时，编译器会创建一个状态机对象来管理协程的状态。这个状态机对象会保存协程的局部变量、返回地址等信息。当协程函数执行到 co_await 或 co_yield 时，编译器会将当前的执行状态保存到状态机对象中，并将控制权交回给调用者。当协程函数被恢复时，编译器会从状态机对象中恢复之前保存的执行状态，从而实现协程的继续执行。\n需要注意的是，C++协程函数的返回类型并不是普通的返回值，而是一个特殊的协程句柄（coroutine handle）。这个句柄可以用来管理协程的生命周期，例如启动、挂起和恢复等操作。\n看到这些可能会一头雾水，别着急，让我们一点点来。\n协程函数和普通函数的区别 最明显的区别是协程函数可以被挂起和恢复。但是有没有想过，编译器在编译代码的时候，是怎样识别一个函数是普通函数还是协程函数呢？ 这主要是通过协程函数的返回类型来判断的。协程函数的返回类型是一个特殊的协程句柄coroutine handle，而不是普通的返回值。这个协程句柄可以用来管理协程的生命周期。\n所以当编译器看到一个函数的返回类型是coroutine handle时，就会将其识别为协程函数。\n下面来看一下什么是协程句柄 coroutine handle\n协程句柄是一个特殊的对象，用于管理协程的生命周期。它可以用来启动、挂起和恢复协程。协程句柄的实现依赖于编译器生成的状态机代码。\n说到 coroutine_handle 就不得不提协程的 promise。promise 类型是协程的核心，它负责管理协程的状态和生命周期。每个协程都有一个对应的 promise 对象，用于保存协程的状态信息。\n在 C++20 中，协程句柄的类型是 std::coroutine_handle。这个类型是一个模板类，接受一个 promise 类型作为模板参数。promise 类型是协程的状态机对象，负责管理协程的状态。\npromise 不是一个具体的类型，通常需要实现以下几个方法的结构体就是 promise类型：\nget_return_object()：返回协程的句柄 initial_suspend()：协程开始时是否挂起 final_suspend()：协程结束时是否挂起 yield_value()：协程中使用 co_yield 返回值时的处理 return_void()：协程返回时是否返回值 unhandled_exception()：处理未捕获的异常 通过这些方法，协程的 promise 类型可以与协程句柄进行交互，从而实现协程的挂起和恢复。\n也就是说，只要一个函数的返回值是 coroutine_handle 类型，编译器就会将其识别为协程函数，协程函数能实现挂起和恢复的功能，主要是通过 promise 对象来管理协程的状态和生命周期。\n协程关键字 在C++20中，协程函数使用了三个个关键字来控制协程行为\nco_await：用于挂起协程并等待一个异步操作的完成。 co_yield：用于返回一个值并挂起协程的执行。 co_return：用于返回协程的最终结果。 通过这些关键字，开发者可以方便地定义协程的行为，从而实现异步编程的需求。\nco_await 和 co_yield 关键字可以用于实现协程的挂起和恢复，而 co_return 关键字则用于返回协程的最终结果。\n其中 co_await 是用于挂起协程并等待一个异步操作的完成的关键字。\n说到 co_await，我们就不得不提一下可等待对象awaitable。这个对象和 promise 有点类似，不是一个具体的类型，而是一个接口。这个对象需要实现以下三个方法：\nawait_ready()：用于检查异步操作是否已经完成。 await_suspend()：用于挂起协程并等待异步操作的完成。 await_resume()：用于恢复协程并返回异步操作的结果。 下面一个个来介绍一下这三个方法的具体实现。\n1bool await_ready() const noexcept; 这个函数用于检查异步操作是否已经完成。如果异步操作已经完成，则返回 true，否则返回 false。如果返回 true，则协程会立即恢复执行，而不会挂起。\n这个函数一般会在协程的 await 表达式中被调用。如果返回 false，则协程会被挂起，等待异步操作的完成。\n1void await_suspend(std::coroutine_handle\u0026lt;result::promise_type\u0026gt; coro) 这个函数用于挂起协程并等待异步操作的完成。它接受一个协程句柄作为参数，这个句柄指向当前协程的 promise 对象。 当异步操作完成时，协程会被恢复执行。\n1void await_resume() 这个函数用于恢复协程并返回异步操作的结果。它一般会在协程的 await 表达式中被调用，用于获取异步操作的结果。\n函数的返回值类型可以是任意类型，通常是异步操作的结果类型。如果异步操作没有结果，则可以返回 void。\n这里还有两个特殊的 await， std::suspend_always 和 std::suspend_never\nstd::suspend_always：表示协程在每次挂起时都会等待，直到显式调用 resume() 恢复协程。 std::suspend_never：表示协程在挂起时不会等待，直接返回控制权给调用者。 直接去看一下这两个类型的实现就明白了，下面是在 llvm-18 的 libc++ 中的实现：\n1struct suspend_never { 2 _LIBCPP_HIDE_FROM_ABI constexpr bool await_ready() const noexcept { return true; } 3 _LIBCPP_HIDE_FROM_ABI constexpr void await_suspend(coroutine_handle\u0026lt;\u0026gt;) const noexcept {} 4 _LIBCPP_HIDE_FROM_ABI constexpr void await_resume() const noexcept {} 5}; 6 7struct suspend_always { 8 _LIBCPP_HIDE_FROM_ABI constexpr bool await_ready() const noexcept { return false; } 9 _LIBCPP_HIDE_FROM_ABI constexpr void await_suspend(coroutine_handle\u0026lt;\u0026gt;) const noexcept {} 10 _LIBCPP_HIDE_FROM_ABI constexpr void await_resume() const noexcept {} 11}; 协程注意事项 协程的生命周期：协程的生命周期由协程句柄 coroutine_handle 管理。协程句柄可以用来启动、挂起和恢复协程。开发者需要注意协程的生命周期，以避免悬空指针和资源泄露等问题。 协程句柄一定要妥善处理，一个协程句柄只能调用一次 destroy() 方法。而且在协程结束后，协程句柄会被销毁，因此开发者需要确保在协程结束前完成对协程句柄的所有操作。如果没有调用 destroy() 方法，协程的资源可能无法被释放，从而导致内存泄漏。如果多次调用 destroy() 方法或者在调用destroy()再次调用resume()，可能会导致未定义行为。\n异常处理：协程中的异常处理与普通函数有所不同。协程可以通过 promise 对象的 unhandled_exception() 方法来处理未捕获的异常。开发者需要在 promise 类型中实现这个方法，以确保协程中的异常能够被正确处理。\n协程例子 说了这么多，通过这些文字可能还是难以理解，下面通过一个简单的例子来帮助理解协程的使用。\n我感觉真正适合协程的场景是需要等待某个操作完成后再继续执行后续逻辑的情况，比如网络请求、文件读写等。最好的搭档就是异步IO的场景。但是直接拿 iouring 这种高性能的异步IO库来做协程的调度，可能会比较复杂，增加理解成本。\n所以就先拿一个简单的例子来说明协程的使用。这个例子是一个简单的协程函数，它会打印一些数字。\n1#include \u0026lt;coroutine\u0026gt; 2#include \u0026lt;iostream\u0026gt; 3#include \u0026lt;optional\u0026gt; 4 5template \u0026lt;typename T\u0026gt; 6struct Task { 7 struct promise_type { 8 std::optional\u0026lt;T\u0026gt; current_value; 9 10 auto get_return_object() { 11 return Task{std::coroutine_handle\u0026lt;promise_type\u0026gt;::from_promise(*this)}; 12 } 13 14 auto initial_suspend() { return std::suspend_always{}; } 15 auto final_suspend() noexcept { return std::suspend_always{}; } 16 17 void unhandled_exception() { std::terminate(); } 18 void return_void() {} 19 20 auto yield_value(T value) { 21 current_value = value; 22 return std::suspend_always{}; // 挂起，等待 next() 恢复 23 } 24 }; 25 26 std::optional\u0026lt;T\u0026gt; next() { 27 if (!handle_ || handle_.done()) return std::nullopt; 28 handle_.resume(); 29 if (handle_.done()) return std::nullopt; 30 return std::move(handle_.promise().current_value); 31 } 32 33 Task(std::coroutine_handle\u0026lt;promise_type\u0026gt; h) : handle_(h) {} 34 Task(Task\u0026amp;\u0026amp; other) noexcept : handle_(other.handle_) { other.handle_ = nullptr; } 35 Task\u0026amp; operator=(Task\u0026amp;\u0026amp; other) noexcept { 36 if (this != \u0026amp;other) { 37 if (handle_) handle_.destroy(); 38 handle_ = other.handle_; 39 other.handle_ = nullptr; 40 } 41 return *this; 42 } 43 44 ~Task() { if (handle_) handle_.destroy(); } 45 46 std::coroutine_handle\u0026lt;promise_type\u0026gt; handle_; 47}; 48 49struct Awaiter { 50 bool await_ready() const noexcept { return false; } 51 52 void await_suspend(std::coroutine_handle\u0026lt;\u0026gt; h) { 53 std::cout \u0026lt;\u0026lt; \u0026#34;Awaiter suspend \u0026#34; \u0026lt;\u0026lt; input \u0026lt;\u0026lt; std::endl; 54 // 这里必须恢复协程 55 h.resume(); 56 } 57 58 int await_resume() noexcept { 59 std::cout \u0026lt;\u0026lt; \u0026#34;Awaiter resume \u0026#34; \u0026lt;\u0026lt; input \u0026lt;\u0026lt; std::endl; 60 return input * 10; 61 } 62 63 int input = 0; 64}; 65 66Task\u0026lt;int\u0026gt; AsyncFunction(int n) { 67 for (int i = 0; i \u0026lt; n; ++i) { 68 auto ret = co_await Awaiter{i + 1}; 69 co_yield ret; 70 } 71 co_return; 72} 73 74int main() { 75 auto t = AsyncFunction(5); 76 while (auto v = t.next()) { 77 std::cout \u0026lt;\u0026lt; \u0026#34;Received: \u0026#34; \u0026lt;\u0026lt; *v \u0026lt;\u0026lt; std::endl; 78 } 79 return 0; 80} 程序输出如下：\n1Awaiter suspend 1 2Awaiter resume 1 3Received: 10 4Awaiter suspend 2 5Awaiter resume 2 6Received: 20 7Awaiter suspend 3 8Awaiter resume 3 9Received: 30 10Awaiter suspend 4 11Awaiter resume 4 12Received: 40 13Awaiter suspend 5 14Awaiter resume 5 15Received: 50 通过打印的信息可以看到，协程函数 AsyncFunction 在每次迭代时都会挂起，并通过 co_yield 返回一个值。每次调用 next() 方法时，协程会恢复执行，直到下一个 co_yield 或协程结束。\n这里是为了展示 co_yield 的用法。才会在协程中使用 co_yield 来返回值。这样写有点画蛇添足了，如果不需要返回值，可以直接使用 co_await 来等待异步操作的完成。这样可以简化代码，更符合协程的使用场景。\n下面让我们来简化一下这段代码\n1#include \u0026lt;coroutine\u0026gt; 2#include \u0026lt;iostream\u0026gt; 3#include \u0026lt;thread\u0026gt; 4 5struct Task 6{ 7 struct promise_type 8 { 9 auto get_return_object() 10 { 11 return Task{std::coroutine_handle\u0026lt;promise_type\u0026gt;::from_promise(*this)}; 12 } 13 14 auto initial_suspend() { return std::suspend_always{}; } 15 auto final_suspend() noexcept { return std::suspend_always{}; } 16 17 void unhandled_exception() { std::terminate(); } 18 19 void return_void() 20 { 21 } 22 }; 23 24 Task(std::coroutine_handle\u0026lt;promise_type\u0026gt; h) : handle_(h) 25 { 26 } 27 28 Task(Task\u0026amp;\u0026amp; other) noexcept : handle_(other.handle_) { other.handle_ = nullptr; } 29 30 Task\u0026amp; operator=(Task\u0026amp;\u0026amp; other) noexcept 31 { 32 if (this != \u0026amp;other) 33 { 34 if (handle_) handle_.destroy(); 35 handle_ = other.handle_; 36 other.handle_ = nullptr; 37 } 38 return *this; 39 } 40 41 ~Task() { if (handle_) handle_.destroy(); } 42 43 std::coroutine_handle\u0026lt;promise_type\u0026gt; handle_; 44}; 45 46struct Awaiter 47{ 48 bool await_ready() const noexcept { return false; } 49 50 void await_suspend(std::coroutine_handle\u0026lt;\u0026gt; h) 51 { 52 std::cout \u0026lt;\u0026lt; \u0026#34;Awaiter suspend \u0026#34; \u0026lt;\u0026lt; input \u0026lt;\u0026lt; std::endl; 53 std::thread t([h]() 54 { 55 //把协程挂起一段时间，模拟异步操作 56 std::this_thread::sleep_for(std::chrono::seconds(1)); 57 h.resume(); 58 }); 59 t.detach(); // 分离线程，避免阻塞 60 } 61 62 int await_resume() noexcept 63 { 64 //协程恢复时执行的操作 65 std::cout \u0026lt;\u0026lt; \u0026#34;Awaiter resume \u0026#34; \u0026lt;\u0026lt; input \u0026lt;\u0026lt; std::endl; 66 return input * 10; 67 } 68 69 int input = 0; 70}; 71 72Task AsyncFunction(int n) 73{ 74 for (int i = 0; i \u0026lt; n; ++i) 75 { 76 auto ret = co_await Awaiter{i + 1}; 77 std::cout \u0026lt;\u0026lt; \u0026#34;Awaiter returned \u0026#34; \u0026lt;\u0026lt; ret \u0026lt;\u0026lt; std::endl; 78 std::cout \u0026lt;\u0026lt; \u0026#34;------------------------\u0026#34; \u0026lt;\u0026lt; std::endl; 79 } 80 co_return; 81} 82 83int main() 84{ 85 auto t = AsyncFunction(5); 86 t.handle_.resume();//手动唤醒协程 87 while (!t.handle_.done()) 88 { 89 } 90 return 0; 91} 上面就是去掉 co_yield 后简化的代码。\n程序执行的输出如下：\n1Awaiter suspend 1 2Awaiter resume 1 3Awaiter returned 10 4------------------------ 5Awaiter suspend 2 6Awaiter resume 2 7Awaiter returned 20 8------------------------ 9Awaiter suspend 3 10Awaiter resume 3 11Awaiter returned 30 12------------------------ 13Awaiter suspend 4 14Awaiter resume 4 15Awaiter returned 40 16------------------------ 17Awaiter suspend 5 18Awaiter resume 5 19Awaiter returned 50 20------------------------ 在 main 函数中，我们手动唤醒协程，并通过循环等待协程完成。\n1while (!t.handle_.done()) 2{ 3} 这里通过 while 循环不断地检查协程是否完成。为什么需要这样做，是因为如果没有检查，而是在协程挂起时直接返回，会导致程序直接退出。\n这也是协程 异步 的体现。普通函数只要调用了，就会一直执行，直到整个函数都执行完成才会退出，然后由函数调用者继续执行。 协程函数会在调用 co_await 时挂起，让出CPU资源，由协程函数的调用者（这里就是main函数）继续执行。等到异步操作完成（也就是执行了 resume）后再恢复执行。\n我们在 await_suspend 中创建了一个新的线程来模拟异步操作。在这个线程中，我们使用 std::this_thread::sleep_for 来让当前线程暂定1秒，模拟异步操作的延迟。\n通过这种方式，我们可以在协程中使用 co_await 来等待异步操作的完成，而不需要使用 co_yield 来返回值。这使得代码更加简洁，也更符合协程的使用场景。\n差不多能想到的就是这些了，当然这只是C++协程中的九牛一毛，想要更深入了解协程的使用，还要通过更多的例子来实践。\n下期将使用 io_uring + 协程来实现真正的异步IO操作。发挥出协程的优势。\n协程+io_uring的文章来了 传送门\n","date":"2025-08-17T20:19:20+08:00","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/6271dad17bae0c4a3d2fd061106001be135c745e.jpg","permalink":"https://lqxhub.github.io/posts/541b707d/","title":"C++20协程，入门，基础，异步 - QX's blog"},{"content":"上一篇文章《C++变量生命周期》中提到了C++中变量的生命周期与作用域是有差别的，其中提到了 左值 和 右值 这两个概念，引申出来了 左值引用 和 右值引用 这两个东西，上次因为篇幅问题，只是简单说了一下左值和右值的一些区别，生命周期和简单用法，没有详细展开。这次讨论一下右值引用的一些常见问题和使用。\nmove 在C++11中，加入了 std::move 函数，实现了移动语义，有了 move函数后，可以实现高效的资源转移，不必像传统的复制那样 ‘笨重’。\nmove例子 先来一个简单的例子来看一下 move 函数的魅力\n1#include \u0026lt;iostream\u0026gt; 2#include \u0026lt;utility\u0026gt; 3#include \u0026lt;vector\u0026gt; 4 5class MyClass { 6public: 7 MyClass(int value) : value_(value) { 8 std::cout \u0026lt;\u0026lt; \u0026#34;Constructing MyClass with value \u0026#34; \u0026lt;\u0026lt; value_ \u0026lt;\u0026lt; std::endl; 9 } 10 11 MyClass(const MyClass\u0026amp; other) : value_(other.value_) { 12 std::cout \u0026lt;\u0026lt; \u0026#34;Copy constructing MyClass with value \u0026#34; \u0026lt;\u0026lt; value_ \u0026lt;\u0026lt; std::endl; 13 } 14 15 MyClass(MyClass\u0026amp;\u0026amp; other) noexcept : value_(other.value_) { 16 other.value_ = 0; 17 std::cout \u0026lt;\u0026lt; \u0026#34;Move constructing MyClass with value \u0026#34; \u0026lt;\u0026lt; value_ \u0026lt;\u0026lt; std::endl; 18 } 19 20 MyClass\u0026amp; operator=(const MyClass\u0026amp; other) { 21 if (this != \u0026amp;other) { 22 value_ = other.value_; 23 std::cout \u0026lt;\u0026lt; \u0026#34;Copy assigning MyClass with value \u0026#34; \u0026lt;\u0026lt; value_ \u0026lt;\u0026lt; std::endl; 24 } 25 return *this; 26 } 27 28 MyClass\u0026amp; operator=(MyClass\u0026amp;\u0026amp; other) noexcept { 29 if (this != \u0026amp;other) { 30 value_ = other.value_; 31 other.value_ = 0; 32 std::cout \u0026lt;\u0026lt; \u0026#34;Move assigning MyClass with value \u0026#34; \u0026lt;\u0026lt; value_ \u0026lt;\u0026lt; std::endl; 33 } 34 return *this; 35 } 36 37 int getValue() const { 38 return value_; 39 } 40 41private: 42 int value_; 43}; 44 45int main() { 46 MyClass a(10); 47 MyClass b = std::move(a); 48 MyClass c = b; 49 50 std::cout\u0026lt;\u0026lt;\u0026#34;----------------------------\u0026#34;\u0026lt;\u0026lt;std::endl; 51 52 std::cout \u0026lt;\u0026lt; \u0026#34;Value of a after move: \u0026#34; \u0026lt;\u0026lt; a.getValue() \u0026lt;\u0026lt; std::endl; 53 std::cout \u0026lt;\u0026lt; \u0026#34;Value of b after move: \u0026#34; \u0026lt;\u0026lt; b.getValue() \u0026lt;\u0026lt; std::endl; 54 55 std::cout\u0026lt;\u0026lt;\u0026#34;----------------------------\u0026#34;\u0026lt;\u0026lt;std::endl; 56 std::vector\u0026lt;MyClass\u0026gt; vec; 57 vec.push_back(MyClass(20)); 58 std::cout\u0026lt;\u0026lt;\u0026#34;----------------------------\u0026#34;\u0026lt;\u0026lt;std::endl; 59 vec.push_back(std::move(b)); 60 61 return 0; 62} 这段代码执行的结果\n1Constructing MyClass with value 10 2Move constructing MyClass with value 10 3Copy constructing MyClass with value 10 4---------------------------- 5Value of a after move: 0 6Value of b after move: 10 7---------------------------- 8Constructing MyClass with value 20 9Move constructing MyClass with value 20 10---------------------------- 11Move constructing MyClass with value 10 12Move constructing MyClass with value 20 通过代码执行的结果可以看到，\n在代码 MyClass a(10); 中，初始化变量 a 调用了构造函数。\n在代码 MyClass b = std::move(a); 中，初始化变量 b 调用了移动构造函数。\n在代码 MyClass c = b; 中，初始化变量 c 调用了拷贝构造函数。\n在代码 vec.push_back(MyClass(20)); 中，对应的两行输出\n1Constructing MyClass with value 20 2Move constructing MyClass with value 20 MyClass(20) 构造一个临时对象 调用移动构造函数，这个临时对象传入到 vec 中 在代码 vec.push_back(std::move(b));中，对应的一行输出\n1Move constructing MyClass with value 10 因为是使用的 std::move 函数，所以直接通过移动构造函数把值放到 vec 中\n最后一行 Move constructing MyClass with value 20 输出是因为在 vec.push_back(std::move(b));时，vec 发生了扩容，MyClass(20) 这个对象发生了一次移动。\n看到这里，大概能对 move 函数有大概的了解了。可能也会产生一个疑问，为什么要使用move 函数呢？\n首先我们要明确一个点，在C++中，变量的赋值默认都是拷贝行为。所谓的引用传递参数，不过是编译器实现的一种指针，本质是对内存地址的一次拷贝。\n拷贝会带来什么问题呢？其中一个问题就是，在传递大的对象时，需要把对象的成员变量都复制一次。上面例子中的 MyClass 中只有一个 int value_ 类型的成员变量开销比较小，如果成员变量很多，而且类型复杂，那每次传递变量都复制一次，这个开销就不能忽视了。\nmove分析 回到 move 函数，移动语义允许将资源的 所有权 从一个对象转移到另一个对象，而无需深拷贝。\n看到这里，是否好奇 move 函数为什么有如此魔力，是怎样实现的呢\n下面就是 move 函数的常见实现方式\n1template\u0026lt;typename T\u0026gt; 2typename std::remove_reference\u0026lt;T\u0026gt;::type\u0026amp;\u0026amp; move(T\u0026amp;\u0026amp; t) { 3 return static_cast\u0026lt;typename std::remove_reference\u0026lt;T\u0026gt;::type\u0026amp;\u0026amp;\u0026gt;(t); 4} 看着挺复杂的，可以将这段代码简化一下，简化后大概就是这个样子\n1template \u0026lt;typename T\u0026gt; 2T \u0026amp;\u0026amp;move(T \u0026amp;t) { 3 return static_cast\u0026lt;T \u0026amp;\u0026amp;\u0026gt;(t); 4} 这样看下来，move 函数其实就做了一件事 接受一个通用引用(T\u0026amp;\u0026amp;)，然后通过 static_cast 将其转换为右值引用\nmove 的本意是提前让一个对象“将亡”，然后把控制权“移交”给右值引用，所以才叫move，也就是“移动语义”。但是，C++并不能真正让一个对象提前“亡”，所以这里的“移动”仅仅是“语义”上的，并不是实际的。只是告诉编译器，这个对象我不需要了，可以绑定到右值引用上了。\n有个点需要注意一下，移动构造函数需要加上 noexcept 虽然不加也能正常执行，但是在使用容器等 STL 库时，如果对象的 移动构造函数没有 声明为 noexcept 可能会导致不会使用移动构造，而是使用拷贝构造。\n再讨论一下上文中提到的 所有权，这个概念我最早是从 rust 中了解到的，后来在C++中，使用 std::unique_ptr 智能指针的时候，逐渐对所有权这个概念有了一些理解。\n书接上面的例子\n1void func1(std::unique_ptr\u0026lt;MyClass\u0026gt; ptr) 2{ 3} 4 5void func2(std::unique_ptr\u0026lt;MyClass\u0026gt;\u0026amp; ptr) 6{ 7} 8 9int main() { 10 std::unique_ptr\u0026lt;MyClass\u0026gt; ptr1 = std::make_unique\u0026lt;MyClass\u0026gt;(30); 11 auto ptr2 = ptr1; //编译报错 12 func1(ptr1); //编译报错 13 14 auto ptr3 = std::move(ptr1); 15 func2(ptr3); 16 func1(std::move(ptr2)); 17} ptr1 这个智能指针拥有该对象的所有权，如果尝试将这个指针复制给 ptr2 这个指针那么编译器会报错，因为 std::unique_ptr 类型的指针只允许一个指针对象持有 MyClass 这个对象的所有权。复制行为是将所有权共享，所以会提示错误。\n能做到只能是将所有权转移，也就是 ptr1 指针放弃所有权，将所有权交给 ptr3 这个指针。同样的，在作为函数的参数传递时，也是同样的道理，作为 func1 函数的参数时，只能使用 move，将所有权转移。\n还有一种方式，借，在函数 func2 中，可以使用引用的方式，将所有权暂时 ‘借’ 给 func2 中的变量使用，但是所有权还在原来的所有者那里。\nmove函数的优先级 如果一个 class 实现了 移动构造函数，在赋值时，是否一定会使用 move 呢？答案是不一定，是否优先使用移动构造函数取决于具体的情境。\n先来看一下 拷贝构造函数 和 移动构造函数 的签名\n1MyClass(const MyClass\u0026amp; other);//拷贝构造 2MyClass(MyClass\u0026amp;\u0026amp; other) noexcept;//移动构造 可以看到，移动构造函数的参数类型是 右值引用。\n也就是说，优先级规则是这样的\n如果实参是 左值，编译器会调用拷贝构造函数 如果实参是 右值，并且存在移动构造函数，编译器会优先调用移动构造函数 但这里的关键是：复制 这个行为是否涉及右值。如果代码没有显式地将对象标记为右值（比如使用 std::move），即使有移动构造函数，也不会被调用。\n使用move注意事项 移动后对象的状态：调用 std::move 后，源对象并没有被销毁，但它处于一个“有效但未指定”的状态（valid but unspecified state）。比如对于 std::string，它可能变为空字符串，但具体取决于类的实现。\n不保证移动：std::move 只是请求移动，能否真正移动取决于目标类型是否实现了移动构造函数或移动赋值运算符。如果没有，编译器会回退到拷贝。\n不要滥用：只有当你确定某个对象不再需要时，才应该使用 std::move。\nforward 说完了 std::move 那就不得不提 std::forward 了。forward也叫 完美转发\n和 move 不同的地方，forward 常用在模板编程中，以确保参数能够按照原始值类别（左值或右值）传递给下一个函数，而不会丢失其属性。在模板编程中，一般都是希望将参数传递给另一个函数时，保留参数的原始值类型。 但是 std::move 总是将对象无条件转换为右值，而 std::forward 则根据参数的原始类型有条件地进行转发。\n如果传入的是 左值，则以左值的形式转发。 如果传入的是 右值，则以右值的形式转发。 forward例子 通过一个简单的例子看一下：\n1#include \u0026lt;iostream\u0026gt; 2 3void process(int\u0026amp; x) { std::cout \u0026lt;\u0026lt; \u0026#34;Lvalue: \u0026#34; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } 4void process(int\u0026amp;\u0026amp; x) { std::cout \u0026lt;\u0026lt; \u0026#34;Rvalue: \u0026#34; \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; } 5 6template\u0026lt;typename T\u0026gt; 7void forwarder(T\u0026amp;\u0026amp; arg) { 8 process(arg); // 直接传递 arg 9} 10 11int main() { 12 int a = 42; 13 forwarder(a); // 传入左值 14 forwarder(100); // 传入右值 15 return 0; 16} 执行结果:\n1Lvalue: 42 2Lvalue: 100 a 是左值，转发为左值，调用 process(int\u0026amp;) 100 是右值，转发为右值，调用 process(int\u0026amp;\u0026amp;) process 函数有两个重载，分别是 左值引用 和 右值引用，forwarder 函数可以根据不同的类型调用不同的 process，也就实现了 转发\n实现原理 std::forward 的实现依赖于 引用折叠和类型推导，下面是 forward 函数实现\n1template\u0026lt;typename T\u0026gt; 2T\u0026amp;\u0026amp; forward(typename std::remove_reference\u0026lt;T\u0026gt;::type\u0026amp; arg) noexcept { 3 return static_cast\u0026lt;T\u0026amp;\u0026amp;\u0026gt;(arg); 4} 5 6template\u0026lt;typename T\u0026gt; 7T\u0026amp;\u0026amp; forward(typename std::remove_reference\u0026lt;T\u0026gt;::type\u0026amp;\u0026amp; arg) noexcept { 8 return static_cast\u0026lt;T\u0026amp;\u0026amp;\u0026gt;(arg); 9} 传入左值时，T 推导为 Type\u0026amp;，T\u0026amp;\u0026amp; 折叠为左值引用 传入右值时，T 推导为 Type，T\u0026amp;\u0026amp; 保持为右值引用 std::forward 与 std::move 相比，它更 智能，适用于需要动态适配参数类型的场景。一般用在模板编程中，确保参数在传递过程中保留原始的 左值 / 右值属性，避免不必要的拷贝。\nRVO RVO（Return Value Optimization，返回值优化，是C++编译器的一种优化技术，用于减少函数返回大对象时的拷贝开销。在没有 RVO 的情况下，函数返回一个对象时，会调用拷贝构造函数或移动构造函数来构造返回值对象。RVO 的目标是直接在调用者的内存空间中构造返回对象，从而避免额外的拷贝或移动。\nRVO 有两种形式\nNRVO（Named Return Value Optimization）：针对命名的局部变量 URVO（Unnamed Return Value Optimization）：针对临时对象（未命名的对象） RVO例子 1#include \u0026lt;iostream\u0026gt; 2 3struct MyClass { 4 MyClass() { std::cout \u0026lt;\u0026lt; \u0026#34;Constructor\\n\u0026#34;; } 5 MyClass(const MyClass\u0026amp;) { std::cout \u0026lt;\u0026lt; \u0026#34;Copy constructor\\n\u0026#34;; } 6 MyClass(MyClass\u0026amp;\u0026amp;) noexcept { std::cout \u0026lt;\u0026lt; \u0026#34;Move constructor\\n\u0026#34;; } 7 ~MyClass() { std::cout \u0026lt;\u0026lt; \u0026#34;Destructor\\n\u0026#34;; } 8}; 9 10MyClass create() { 11 MyClass obj; 12 return obj; // 返回局部对象 13} 14 15int main() { 16 MyClass a = create(); 17 return 0; 18} 现在的编译器默认都会开启 RVO 优化，所以需要手动禁用，在clang中，可以在命令行中添加 -fno-elide-constructors 来禁用。\n使用 clang++ -fno-elide-constructors -o main main.cpp 命令来编译，然后执行 main，输出如下\n1Constructor 2Move constructor 3Destructor 4Destructor 可以看到在 return obj 时，因为没有使用 RVO 优化，所以复制了一次对象，但是因为有移动构造函数，所以使用了 move 优化。\n下面开启 RVO 优化看一下\n使用 clang++ -o main main.cpp 命令编译，然后执行 main 输出如下\n1Constructor 2Destructor 可以看到只调用了构造函数。\n工作原理 在线汇编 使用这个工具，可以看到具体的汇编代码\n下面是是让GPT加了注释的汇编代码\n1create(): ; create() 函数定义开始 2 push rbp ; 保存当前栈帧基址指针 3 mov rbp, rsp ; 建立新的栈帧，将栈指针值赋给基址指针 4 sub rsp, 16 ; 分配16字节的栈空间用于局部变量 5 mov QWORD PTR [rbp-8], rdi ; 保存第一个参数(rdi)到栈上[rbp-8]位置，这是对象指针 6 mov rax, QWORD PTR [rbp-8] ; 将对象指针加载到rax寄存器 7 mov rdi, rax ; 将对象指针作为第一个参数(rdi)传递给构造函数 8 call MyClass::MyClass() [complete object constructor] ; 调用MyClass的构造函数初始化对象 9 mov rax, QWORD PTR [rbp-8] ; 将对象指针重新加载到rax作为函数返回值 10 leave ; 恢复栈帧（相当于mov rsp, rbp; pop rbp） 11 ret ; 从函数返回，返回值在rax中 12 13main: ; main函数定义开始 14 push rbp ; 保存当前栈帧基址指针 15 mov rbp, rsp ; 建立新的栈帧 16 push rbx ; 保存rbx寄存器的值(调用者保存的寄存器) 17 sub rsp, 24 ; 分配24字节的栈空间 18 lea rax, [rbp-17] ; 将栈上地址[rbp-17]加载到rax，这是为MyClass对象分配的空间 19 mov rdi, rax ; 将对象地址作为参数传递给create函数 20 call create() ; 调用create函数，初始化对象 21 mov ebx, 0 ; 将返回值0存储到ebx寄存器 22 lea rax, [rbp-17] ; 重新加载对象地址到rax 23 mov rdi, rax ; 将对象地址作为参数传递给析构函数 24 call MyClass::~MyClass() [complete object destructor] ; 调用MyClass的析构函数清理对象 25 mov eax, ebx ; 将返回值(0)从ebx移动到eax作为main函数的返回值 26 mov rbx, QWORD PTR [rbp-8] ; 恢复之前保存的rbx值 27 leave ; 恢复栈帧 28 ret ; 从main函数返回，返回值在eax中 可以看到开启 ROV 优化后，确实是先在 main 函数的栈空间 先初始化 MyClass 的对象，所以可以避免在 return 时拷贝。\nRVO 的核心思想是：编译器在生成代码时，识别出函数返回的对象可以直接在调用者的目标位置构造，而不是先在函数栈上构造然后拷贝或移动到调用者。\n在 C++17 之前，RVO 是一种编译器可选的优化，程序员不能完全依赖它。从 C++17 开始，标准对某些情况下的返回值优化做了强制要求，称为 Mandatory Copy Elision（强制拷贝消除）。这意味着在特定场景下，即使禁用优化，编译器也必须消除拷贝或移动。\nRVO 和 std::move 的关系 一般来说，使用了 move 后就不会再使用 RVO 了\n1MyClass create() { 2 MyClass obj; 3 return std::move(obj); // 显式移动 4} 改一下上面的例子，开启 ROV优化看一下\nclang++ -O3 -o main main.cpp 编译 执行 main\n输出：\n1Constructor 2Move constructor 3Destructor 4Destructor 所以，在编写现代C++代码时，在 return 局部变量时没有必要使用 std::move,使用了大概率会影响编译器优化，反而会适得其反，性能更差了。\n所以相信编译器，很多情况下，编译器会比人更 ‘聪明’。\n总结 std::move 不会改变对象的内容(不会移动)，只是欺骗了编译器 std::move 只是请求移动，能否真正移动取决于目标类型是否实现了移动构造函数或移动赋值运算符。如果没有，编译器会回退到拷贝 左值：调用拷贝构造函数，右值: 如果有移动构造函数，优先调用移动构造函数；否则回退到拷贝构造函数 std::forward 有条件地转发参数，保留其原始值类别（左值或右值） 函数返回一个对象时，除非需要显示调用移动或者拷贝构造，否则不要使用 std::move，而是使用编译器的 RVO 优化 ","date":"2025-03-16T19:50:55+08:00","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/7320b79a5cd9f9ac9e07752081db9612e98ca223.jpg","permalink":"https://lqxhub.github.io/posts/14155cf4/","title":"C++中的移动语义与完美转发，C++中的右值引用、std::move和std::forward的使用方法及其实现原理，结合实例讲解RVO"},{"content":"在C++11及以后的版本中，可以将变量简单的分为左值，右值。其中右值又可以分为纯右值和将亡值。 不同类型的变量的生命周期与作用域也是有差别的，这次就来浅谈一下C++中变量的生命周期。\n事情的起因是最近在修一个C++的bug时，发现是因为变量的生命周期问题导致的，所以就来总结一下。\n提交的PR\n代码位置\nbug分析 有bug的代码如下：\n1HashesMetaValue tmf_meta_value2(DataType::kHashes, std::string(str, sizeof(int32_t))); 1using HashesMetaValue = BaseMetaValue; 2 3class BaseMetaValue : public InternalValue { 4 public: 5 explicit BaseMetaValue(DataType type, const Slice\u0026amp; user_value) : InternalValue(type, user_value) {} 6 ................... 7}; 可以看到，BaseMetaValue的构造函数接受的是const Slice\u0026amp;类型的参数， 而std::string(str, sizeof(int32_t))是一个临时变量，是一个右值(将亡值)， 所以这个临时变量的生命周期只在这一行代码中，当这一行代码执行完后，这个临时变量就会被销毁， 所以tmf_meta_value2的user_value就是一个悬空指针，所以在后面的代码中就会出现问题。\nSlice 是一个类似于std::string_view的类，Slice不拥有数据，只是一个指向数据的指针。所以必须由调用者保证数据的生命周期。\n解决方法也很简单，将BaseMetaValue的构造函数改为接受std::string类型的参数即可。\n1auto key = std::string(str, sizeof(int32_t)); 2HashesMetaValue tmf_meta_value1(DataType::kHashes, key); 这样key就是一个左值，生命周期会持续到tmf_meta_value1的生命周期结束。所以就不会出现悬空指针的问题了。\nC++中没有严格限制变量的生命周期，我没有系统的学习过rust，但是了解过rust的一些概念，rust中有严格的生命周期检查，这样就可以避免很多悬空指针的问题， 上述的bug在rust中是不会出现的。因为rust中有严格的变量所有权的，生命周期检查。 所有权 这个概念在rust中是非常重要，我觉得这个概念在C++中也是很重要的， 想要写出高质量的代码，就需要了解这所有权这个概念。\n左值、右值 左值 最简单的一个例子就是变量，变量是一个左值，它有一个内存地址，可以取地址，可以修改。\n1int a = 10; // a 是左值 2int* p = \u0026amp;a; // 可以取 a 的地址 3a = 20; // a 可以被赋值 右值 右值是指不能取地址的临时对象或值，通常是短暂存在的（ephemeral），无法出现在赋值语句的左侧。\n1int b = 5 + 3; // 5 + 3 是右值（纯右值） 其中右值又可以分为纯右值和将亡值。\n纯右值 特性：没有身份，无法取地址，无法被赋值\n常见的 字面量、临时对象、函数返回值\n142; // 字面量是纯右值 25 + 3; // 计算结果是纯右值 3std::string(\u0026#34;hello\u0026#34;); // 构造函数返回的临时对象是纯右值 将亡值 将亡值是“即将消亡的值”，通常是通过右值引用绑定到的临时对象，或者被显式移动（move）的对象。\n特性：有身份（可以取地址），但生命周期即将结束\n通常出现在使用 std::move 或函数返回右值引用的场景\n1#include \u0026lt;utility\u0026gt; 2int\u0026amp;\u0026amp; getRvalue() { return 42; } 3int main() { 4 int a = 10; 5 int\u0026amp;\u0026amp; r1 = std::move(a); // std::move(a) 是将亡值 6 int\u0026amp;\u0026amp; r2 = getRvalue(); // getRvalue() 返回的临时对象是将亡值 7} 变量的生命周期 左值 左值的生命周期由存储期决定，通常是持久的，可以控制。比如局部变量，离开作用域后会被销毁。 动态分配的内存也是左值，需要手动释放。\n1void example() { 2 int a = 10; // 左值 a，自动存储期，离开作用域销毁 3 static int b = 20; // 左值 b，静态存储期，程序结束销毁 4 int* p = new int(30); // 左值 *p，动态存储期，直到 delete 5 delete p; 6} a 的生命周期从定义到函数结束。 b 的生命周期贯穿整个程序。 p 的生命周期从 new 到 delete。 右值 纯右值：生命周期短暂，表达式结束后销毁，一旦表达式求值完成，纯右值要么被销毁，要么被用于初始化其他对象 1int main() { 2 5 + 3; // 纯右值，表达式结束后销毁 3 std::string s = std::string(\u0026#34;hello\u0026#34;); // 临时对象是纯右值，构造 s 后销毁 4 const int\u0026amp; ref = 42; // 纯右值 42 的生命周期延长到 ref 的作用域结束 5} 将亡值：生命周期取决于底层对象，通常是短暂的，或者可以被转移，可以通过右值引用绑定延长生命周期 1std::string\u0026amp;\u0026amp; rvalue = std::move(str); // str 是将亡值，通过 std::move 转为右值引用，延长生命周期 声明周期的延长 绑定到常量左值引用 const \u0026amp; 当纯右值绑定到 const T\u0026amp; 时，临时对象的生命周期延长到引用的作用域结束。 1const std::string\u0026amp; str = std::string(\u0026#34;temp\u0026#34;); // str 有效直到作用域结束 绑定到右值引用\u0026amp;\u0026amp; 当右值（纯右值或将亡值）绑定到 T\u0026amp;\u0026amp; 时，临时对象的生命周期延长到右值引用的作用域结束。 1std::string\u0026amp;\u0026amp; str = std::string(\u0026#34;temp\u0026#34;); // str 有效直到作用域结束 值类别 生命周期特点 是否可延长生命周期 示例场景 左值 (lvalue) 由存储期决定，持久且可控 不需要延长，本身持久 局部变量、全局变量 纯右值 (prvalue) 临时，表达式结束后销毁 可通过 const \u0026amp; 延长 字面量、临时对象 将亡值 (xvalue) 取决于底层对象，通常短暂或可转移 可通过 \u0026amp;\u0026amp; 绑定延长 std::move、函数返回右值引用 左值引用、右值引用 单纯的左值和右值其实还是好理解的，但是结合C++中的引用，就会有一些特殊的情况，比如右值引用绑定到左值， 右值引用绑定到右值等等，这些情况就需要我们去了解C++中的引用的特性。\n左值引用 先来看一下最简单的左值引用，我的理解，左值引用可以理解为一个别名，它是一个左值，可以取地址，可以修改，可以看做是一种简化的指针。\n1int a = 42; 2int\u0026amp; ref = a; // 左值引用，绑定到左值 3ref = 100; // 修改ref实际上就是修改a 左值引用中，还有一个特殊的情况，就是 const 左值引用，它可以绑定到右值，但是不能修改。\n1const int\u0026amp; ref = 42; // const 左值引用，绑定到右值 const 类型的左值引用，常用在函数的参数中，可以接受左值和右值。\n1void func(const int\u0026amp; ref) { 2 // ref 可以绑定到左值或右值 3} 4 5int main() { 6 int a = 42; 7 func(a); // a 是左值 8 func(42); // 42 是右值 9} 为什么 const 左值引用可以绑定到右值呢？因为右值是临时的，不会被修改，const修饰的变量是不可以修改的， 所以可以绑定到const左值引用。\n右值引用 右值引用是C++11引入的新特性，它是一个新的引用类型，用于绑定到右值。\n1int\u0026amp;\u0026amp; rref = 100; // 右值引用，绑定到右值 2int x = 101； 3rref = x; // 错误，右值引用不能绑定到左值 右值引用有容易迷惑的地方，比如一个函数的参数是右值引用，但是这个右值在函数调用时是左值。\n1void func(int\u0026amp;\u0026amp; ref) { 2 // ref 是右值引用, 但是在函数调用时是左值 3 ref = 100; // 可以修改 4} 两种引用在函数调用时的区别：\n1void func1(int\u0026amp; ref) { 2 // ref 是左值引用 3} 4 5void func2(int\u0026amp;\u0026amp; ref) { 6 // ref 是右值引用 7} 8 9void func3(const int\u0026amp; ref) { 10 // ref 是 const 左值引用 11} 12 13int main() { 14 int a = 100; 15 func1(a); // 正确 a 是左值 16 func1(101); // 错误 101 是右值 17 func2(102); // 正确 102 是右值 18 func2(a); // 错误 a 是左值 19 func3(a); // 正确 a 是左值 20 func3(103); // 正确 103 是右值 21} 引用折叠 引用折叠是C++11引入的新特性，也可以叫万能引用，用于简化引用的使用，主要用于模板的参数推导。 主要用在模板的参数推导中，当一个模板参数是引用时，引用折叠规则会决定最终的引用类型。\nC++11引入右值引用 T\u0026amp;\u0026amp; 后，允许绑定到右值，同时在模板中可能出现复杂的类型推导情况，例如：\nT\u0026amp; \u0026amp; T\u0026amp; \u0026amp;\u0026amp; T\u0026amp;\u0026amp; \u0026amp; T\u0026amp;\u0026amp; \u0026amp;\u0026amp; 为了简化模板参数推导，引入了引用折叠规则：\n引用折叠规则：\nT\u0026amp; \u0026amp; -\u0026gt; T\u0026amp; T\u0026amp; \u0026amp;\u0026amp; -\u0026gt; T\u0026amp; T\u0026amp;\u0026amp; \u0026amp; -\u0026gt; T\u0026amp; T\u0026amp;\u0026amp; \u0026amp;\u0026amp; -\u0026gt; T\u0026amp;\u0026amp; 简单来说,左值引用 \u0026amp; 具有优先级，只要组合中出现左值引用，最终结果就是左值引用。 右值引用 \u0026amp;\u0026amp; 只有在没有左值引用的情况下才会保留。\n1template\u0026lt;typename T\u0026gt; 2void func(T\u0026amp;\u0026amp; param) { 3 // param 的类型取决于传入的值类别 4} 5 6int main() { 7 int x = 100; 8 func(x); // T 推导为 int\u0026amp;，T\u0026amp;\u0026amp; 折叠为 int\u0026amp; 9 func(101); // T 推导为 int，T\u0026amp;\u0026amp; 保持为 int\u0026amp;\u0026amp; 10} 当传入左值x时，T推导为int\u0026amp;，T\u0026amp;\u0026amp;变成int\u0026amp; \u0026amp;\u0026amp;，折叠为int\u0026amp;。 当传入右值101时，T推导为int，T\u0026amp;\u0026amp;保持为int\u0026amp;\u0026amp;。 引用折叠生效的一个前提是模板参数要发生类型推导，如果模板参数是明确的类型，引用折叠规则不会生效。\n1template\u0026lt;typename T\u0026gt; 2void func(std::vector\u0026lt;T\u0026gt;\u0026amp;\u0026amp; param); // 普通右值引用，只能绑定右值 1template \u0026lt;typename T\u0026gt; 2class A 3{ 4public: 5 void push(T\u0026amp;\u0026amp; t) 6 { 7 data_.push_back(std::forward\u0026lt;T\u0026gt;(t)); 8 } 9 10private: 11 std::vector\u0026lt;T\u0026gt; data_; 12}; 13 14int main() { 15 A\u0026lt;int\u0026gt; a; 16 // int x = 100; 17 // a.push(x); // 编译错误：左值不能绑定到右值引用 18 a.push(101); // 正确：右值 19 return 0; 20} 这里的 T\u0026amp;\u0026amp; 是一个右值引用，但是在模板参数推导时，会根据传入的参数类型来决定最终的引用类型。 因为在初始化 A 类时，T 的类型已经确定了，所以 T\u0026amp;\u0026amp; 不会发生引用折叠。\n改进\n1template \u0026lt;typename T\u0026gt; 2class A 3{ 4public: 5 template \u0026lt;typename U\u0026gt; 6 void push(U\u0026amp;\u0026amp; u) 7 { 8 data_.push_back(std::forward\u0026lt;U\u0026gt;(u)); 9 } 10 11private: 12 std::vector\u0026lt;T\u0026gt; data_; 13}; 14int main() { 15 A\u0026lt;int\u0026gt; a; 16 int x = 100; 17 a.push(x); 18 a.push(101); 19 return 0; 20} 这里的 U\u0026amp;\u0026amp; 是一个万能引用，它会根据传入的参数类型来决定最终的引用类型，所以可以正确的推导出左值和右值。\n总结 C++中的变量可以分为左值和右值，右值又可以分为纯右值和将亡值。不同类型的变量的生命周期与作用域也是有差别的。\n简单说有明确变量名，可以取地址，可以修改的是左值，没有明确变量名，不能取地址，不能修改的是右值。\n左值和右值配合引用，可以更好的控制变量的生命周期，同时也会带来一些特殊的情况，比如引用折叠。\n左值引用：左值引用是一个别名，它是一个左值，可以取地址，可以修改。作为函数参数时，只能绑定左值。 const 左值引用：可以绑定到右值，但是不能修改。 右值引用：右值引用是一个新的引用类型，用于绑定到右值。作为函数参数时，只能绑定右值。 引用折叠：引用折叠是C++11引入的新特性，用于简化引用的使用，主要用于模板的参数推导。只有在发生类型推导时才会生效。 左值引用和右值引用，应该要配合 std::move 和 std::forward 使用，这样可以更好的控制变量的生命周期。 这里先挖一个坑，后面有空再来聊这部分内容。\n","date":"2025-03-09T18:01:29+08:00","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/0677f36b25f64ef20bd9b0ff4317dee12d1c8c4e.jpg","permalink":"https://lqxhub.github.io/posts/567e834f/","title":"C++变量生命周期，结左值引用和右值引用，引用折叠，这次就来浅谈一下C++中变量的生命周期 - QX's blog"},{"content":"go自带的链表是没有排序功能的，而且也不支持泛型。不支持泛型还好说，使用 interface{} 就能解决。但是很多时候还是有对 list 排序的需求。 之前在公司内部，我写过一个 list 的排序，因为list内部的很多数据都是 private 的，所以没法使用归并排序，只能使用类插入排序。 在数据量不大的情况下，这种排序是可以接受的。但是如果数据量很大，这种排序就会很慢，所以这次我使用归并排序来实现排序，并且使用泛型来实现。\n链表的归并排序，之前写过一次，这次就不再赘述了归并排序\n关于 go 的泛型，之前也写过一篇文章go泛型\n这次写的 支持 泛型 和 排序 的 GitHub 地址：listplus\n这次简单讲解一下 go 自带的 list 的一些源码。\nlist源码 list 源码还是很简单的，就是一个双向链表，就挑几个函数学一下吧\nelement 1type Element struct { 2 next, prev *Element 3 list *List 4 Value any 5} 为什么要写 Element 这个结构体呢，是因为这里面存了 list 的指针。这个指针主要用来判断要操作的 element 是否属于这个 list。 一般自己在写链表的时候,很少这样写。多了这个指针，可以避免很多错误。比如把 A 链表中的元素插入到 B 链表中，这样就会出现问题。\n剩下的 next 和 prev 就是链表的前后指针了，Value 就是存放数据的地方。 any 在 go 1.18 之后才有的，之前都是用 interface{} 来代替。\nlist 1type List struct { 2 root Element 3 len int 4} 这个结构就是链表的结构了，root 是一个 Element 结构体，这个 Element 结构体是一个哨兵，不存放数据，只是用来标记链表的头和尾。\nroot 的 next 指向链表的第一个元素，prev 指向链表的最后一个元素。\nlen 是链表的长度。\ninsert 1func (l *List) insert(e, at *Element) *Element { 2\te.prev = at 3\te.next = at.next 4\te.prev.next = e 5\te.next.prev = e 6\te.list = l 7\tl.len++ 8\treturn e 9} PushBack 和 PushFront 都是调用这个函数来插入元素的。\n这个函数也挺简单的，就是把 e 插入到 at 后面。逻辑也很简单，就是设置一下 e 和 at 的指针。然后把新插入的元素的 list 指针指向这个链表，最后链表的长度加一。 最后 return e，这个 e 就是新插入的元素。\n在 PushBack 中，at 就是 root.prev，在 PushFront 中，at 就是 root。\nremove 1func (l *List) remove(e *Element) { 2\te.prev.next = e.next 3\te.next.prev = e.prev 4\te.next = nil // avoid memory leaks 5\te.prev = nil // avoid memory leaks 6\te.list = nil 7\tl.len-- 8} remove 函数就是调用这个函数来删除元素的。逻辑也很简单，就是把 e 从链表中删除。双向链表的删除，就是把 e 的前后指针指向对方，然后把 e 的 list 指针置空，最后链表的长度减一。\n链表中删除一个元素，首先要找到这个元素，然后调用这个函数来删除。虽然链表删除的时间复杂度是 O(1)，但是找到这个元素的时间复杂度是 O(n)。\nmove 1func (l *List) move(e, at *Element) { 2\tif e == at { 3\treturn 4\t} 5\te.prev.next = e.next 6\te.next.prev = e.prev 7 8\te.prev = at 9\te.next = at.next 10\te.prev.next = e 11\te.next.prev = e 12} move 函数就是调用这个函数来移动元素的。逻辑也很简单，就是把 e 移动到 at 后面。先把 e 从链表中 ‘删除’，然后把 e 插入到 at 后面。 所谓的删除就是 e 的前后指针指向对方。\ngo 的 list 中还有很多函数，这里就不一一列举了，但是对链表的核心操作就是这几个函数。\nlistplus 下面是我修改后的 list 的部分代码，整体逻辑没改，就是加了泛型支持，然后再加了排序功能。 就只列举一下 sort 函数吧\n1func (l *List[T]) Sort(compare func(front, back T) bool) { 2\tif l.len \u0026lt; 2 {//如果链表长度是0或者1，直接返回 3\treturn 4\t} 5\thead := l.Front() 6\ttail := l.Back() 7\ttail.next = nil 8 //取出链表的头和尾，然后调用归并排序 9\thead, tail = l.mergeSort(head, compare) 10\t//这里是把排序后的链表重新连接起来 11\tl.root.next = head 12\tl.root.prev = tail 13\thead.prev = \u0026amp;l.root 14\ttail.next = \u0026amp;l.root 15} 16 17func (l *List[T]) mergeSort(head *Element[T], compare func(front, back T) bool) (*Element[T], *Element[T]) { 18\tif head == nil || head.next == nil { 19\treturn head, head 20\t} 21\tslow, fast := head, head 22\t//使用快慢指针找到链表的中间节点 23\tfor fast.next != nil \u0026amp;\u0026amp; fast.next.next != nil { 24\tslow = slow.next 25\tfast = fast.next.next 26\t} 27\tmid := slow.next 28\tslow.next = nil//截断链表,因为下面的操作只会用 next指针,所以不用截断 prev指针 29 30\th1, t1 := l.mergeSort(head, compare) 31\th2, t2 := l.mergeSort(mid, compare) 32\treturn l.merge(h1, t1, h2, t2, compare) 33} 34 35func (l *List[T]) merge(h1, t1, h2, t2 *Element[T], compare func(front, back T) bool) (*Element[T], *Element[T]) { 36\t//合并两个链表,然后返回合并后的头和尾 37\t//和单向链表的合并不同的是,这里需要维护 prev指针 38\tcur := \u0026amp;l.root 39\tfor h1 != nil \u0026amp;\u0026amp; h2 != nil { 40\tif compare(h1.Value, h2.Value) { 41\tcur.next = h1 42\th1.prev = cur 43\th1 = h1.next 44\t} else { 45\tcur.next = h2 46\th2.prev = cur 47\th2 = h2.next 48\t} 49\tcur = cur.next 50\t} 51\tif h1 != nil { 52\tcur.next = h1 53\th1.prev = cur 54\tcur = t1 55\t} else { 56\tcur.next = h2 57\th2.prev = cur 58\tcur = t2 59\t} 60\treturn l.root.next, cur 61} 整体和以前写的链表排序差不多，不同的地方是这次是双向链表，所以需要维护 prev 指针。\n一开始我是没有维护 prev 指针的，完全按照单向链表的思路来 merge，只是在 merge 完一个链表后，需要继续merge 另一个链表，重新组织链表的结构。\nmerge函数：\n1func (l *List) merge(l1, l2 *Element, compare func(v1, v2 any) bool) *Element { 2\tcur := \u0026amp;l.root 3\tfor l1 != nil \u0026amp;\u0026amp; l2 != nil { 4\tif compare(l1.Value, l2.Value) { 5\tcur.next = l1 6\tl1.prev = cur 7\tl1 = l1.next 8\t} else { 9\tcur.next = l2 10\tl2.prev = cur 11\tl2 = l2.next 12\t} 13\tcur = cur.next 14\t} 15\tif l1 != nil { 16\tcur.next = l1 17\tl1.prev = cur 18\t} else { 19\tcur.next = l2 20\tl2.prev = cur 21\t} 22\tfor cur.next != nil { 23\tcur.next.prev = cur 24\tcur = cur.next 25\t} 26\tl.root.prev = cur 27\treturn l.root.next 28} 前半部分和这次的 merge 函数差不多，后面多了一个循环，是为了维护 prev 指针。\n后来考虑到这部分是可以优化的，每次merge的时候，传递每个链表的 head 和 tail，这样就不用在merge完一个链表后，继续merge 另一个链表了。\n这样就可以直接返回 head 和 tail，然后在 Sort 函数中重新连接链表。\n整体还是比较简单的，就是不知的为什么 go 的 list 没有排序功能，这个功能还是很常用的。泛型都出了这么多年了，go 的 list 还是没有泛型。\n性能 归并排序的时间复杂度是 O(nlogn)，比之前写的插入排序要快很多。但是 归并排序是基于递归的，需要额外的空间的，空间复杂度是 O(n)。\n在数据量很大的时候，这个空间复杂度是很大的，所以在数据量很大的时候，还是要考虑一下。\n原来想借鉴一下 go 的 sort 包，但是发现 go 的 sort 中的一些思想，比如 当数据量小于 12 的时候，使用插入排序，但是链表的长度统计不像切片那么方便，所以就没有实现。\n还有就是在递归层数达到一定值的时候，使用别的排序算法，防止栈溢出。但是计算了一下\n$ {log}_{2}1000000 = 19.931568569324174 $\n链表的长度达到 1000000 的时候，递归层数也就 20 层，这个层数是可以接受的。\n总结 这次实现了一个支持泛型和排序的链表，主要是为了学习 go 的泛型和链表的一些操作。链表的排序还是比较简单的，但是链表的排序还是比较少见的，一般都是使用切片来排序。 文中如果有错误的地方，还请指正。如果对 go 的泛型和链表有更好的想法，欢迎在 GitHub 上提出。\n","date":"2025-01-12T12:26:34+08:00","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/def9654de08c79035495f70fa24c7a388b4cc883.jpg","permalink":"https://lqxhub.github.io/posts/db59b241/","title":"Go支持泛型和排序的list，实现一个支持泛型和排序功能的链表。通过归并排序算法为链表添加排序功能的实现过程，对比插入排序的实现方式"},{"content":"时间真的是如白驹过隙，上次写2023年的总结已经是一年前的事情了，但是总感觉好像就是前几天的事情，也在在这个房间里，也是这台电脑。一切都好像没有变过，但是时间却在不停的流逝。 2024这一年，咋说呢，想不到一个词来形容。原来不想写了，可是以前立了个flag，每年都写，就还是写一下吧。\n老传统 还是从 生活 与 工作 两方面来写吧\n生活 这一年最大的变化就是开始骑车了，虽然不是每天骑，但是也算是养成了一个习惯。通过骑车，一年瘦了差不多10公斤，还看到了一些以前没有看过的风景。也认识了很多新的朋友，也有了一些新的经历。 现在已经喜欢上骑车了，每周不骑车都会觉得少了点什么，骑车后游戏也戒了，基本不玩了，以前周末没事喜欢懒在家里，现在周末都会出去骑车，感觉生活变得充实了很多。\n骑车后认识了很多新的朋友 今年还去太湖东西山骑了一次，也是第一次去，感觉还是不错的，风景也很美，也是一次很好的经历。原来计划中秋放假去环太湖，因为来台风了，就取消了，明年一定要去。 今年的骑行数据，明年继续努力 去年写总结时计划去玩的地方，今年一个没去，基本都是时间不够。今年基本都是在附近的地方，南京去了好几次，春天和同学去看了一次樱花。确实很美，但是人也很多。 和同学边走边聊，感觉很好。 最神奇的是，这次去南京，找吃的时候，又去了大学时和另一个同学去过的一家餐厅。第一次去应该是2016年，那时候是去南京参加比赛，和一个大学室友，俩人都是第一去南京。 那时候还有没有小红书这样的软件，俩人就网上随便搜，瞎逛，找到了狮子桥那里，看到那家餐厅，就进去吃了。那时候没觉得有多美好吃。没想到这两年那里成立网红打卡地了，人也超级多。 买个饭都要排好久。这次我去路过那家餐厅，看着招牌很眼熟，就拍下来发给那个同学，问他这是不是咱俩之前去吃过的那家餐厅，他说是。感觉很神奇，这么多年了，又来到了这里。\n这次去南京还一件有意思的事。两个人吃完饭去中山陵的路上，我同学想去厕所了，我一看快到新街口了，于是就去德基广场那吧，别的地方也不好找。好家伙，第一次见识到了厕所也成了网红打卡地。\n还一次去南京是中秋放假，原来计划去环太湖，因为来台风了，就取消了。正好有个高中同学在南京出差，还一个同学在杭州，也是闲着没事，于是三人相约在南京见面。没想到去南京玩的人很多，想去玩的地方都没预约到。 虽然玩没玩成，但是吃的还是吃了不少，南京的美食还是很多的。\n6月份还去了一次济南，见到了另一个大学同学，也是很久没见了。这次去济南一开始是找一个小学初中的同学，虽然老家距离不远，但是一年基本也就过年的时候能见一次。 虽然我是山东人，但是济南没怎么去玩过，以前去基本都是有事，这次去济南，感觉还是不错的，济南的泉水还是很有名的，还有很多好吃的。 后来又想起了，另一个大学同学也在济南，于是就又约了一次。\n这次去济南，顺路又去爬了一次泰山。夜爬泰山的感觉还是很不错的，虽然很累，但是看到日出的那一刻，感觉所有的辛苦都是值得的。\n这次爬泰山，之前骑车的好处就体现出来了，爬山的时候一路基本都是超越别人，也没有感觉很累，也没有感觉很难。从红门开始，一口气爬到中天门，喝了点水，休息了一下，然后就一口气爬到了南天门。\n这速度我自己还是挺满意的。\n这一年，生活好像也没有什么大的变化，但是也有很多小的变化。以前周末基本都是在家里，现在周末都会出去骑车，感觉生活变得充实了很多。别的好像也没什么变化，还是一个人在这城市中。\n工作 这一年工作也算是比较忙，事情挺多的。整体看下来，也算是在工作和生活中找到了一个平衡点。工作这么多年了，很多事情处理起来也算是比较得心应手，\n今年在工作上算是没有遇到大的困难。 今年有几次线上测试，这也是我负责后，第一次经历线上测试。测试中不出意外的出意外了。好在也没出大的问题，也算是顺利通过了。\n经历了半夜被叫起来查bug，好在最后发现不是重要的问题，服务没有挂掉，只需要后面修复就行了。每次测试都能发现一些问题，也算是一次很好的经历。早发现问题比晚发现问题要好很多。\n今年工作上也没有什么大的变化，还是在原来的公司，还是在原来的岗位。可能是时间久了，很多事情处理起来也算是比较得心应手，也没有什么大的困难。就一笔带过吧。\n开源社区 自从接触了开源社区，基本平时有空就会参与一下。今年也是参与了一些开源项目，也是有一些收获。在社区里认识了很多朋友，也学到了很多东西。\n今年的commit次数和去年相比，也差不多吧\n好像也没什么好说的了，就这样吧。2025继续参与。\nother 这里就想到什么就写什么吧。\n原来计划今年要读一些书，但是最后也没读几本，年初的时候一口气看了好多，后面开始骑车了，看书的时间就少了。明年继续努力吧。\n只有《长安的荔枝》和《太白金星有点烦》这两本书看完了，其他的都没看完，明年继续读。 读了这两本书后，越来越喜欢马伯庸了，写的东西很有意思。听说《长安的荔枝》要拍电视剧了，期待一下。\n今年技术文章写的更少了，有时候没找到好的技术点，不知道写什么。有几次想写 redis 源码的解读，但是这方面的文章太多了，也没什么新意，就一直没写。\n最近天冷了，基本不怎么骑车了。玩了一下 赛博朋克2077，开始思考一个问题，未来科技是否真的能发展到游戏里那样，人类是否真的能实现意识的永生。 不知道马斯克的 neuralink 会不会实现，如果实现了，人类的未来会是什么样子。能不能像游戏里那样，人类的意识可以永生，可以在不同的机器人身上转移。 如果真的实现了，会不会给这个世界带来更多的问题，人类的意识永生，会不会导致人类的灭亡。\n老生常谈的事情，今年还是一个人，明年继续努力吧。\n2025 2025年，继续在一些方面尝试突破自己，像是今年的骑车，算是一个很好的尝试，认识了很多新的朋友，也有了一些新的经历，也看到了一些以前没有看过的风景。\n至于目标啥的也别定了，自己啥执行力自己也清楚，努力过好每一天。\nGood luck next year\n","date":"2024-12-31T18:25:29+08:00","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/83e38256ec22b91652d36e1d8b6f5397a55d5dbc.jpg","permalink":"https://lqxhub.github.io/posts/0893a8b9/","title":"我的2024"},{"content":"最近，我将我的博客从Hexo迁移到了Hugo。起因是最近在查资料的时候，发现了一个很好看的博客，看到是用Hugo生成的，于是就萌生了从Hexo迁移到护国的想法。 Hexo其实也挺好用的，当时我自建blog的时候，就已经有Hugo了，但是当时Hugo的资料不多，于是就选了了Hexo。这是想要换到Hugo，主要是看中了 Hugo中 Stack 这个主题。 还一个原因是我不喜欢Hexo使用 Node.js。我一个写后端的，平时也用不到Node，而且对 npm 的命令也不熟悉，总之用起来就很别扭。 Hugo还一个优点是构建的速度比Hexo快得多，当然我目前使用Hexo还没有在构建上花费太多时间。好了闲话就说到这里把，下面我将分享一些关于如何将Hexo迁移到Hugo的经验。\n在开始之前，需要先下载Hugo，可以去GitHub下载。下载的时候，需要根据自己的系统选择对应的版本，下载的时候记得下载 extended 的版本。 这是支持 SCSS 和 PostCSS 的版本。 下载完成后，解压到一个目录，然后将解压后的目录添加到环境变量中。 安装完成后，可以通过 hugo version 命令查看是否安装成功。\n我将分 Hugo配置 和 自定义 这两个部分来讲。\nHugo配置 因为 Hugo 中，很多目录在 项目目录 和 themes（主题） 目录下都有，所以在介绍的时候，没有特殊说明都是在 项目目录 下。\nHugo配置文件 Hugo配置文件支持多种格式，比如 toml、yaml、json。我选择的是 yaml 格式。Hugo的配置文件是 根目录的config.yaml\n下面根据层级来介绍一下Hugo的配置文件\n这是根层的配置，主要是一些基本的配置，比如网站的基础URL、网站的语言、默认的内容语言、使用的主题、每页显示多少文章、网站的标题等。\n1baseurl: https://lqxhub.github.io # 网站的基础URL 2languageCode: zh-cn # 网站的语言 3defaultContentLanguage: \u0026#34;zh-cn\u0026#34; # 默认的内容语言 4theme: hugo-theme-stack # 使用的主题 5paginate: 10 # 每页显示多少文章 6title: \u0026#34;QX 的笔记\u0026#34; # 网站的标题 7hasCJKLanguage: true # 是否使用CJK语言,用到中文的时候需要设置为true 8summaryLength: 200 # 摘要的长度 9enablePermalinks: true # 启用永久链接 10enableEmoji: true # 开启 Emoji 支持 11enableInlineShortcodes: true # 开启内联 Shortcodes 支持 12noTimes: false # 同步文件的修改时间。 这些配置没有什么好说的，就是一些基本的配置，根据自己的需求来配置就好。\n1permalinks: 2 post: /posts/:slug/ # 文章的永久链接 3 page: /:slug/ # 页面的永久链接 这个配置是文章和页面的永久链接，文章的永久链接是 /posts/:slug/，页面的永久链接是 /:slug/。 这里的 :slug 是文章生成的 hash 值，因为我再Hexo中的文章的 hash值，所以这里也使用 hash值。 后面在构建的时候，页面的 URL 格式是 baseurl/posts/slug。比如这篇文章的 URL 是 https://lqxhub.github.io/posts/a660c9b1/。\n1params: 2 mainSections: # 首页从哪些部分获取文章 3 - post 4 dateFormat: # 日期格式,必须是符合 Go 语言的日期格式 5 published: Jan 02, 2006 # 发布日期 6 lastUpdated: Jan 02, 2006 15:04 MST # 最后更新日期 7 8 footer: # 页脚的配置 9 enable: true # 是否启用页脚 10 since: 2021 # 网站创建年份 11 customText: \u0026#34;© QX\u0026#34; # 页脚的自定义文本 12 copyright: true # 是否显示版权信息 13 author: true # 是否显示作者信息 14 15 favicon: icons/favicon.ico # 浏览器 Tab 页的网站图标 16 sidebar: # 侧边栏的配置 17 emoji: 😉 18 subtitle: \u0026#34;雄关漫道真如铁，而今迈步从头越\u0026#34; 19 avatar: # 作者头像 20 enabled: true 21 local: true 22 src: img/avatar.gif 23 24 featuredImageField: image # 文章的封面图片从哪个字段获取,这里是从image字段获取 25 rssFullContent: false # RSS 是否开启全内容 / false 则为只有摘要 26 27 article: # 文章的配置 28 headingAnchor: true # 是否开启标题锚点 29 math: true # 这里关闭是因为我们使用的是 MathJax 30 toc: false # TOC 文章也右边的导航 31 readingTime: true # 阅读时间 32 license: # 文章的版权信息 33 enabled: true # 是否启用版权信息 34 default: \u0026#39;Licensed under CC BY-NC-SA 4.0\u0026#39; # 默认的版权信息 35 36 widgets: # 网页中右边的小部件 37 homepage: # 首页的小部件 38 - type: search # 搜索框 39 - type: archives # 归档 40 params: 41 limit: 5 # 归档显示的数量 42 - type: categories # 分类 43 params: 44 limit: 10 # 分类显示的数量 45 - type: tag-cloud # 标签云 46 params: 47 limit: 10 # 标签云显示的数量 48 page: 49 - type: \u0026#34;toc\u0026#34; # TOC 文章也右边的导航 50 51 colorScheme: # 颜色主题 52 toggle: true # 是否显示切换按钮 53 # Available values: auto, light, dark 54 default: auto # 默认的颜色主题 这里配置项比较多，挑几个不好理解的来说一下。\n这部分就是 footer 配置对应图片应该能看懂，这里就不多说了。\n相关的配置都在图片里标注了\nsidebar 配置是侧边栏的配置，这里配置了作者的头像、作者的名字、作者的座右铭、作者的头像等。\nwidgets 配置是网页中右边的小部件，这里配置了首页的小部件，包括搜索框、归档、分类、标签等。有不想显示的，在配置中删除就行。\n下面是 mene 相关的配置\n1menu: 2 main: 3 - identifier: home 4 name: 首页 5 url: / 6 weight: -100 7 params: 8 newTab: false 9 icon: home 10 - identifier: categories 11 name: 分类 12 url: /categories 13 weight: 1 14 params: 15 newTab: false 16 icon: categories 17 social: 18 - identifier: email 19 name: Email 20 url: mailto:lqxlucky@qq.com 21 params: 22 newTab: true 23 icon: email 24 - identifier: github 25 name: GitHub 26 url: https://github.com/lqxhub 27 params: 28 newTab: true 29 icon: brand-github 这是精简后的，在图片中，sidebar 下面的是 social 的配置，再往下是 main 的配置。\n这里说一下 main 中的一些问题\nidentifier：标识符 name 菜单的名字 url 菜单的链接 weight 是权重，权重越小，菜单越靠前。 newTab 是否在新标签页打开 icon 菜单的图标 如果不需要自定义的话，直接配置就行了，在构建的时候，会自动生成菜单。一些 icon 可能主题中没有，需要自己添加，我再配置时有好几个没有找到， 我使用 chatGPT 生成了一些图标\n如果要自定义，那么需要在 content 目录下创建一个和 访问这个页面的 URL 同名的目录，然后在新建的目录下创建一个 _index.md 文件， 然后在 _index.md 文件中配置\n以 分类 为例，content/categories/_index.md 的配置如下：\n1--- 2title: \u0026#34;分类\u0026#34; 3license: false 4--- 这里主要是改一下 title，只有 网页的标题和 配置中的 name 相同时，在点击对应的菜单后，对应的菜单名才会高亮。\nsocial 都是常见的内容，这里就不多说了。\n页面渲染相关的配置：\n1markup: 2 defaultMarkdownHandler: goldmark 3 tableOfContents: # TOC 文章也右边的导航 4 ordered: true # 是否有序 5 startLevel: 2 # 从 2级标题开始 6 endLevel: 5 # 到 5级标题结束 7 highlight: # 代码高亮配置 8 codeFences: true # 是否启用代码块 9 guessSyntax: true # 是否猜测语法 10 lineNoStart: 1 # 代码块的起始行号 11 lineNos: true # 是否显示行号 12 lineNumbersInTable: false # 是否在表格中显示行号 13 noClasses: true # 是否不使用类 14 style: \u0026#34;dracula\u0026#34; # 代码块的样式 15 tabWidth: 4 # tab 的宽度 这部分也是比较好理解的，主要是代码高亮的配置，这里使用的是 dracula 主题。 不同主题的效果，可以去这里查看。\n页面中的配置 在每篇文章的 front matter 中，可以配置一些文章的信息，比如文章的标题、作者、日期、标签、分类等。 可以使用 yaml、toml 等，我使用的是 YAML 格式。 使用 --- 来分隔 是 yaml 格式的配置，使用 +++ 来分隔是 toml 格式的配置。\n1+++ 2date = 2024-10-20T17:31:37+08:00 3title = \u0026#34;Linux下使用iouring实现一个tcp服务\u0026#34; 4slug = \u0026#34;f0e9829c\u0026#34; 5categories = [\u0026#34;linux\u0026#34;, \u0026#34;C++\u0026#34;] 6tags = [\u0026#34;linux\u0026#34;, \u0026#34;iouring\u0026#34;, \u0026#34;tcp\u0026#34;, \u0026#34;C++\u0026#34;] 7description = \u0026#34;探索 Linux io_uring 异步 I/O 接口，通过 liburing 库实现高效 TCP 服务。本文深入 io_uring 的基础概念，包括 Submission Queue 和 Completion Queue，并通过示例代码演示如何初始化、提交 I/O 请求和处理完成事件。了解 io_uring 如何提升 I/O 密集型应用的性能，以及在实际部署中需要注意的错误处理和连接管理。\u0026#34; 8image = \u0026#34;https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/6a84474a44a97bccecbbc9c5a3b9f7aea2571c97.jpg\u0026#34; 9+++ 这里简单说一下\ndate 文章的日期，必须是 GO 语言的日期格式 title 文章的标题 slug 文章的永久链接 categories 文章的分类，可以有多个，Hugo在构建的时候，会自动生成分类的页面 tags 文章的标签，可以有多个，Hugo在构建的时候，会自动生成标签的页面 description 文章的描述，会在首页的文章列表中显示，也是 SEO 的一部分 image 文章的封面图片，会在首页的文章列表中显示 在说一下 分类 中的封面\n也就是图片中标注的部分，这个是分类的封面，如果不配置的话，会使用默认的封面，如果想要自定义的话，可以在 content/categories 目录下创建一个和 分类 同名的目录， 比如 content/categories/linux，然后在 linux 目录下创建一个 _index.md 文件，然后在 _index.md 文件中配置\n1--- 2title: \u0026#34;linux\u0026#34; 3slug: \u0026#34;linux\u0026#34; 4image: \u0026#34;https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/Linux.jpg\u0026#34; 5weight: 10 6--- 其中 image 就是分类的封面，weight 是权重，权重越小，分类越靠前。\n搜索 页面的配置，在添加了搜索页面的时候，需要在 content/search 目录下创建一个 index.md 文件，然后在 index.md 文件中配置\n1--- 2title: \u0026#34;搜索\u0026#34; 3layout: \u0026#34;search\u0026#34; 4outputs: 5 - \u0026#34;html\u0026#34; 6 - \u0026#34;json\u0026#34; 7sitemap: 8 priority: 0.1 9--- 如果没有配置 outputs 的话，搜索页中的搜索功能是无效的，这里配置了 html 和 json，这样就可以在搜索页中搜索文章了。\n1 2## 迁移到Hugo 3 4### 创建Hugo项目 5在迁移之前，需要先创建一个Hugo项目。在Hexo中，我们可以通过 `hexo init` 命令来创建一个Hexo项目。而在Hugo中，我们可以通过 `hugo new site` 命令来创建一个Hugo项目。 6 7```shell 8hugo new site blog public 是构建后生成的目录，也就是生成网站的根目录 content 目录是存放文章的目录， layouts 目录是存放模板的目录，static 目录是存放静态文件的目录， 这个目录的内容在构建时会直接复制到网站的根目录下。themes 目录是存放主题的目录。这些目录都是Hugo创建项目时自动生成的。 别的目录在后面用到的时候再介绍。\n迁移文章 在Hexo中，文章是存放在 source/_posts 目录下的，而在Hugo中，文章是存放在 content 目录下的。所以我们需要将Hexo中的文章迁移到Hugo中。\n我的习惯还是在 content 目录下创建一个 post 目录，然后将Hexo中的文章迁移到 post 目录下。迁移完成后，目录结构如下：\n然后把Hexo中的文章迁移到 post 目录下。这样就完成了文章的迁移。这时候，我们可以通过 hugo 命令来构建项目， 这时候大概率是构建失败的，因为我们还没有配置Hugo的配置文件。\n首先要解决的是 front matter 的问题，Hugo中的 date 必须是 Go 语言的日期格式，这里需要改成 Go 语言的日期格式。 在Hugo中，永久连接的是 slug，如果原来文章使用了永久连接，需要改一下。\n迁移图片 我的图片是使用的 GitHub 作为图床，所以图片的链接是 GitHub 的链接。不需要改动，直接使用就行。\n到这里，应该能成功构建出网站了，下面是一些自定义的内容。\n自定义Hugo 我使用的是 Stack 主题，这个主题是我在查资料的时候发现的，觉得挺好看的，所以就选择了这个主题。但是主题内一些东西没有，需要自己添加。\n这里先介绍一下Hugo加载文件的顺序，Hugo加载文件的顺序是 themes 目录下的文件优先级最高，然后是项目中 layouts 目录下的文件，最后是 archetypes 目录下的文件。\n如果项目中的 layouts 目录中有和 themes 目录中的文件同名的文件，那么项目中的文件会覆盖 themes 目录中的文件。这样我们就可以自定义主题了。\n自定义友链页 在 layouts/shortcodes 目录下创建一个 friends.html 文件，然后在 friends.html 文件中配置\n1 2{{- $css := resources.Get \u0026#34;extended/blank.css\u0026#34; }} 3{{- if $css }} 4{{- $css := $css | resources.ToCSS | resources.Minify }} 5\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{{ $css.RelPermalink }}\u0026#34;\u0026gt; 6{{- end }} 7 8{{- if .IsNamedParams -}} 9\u0026lt;a target=\u0026#34;_blank\u0026#34; href={{ .Get \u0026#34;url\u0026#34; }} title={{ .Get \u0026#34;name\u0026#34; }} class=\u0026#34;friendurl\u0026#34;\u0026gt; 10\u0026lt;div class=\u0026#34;frienddiv\u0026#34;\u0026gt; 11 \u0026lt;div class=\u0026#34;frienddivleft\u0026#34;\u0026gt; 12 \u0026lt;img class=\u0026#34;myfriend\u0026#34; src={{ .Get \u0026#34;logo\u0026#34; }} /\u0026gt; 13 \u0026lt;/div\u0026gt; 14 \u0026lt;div class=\u0026#34;frienddivright\u0026#34;\u0026gt; 15 \u0026lt;div class=\u0026#34;friendname\u0026#34;\u0026gt;{{- .Get \u0026#34;name\u0026#34; -}}\u0026lt;/div\u0026gt; 16 \u0026lt;div class=\u0026#34;friendinfo\u0026#34;\u0026gt;{{- .Get \u0026#34;word\u0026#34; -}}\u0026lt;/div\u0026gt; 17 \u0026lt;/div\u0026gt; 18\u0026lt;/div\u0026gt; 19\u0026lt;/a\u0026gt; 20{{- end }} 还需要在 assets/extented 目录下创建一个 blank.css 文件，然后在 blank.css 文件中自定义友链页面的样式。\n1.friendurl { 2 text-decoration: none !important; 3 color: black; 4 box-shadow: none !important; 5} 6 7.myfriend { 8 width: 56px !important; 9 height: 56px !important; 10 border-radius: 50%!important; 11 padding: 2px; 12 margin-top: 20px !important; 13 margin-left: 14px !important; 14 background-color: #fff; 15} 16 17.frienddiv { 18 overflow: auto; 19 height: 100px; 20 width: 49%; 21 display: inline-block !important; 22 border-radius: 5px; 23 background: none; 24 25 -webkit-transition: all ease-out 0.3s; 26 -moz-transition: all ease-out 0.3s; 27 -o-transition: all ease-out 0.3s; 28 transition: all ease-out 0.3s; 29} 30 31.dark .frienddiv:hover { 32 background: var(--code-bg); 33} 34 35.frienddiv:hover { 36 background: var(--theme); 37 transition: transform 1s; 38 webkit-transform: scale(1.1); 39 -moz-transform: scale(1.2); 40 -ms-transform: scale(1.2); 41 -o-transform: scale(1.2); 42 transform: scale(1.1); 43} 44 45.frienddiv:hover .frienddivleft img { 46 transition: 0.9s !important; 47 -webkit-transition: 0.9s !important; 48 -moz-transition: 0.9s !important; 49 -o-transition: 0.9s !important; 50 -ms-transition: 0.9s !important; 51 transform: rotate(360deg) !important; 52 -webkit-transform: rotate(360deg) !important; 53 -moz-transform: rotate(360deg) !important; 54 -o-transform: rotate(360deg) !important; 55 -ms-transform: rotate(360deg) !important; 56} 57 58.frienddivleft { 59 width: 92px; 60 float: left; 61 margin-right: -5px; 62} 63 64.frienddivright { 65 margin-top: 18px; 66 margin-right: 18px; 67} 68 69.friendname { 70 text-overflow: ellipsis; 71 font-size: 100%; 72 margin-bottom: 5px; 73 color: var(--primary); 74} 75 76.friendinfo { 77 text-overflow: ellipsis; 78 font-size: 70%; 79 color: var(--primary); 80} 81 82@media screen and (max-width: 600px) { 83 .friendinfo { 84 display: none; 85 } 86 .frienddivleft { 87 width: 84px; 88 margin: auto; 89 } 90 .frienddivright { 91 height: 100%; 92 margin: auto; 93 display: flex; 94 align-items: center; 95 justify-content: center; 96 } 97 .friendname { 98 font-size: 18px; 99 } 100} 到这，友链页面的模板就完成了，然后在 content 目录下创建一个 friends/index.md 文件，然后在 index.md 文件中配置\n1--- 2type: friend 3hiddenFromSearch: true 4readingTime: false 5license: false 6title: 友链 7contentEnd: false 8toc: false 9image: \u0026#34;https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/54de3f8d81a4f97fb1ac4dc06eaf3fda335a5937.webp\u0026#34; 10--- friend.md 的内容如下，因为直接写入这段文字，会被解析，所以这里就不写了，使用图片了\n这样友链页面就完成了，在构建的时候，友链页面会自动生成。\n添加阅读进度条 在页面顶部加一个阅读进度条，即实用又美观。在 layouts/partials 目录下创建一个 readingbar.html 文件，然后在 readingbar.html 文件中配置\n在 layouts/partials/head/ 目录下的 custom.html 中 添加 这段代码\n1{{ if strings.HasPrefix .RelPermalink \u0026#34;/posts/\u0026#34; }} 2\u0026lt;div class=\u0026#34;top-scroll-bar\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; 3\u0026lt;style\u0026gt; 4 .top-scroll-bar { 5 position: fixed; 6 top: 0; 7 left: 0; 8 z-index: 9999; 9 display: none; 10 width: 0; 11 height: 3px; 12 background: #ef3982; 13 } 14\u0026lt;/style\u0026gt; 15 16\u0026lt;script\u0026gt; 17 $(document).ready(function () { 18 $(window).scroll(function(){ 19 $(\u0026#34;.top-scroll-bar\u0026#34;).attr(\u0026#34;style\u0026#34;, \u0026#34;width: \u0026#34; + ($(this).scrollTop() / ($(document).height() - $(this).height()) * 100) + \u0026#34;%; display: block;\u0026#34;); 20 }); 21 }); 22\u0026lt;/script\u0026gt; 23{{ end }} 说一下这个 readingbar.html 文件，看名字就知道，这个文件是 Hugo 允许我们自定义 生成 HTML 中 head 部分的内容。 Hugo 在构建的时候，会自动加载这个文件，所以我们可以在这个文件中添加一些 HTML 代码，比如 CSS、JS 等。\n添加返回顶部按钮 在 custom.html 文件中添加这段代码\n1\u0026lt;div id=\u0026#34;back-top\u0026#34;\u0026gt; 2 \u0026lt;a href=\u0026#34;#top\u0026#34; title=\u0026#34;回到顶部\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; 3\u0026lt;/div\u0026gt; 4\u0026lt;style\u0026gt; 5 #back-top { 6 position: fixed; 7 bottom: 30px; 8 right: 80px; 9 } 10 #back-top a { 11 width: 54px; 12 height: 54px; 13 display: block; 14 background: #ddd url(/images/back_top.svg) no-repeat center center; 15 background-color: rgba(218, 214, 214, 0.87); 16 -webkit-border-radius: 7px; 17 -moz-border-radius: 7px; 18 border-radius: 7px; 19 -webkit-transition: 1s; 20 -moz-transition: 1s; 21 transition: 1s; 22 } 23 #back-top a:hover { 24 background-color: #e88282; 25 } 26\u0026lt;/style\u0026gt; 27 28\u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; 29 $(\u0026#34;#back-top\u0026#34;).hide(); 30 $(document).ready(function () { 31 $(window).scroll(function () { 32 if ($(this).scrollTop() \u0026gt; 100) { 33 $(\u0026#39;#back-top\u0026#39;).fadeIn(); 34 } else { 35 $(\u0026#39;#back-top\u0026#39;).fadeOut(); 36 } 37 }); 38 $(\u0026#39;#back-top a\u0026#39;).click(function () { 39 $(\u0026#39;body,html\u0026#39;).animate({ 40 scrollTop: 0 41 }, 800); 42 return false; 43 }); 44 }); 45\u0026lt;/script\u0026gt; 图片灯箱效果 Hugo 自带的图片渲染是没有灯箱效果的，所以我们需要自己添加。灯箱效果就是点击图片后，图片会放大显示。\n还是在 custom.html 文件中添加这段代码\n1{{if .Page.Site.Params.fancybox }} 2\u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 3\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css\u0026#34; /\u0026gt; 4\u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 5{{ end }} 然后在 layouts/_default 目录下 新建 render-image.html文件，然后在 render-image.html 文件中配置\n1\u0026lt;div class=\u0026#34;post-img-view\u0026#34;\u0026gt; 2 \u0026lt;a data-fancybox=\u0026#34;gallery\u0026#34; href=\u0026#34;{{ .Destination | safeURL }}\u0026#34;\u0026gt; 3 \u0026lt;img src=\u0026#34;{{ .Destination | safeURL }}\u0026#34; alt=\u0026#34;{{ .Text }}\u0026#34; {{ with .Title}} title=\u0026#34;{{ . }}\u0026#34;{{ end }} /\u0026gt; 4 \u0026lt;/a\u0026gt; 5\u0026lt;/div\u0026gt; 这段代码的作用是替换 Hugo 默认的图片渲染，这样就可以实现点击图片放大显示的效果了。\n修改列表渲染样式 我使用的 Stack 主题，在给 homepage 添加了 Widget 后，除了主页的文章列表显示了， 标签、分类 也显示了。\n这不是我想要的，我只想在主页显示文章列表，所以需要修改一下 layouts/_default 目录下的 my_list.html 文件。 然后把 Stack 主题中的 layouts/_default/list.html 文件复制到 项目的layouts/_default 目录下，然后修改 my_list.html 文件中的内容。\n把最后面那段代码删除就行了。也就是下面这段代码\n1{{ define \u0026#34;right-sidebar\u0026#34; }} 2{{ partial \u0026#34;sidebar/right.html\u0026#34; (dict \u0026#34;Context\u0026#34; . \u0026#34;Scope\u0026#34; \u0026#34;homepage\u0026#34;) }} 3{{ end }} 然后在想使用这个模板的页面中，把 layout 改成 my_list 就行了。\n比如 content/categories/_index.md 文件中的配置\n1--- 2title: \u0026#34;分类\u0026#34; 3contentEnd: false 4license: false 5layout: my_list 6--- 其实这给我们提供了一个思路，就是 Hugo 的模板是可以自定义的，我们可以根据自己的需求来修改模板，这样就可以实现自己想要的效果了。\n搜索引擎验证信息 我们自建的博客，需要提交到搜索引擎中，这样搜索引擎才能收录我们的博客。这时候就需要在博客中添加搜索引擎验证信息。可以使用在网站的目录中放一个 html 文件，然后在 html 文件中添加验证信息。\n也可以在每个网页中添加验证信息，这样就不需要在网站的目录中放一个 html 文件了。这条验证信息是在 head 中添加的，所以我们可以在 custom.html 文件中添加这条验证信息。\n1{{ if .Site.Params.google_site_verification }} 2\u0026lt;meta name=\u0026#34;google-site-verification\u0026#34; content=\u0026#34;{{ .Site.Params.google_site_verification }}\u0026#34; /\u0026gt; 3{{ end }} 4 5{{ if .Site.Params.bing_site_verification }} 6\u0026lt;meta name=\u0026#34;msvalidate.01\u0026#34; content=\u0026#34;{{ .Site.Params.bing_site_verification }}\u0026#34; /\u0026gt; 7{{ end }} 添加完这段代码后，我们就可以在 config.yaml 文件中添加 google_site_verification 和 bing_site_verification 了。\n1 google_site_verification: \u0026#34;XXX\u0026#34; 2 bing_site_verification: \u0026#34;XXX\u0026#34; 把 XXX 替换成对应的验证信息就行了。\n这段配置需要在 params 层级下配置，这样就可以在 head 中添加搜索引擎验证信息了。\n板娘 就是左下角的那个小女孩，这个是我在网上找的， GitHub\n添加方法也很简单，只需要在 layouts/partials/head 目录下的 custom.html 文件中添加这段代码就行了。\n1\u0026lt;script src=\u0026#34;https://fastly.jsdelivr.net/gh/stevenjoezhang/live2d-widget@latest/autoload.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 自动部署 一般都会使用 git 来管理博客的源码，然后使用 GitHub Actions 来自动部署博客。这样我们只需要在 git 仓库中提交代码，然后 GitHub Actions 就会自动构建并部署博客。 像我的博客就是这样的，我使用 GitHub Actions 来自动构建并部署博客。并且使用 GitHub的 Pages 功能来托管博客。\n这时候我会使用两个 GitHub 仓库，一个用来存放 Hugo 项目的源码，一个用来存放 Hugo 项目构建后的静态文件。\n并且把 存放源码的仓库设置为 private，因为GitHub的限制，GitHub Pages 只支持 public 仓库。\n这样就可以实现自动部署了，只需要在 git 仓库中提交代码，然后 GitHub Actions 就会自动构建并部署博客。\n在源码的仓库中，需要添加一个 .github/workflows 目录，然后在 .github/workflows 目录中创建一个 deploy.yml 文件，然后在 deploy.yml 文件中配置\n1name: Deploy 2 3env: 4 GIT_USER: lqx # GitHub 用户名 5 GIT_EMAIL: lqxlucky@qq.com # GitHub 邮箱 6 PAGE_REPO: git@github.com:lqxhub/lqxhub.github.io.git # 存放静态文件的仓库（GitHub page的仓库） 7 8on: 9 push: 10 branches: 11 - master # 源码仓库的分支 12 13 workflow_dispatch: 14 15jobs: 16 build: 17 runs-on: ubuntu-latest 18 19 steps: 20 - name: checkOut # 拉取源码 21 uses: actions/checkout@v4 22 - name: Setup Hugo # 安装 Hugo 23 uses: peaceiris/actions-hugo@v3 24 with: 25 hugo-version: \u0026#39;0.136.2\u0026#39; # Hugo 版本 26 extended: true # 是否使用扩展版本 27 - name: Build the website # 构建hugo页面 28 run: | 29 sudo timedatectl set-timezone \u0026#34;Asia/Shanghai\u0026#34; # 设置时区 30 hugo --minify # 构建页面 这里使用了 --minify 参数，这样构建的页面会更小 31 32 - name: Deploy # 部署 33 env: 34 DEPLOY_SECRET: ${{ secrets.DEPLOY_SECRET }} # GitHub的密钥 35 run: | 36 mkdir -p ~/.ssh 37 echo \u0026#34;$DEPLOY_SECRET\u0026#34; \u0026gt; ~/.ssh/id_rsa 38 chmod 600 ~/.ssh/id_rsa 39 ssh-keyscan github.com \u0026gt;\u0026gt; ~/.ssh/known_hosts 40 git config --global user.name \u0026#34;${{ env.GIT_USER }}\u0026#34; 41 git config --global user.email \u0026#34;${{ env.GIT_EMAIL }}\u0026#34; 42 43 cd public # Hugo generates the site in \u0026#39;public\u0026#39; folder by default 44 git init 45 git remote add origin \u0026#34;${{ env.PAGE_REPO }}\u0026#34; 46 git add . 47 git commit -m \u0026#34;Deploy from Hugo site\u0026#34; 48 git push --force origin master 这里说一下 DEPLOY_SECRET，这个是 GitHub 的密钥，需要在 托管源码的仓库(也就是私有仓库里)中添加 DEPLOY_SECRET。\n如图中所示，创建即可。\n我使用的自定义配置 我对 Stack 主题进行了一些修改，都在 assets/scss 目录下的 custom.scss 文件中配置。\n1// assets\\scss\\custom.scss 2 3// 页面基本配色 4:root { 5 // 全局顶部边距 6 --main-top-padding: 30px; 7 // 全局卡片圆角 8 --card-border-radius: 25px; 9 // 标签云卡片圆角 10 --tag-border-radius: 8px; 11 // 卡片间距 12 --section-separation: 40px; 13 // 全局字体大小 14 --article-font-size: 1.8rem; 15 // 行内代码背景色 16 --code-background-color: #f8f8f8; 17 // 行内代码前景色 18 --code-text-color: #e96900; 19 // 暗色模式下样式 20 \u0026amp;[data-scheme=\u0026#34;dark\u0026#34;] { 21 // 行内代码背景色 22 --code-background-color: #ff6d1b17; 23 // 行内代码前景色 24 --code-text-color: #e96900; 25 } 26 } 27 28 //------------------------------------------------------ 29 // 修复引用块内容窄页面显示问题 30 a { 31 word-break: break-all; 32 } 33 34 //-------------------------------------------------- 35 // 文章封面高度 36 .article-list article .article-image img { 37 width: 100%; 38 height: 200px !important; 39 object-fit: cover; 40 41 @include respond(md) { 42 height: 250px !important; 43 } 44 45 @include respond(xl) { 46 height: 285px !important; 47 } 48 } 49 50 //--------------------------------------------------- 51 // 文章内容图片圆角阴影 52 .article-page .main-article .article-content { 53 img { 54 max-width: 96% !important; 55 height: auto !important; 56 border-radius: 8px; 57 } 58 } 59 60 //------------------------------------------------ 61 // 文章内容引用块样式 62 .article-content { 63 blockquote { 64 border-left: 6px solid #358b9a1f !important; 65 background: #3a97431f; 66 } 67 } 68 69 code { 70 word-break: break-all; 71 border-radius: var(--tag-border-radius); 72 font-family: var(--code-font-family); 73 border-radius: var(--category-border-radius); 74 } 75 76 // 代码块基础样式修改 77 .highlight { 78 border-radius: 20px; 79 \u0026amp;:hover { 80 .copyCodeButton { 81 opacity: 1; 82 } 83 } 84 85 pre { 86 margin: initial; 87 padding: 0; 88 margin: 0; 89 width: auto; 90 } 91 } 92 93 //------------------------------------------- 94 // 设置选中字体的区域背景颜色 95 //修改选中颜色 96 ::selection { 97 color: #fff; 98 background: #34495e; 99 } 100 101 a { 102 text-decoration: none; 103 color: var(--accent-color); 104 105 \u0026amp;:hover { 106 color: var(--accent-color-darker); 107 } 108 109 \u0026amp;.link { 110 color: #4288b9ad; 111 font-weight: 600; 112 padding: 0 2px; 113 text-decoration: none; 114 cursor: pointer; 115 116 \u0026amp;:hover { 117 text-decoration: underline; 118 } 119 } 120 } 121//固定代码块的高度 122 .article-content { 123 .highlight { 124 padding: var(--card-padding); 125 pre { 126 width: auto; 127 max-height: 50em; 128 } 129 } 130 } 131 132 //------------------------------------------------- 133 //文章封面高度更改 134 .article-list article .article-image img { 135 width: 100%; 136 height: 150px; 137 object-fit: cover; 138 139 @include respond(md) { 140 height: 200px; 141 } 142 143 @include respond(xl) { 144 height: 305px; 145 } 146 } 147 148 //--------------------------------------------------- 149 // 全局页面布局间距调整 150 .main-container { 151 min-height: 100vh; 152 align-items: flex-start; 153 padding: 0 15px; 154 gap: var(--section-separation); 155 padding-top: var(--main-top-padding); 156 157 @include respond(md) { 158 padding: 0 37px; 159 } 160 } 161 162 //-------------------------------------------------- 163 //页面三栏宽度调整 164 .container { 165 margin-left: auto; 166 margin-right: auto; 167 168 .left-sidebar { 169 order: -3; 170 max-width: var(--left-sidebar-max-width); 171 } 172 173 .right-sidebar { 174 order: -1; 175 max-width: var(--right-sidebar-max-width); 176 177 /// Display right sidebar when min-width: lg 178 @include respond(lg) { 179 display: flex; 180 } 181 } 182 183 \u0026amp;.extended { 184 @include respond(md) { 185 max-width: 1024px; 186 --left-sidebar-max-width: 25%; 187 --right-sidebar-max-width: 22% !important; 188 } 189 190 @include respond(lg) { 191 max-width: 1280px; 192 --left-sidebar-max-width: 20%; 193 --right-sidebar-max-width: 30%; 194 } 195 196 @include respond(xl) { 197 max-width: 1453px; //1536px; 198 --left-sidebar-max-width: 15%; 199 --right-sidebar-max-width: 25%; 200 } 201 } 202 203 \u0026amp;.compact { 204 @include respond(md) { 205 --left-sidebar-max-width: 25%; 206 max-width: 768px; 207 } 208 209 @include respond(lg) { 210 max-width: 1024px; 211 --left-sidebar-max-width: 20%; 212 } 213 214 @include respond(xl) { 215 max-width: 1280px; 216 } 217 } 218 } 219 220 //------------------------------------------------------- 221 //全局页面小图片样式微调 222 .article-list--compact article .article-image img { 223 width: var(--image-size); 224 height: var(--image-size); 225 object-fit: cover; 226 border-radius: 17%; 227 } 228 229//---------------------------------------------------- 230// 菜单栏样式 231// 下拉菜单改圆角样式 232.menu { 233 padding-left: 0; 234 list-style: none; 235 flex-direction: column; 236 overflow-x: hidden; 237 overflow-y: scroll; 238 flex-grow: 1; 239 font-size: 1.6rem; 240 background-color: var(--card-background); 241 242 box-shadow: var(--shadow-l2); //改个阴影 243 display: none; 244 margin: 0; //改为0 245 border-radius: 10px; //加个圆角 246 padding: 30px 30px; 247 248 @include respond(xl) { 249 padding: 15px 0; 250 } 251 252 \u0026amp;, 253 .menu-bottom-section { 254 gap: 30px; 255 256 @include respond(xl) { 257 gap: 25px; 258 } 259 } 260 261 \u0026amp;.show { 262 display: flex; 263 } 264 265 @include respond(md) { 266 align-items: flex-end; 267 display: flex; 268 background-color: transparent; 269 padding: 0; 270 box-shadow: none; 271 margin: 0; 272 } 273 274 li { 275 position: relative; 276 vertical-align: middle; 277 padding: 0; 278 279 @include respond(md) { 280 width: 100%; 281 } 282 283 svg { 284 stroke-width: 1.33; 285 286 width: 20px; 287 height: 20px; 288 } 289 290 a { 291 height: 100%; 292 display: inline-flex; 293 align-items: center; 294 color: var(--body-text-color); 295 gap: var(--menu-icon-separation); 296 } 297 298 span { 299 flex: 1; 300 } 301 302 \u0026amp;.current { 303 a { 304 color: var(--accent-color); 305 font-weight: bold; 306 } 307 } 308 } 309 } 310 311 // ~\\blog\\assets\\scss\\custom.scss 312 313//------------------------------------------------ 314//将滚动条修改为圆角样式 315//菜单滚动条美化 316.menu::-webkit-scrollbar { 317 display: none; 318 } 319 320 // 全局滚动条美化 321 html { 322 ::-webkit-scrollbar { 323 width: 20px; 324 } 325 326 ::-webkit-scrollbar-track { 327 background-color: transparent; 328 } 329 330 ::-webkit-scrollbar-thumb { 331 background-color: #d6dee1; 332 border-radius: 20px; 333 border: 6px solid transparent; 334 background-clip: content-box; 335 } 336 337 ::-webkit-scrollbar-thumb:hover { 338 background-color: #a8bbbf; 339 } 340 } 341 342//-------------------------------------------------- 343//归档页面双栏 344/* 归档页面两栏 */ 345@media (min-width: 1024px) { 346 .article-list--compact { 347 display: grid; 348 grid-template-columns: 1fr 1fr; 349 background: none; 350 box-shadow: none; 351 gap: 1rem; 352 353 article { 354 background: var(--card-background); 355 border: none; 356 box-shadow: var(--shadow-l2); 357 margin-bottom: 8px; 358 border-radius: 16px; 359 } 360 } 361 } 362 363//-------------------------------------------------- 364//链接三栏 365@media (min-width: 1024px) { 366 .article-list--compact.links { 367 display: grid; 368 grid-template-columns: 1fr 1fr 1fr; //三个1fr即为三栏,两个1fr则为双栏,以此类推即可. 369 background: none; 370 box-shadow: none; 371 gap: 1rem; 372 373 article { 374 background: var(--card-background); 375 border: none; 376 box-shadow: var(--shadow-l2); 377 margin-bottom: 8px; 378 border-radius: var(--card-border-radius); 379 380 \u0026amp;:nth-child(odd) { 381 margin-right: 8px; 382 } 383 } 384 } 385 } 386 387 388//--------------------------------------------------------- 389//首页欢迎板块样式 390.welcome { 391 color: var(--card-text-color-main); 392 background: var(--card-background); 393 box-shadow: var(--shadow-l2); 394 border-radius: 30px; 395 display: inline-block; 396 } 397 398 // 👋emoji实现摆动效果 399 .shake { 400 display: inline-block; 401 animation: shake 1s; 402 animation-duration: 1s; 403 animation-timing-function: ease; 404 animation-delay: 0s; 405 animation-iteration-count: 1; 406 animation-direction: normal; 407 animation-fill-mode: none; 408 animation-play-state: running; 409 animation-name: shake; 410 animation-timeline: auto; 411 animation-range-start: normal; 412 animation-range-end: normal; 413 animation-delay: 2s; 414 @keyframes shake { 415 0% { 416 transform: rotate(0); 417 } 418 25% { 419 transform: rotate(45deg) scale(1.2); 420 } 421 50% { 422 transform: rotate(0) scale(1.2); 423 } 424 75% { 425 transform: rotate(45deg) scale(1.2); 426 } 427 100% { 428 transform: rotate(0); 429 } 430 } 431 } 432 // 实现字符跳动动画 433 .jump-text1 { 434 display: inline-block; 435 animation: jump 0.5s 1; 436 } 437 438 .jump-text2 { 439 display: inline-block; 440 animation: jump 0.5s 1; 441 animation-delay: 0.1s; 442 } 443 444 .jump-text3 { 445 display: inline-block; 446 animation: jump 0.5s 1; 447 animation-delay: 0.2s; 448 } 449 450 .jump-text4 { 451 display: inline-block; 452 animation: jump 0.5s 1; 453 animation-delay: 0.3s; 454 } 455 456 .jump-text5 { 457 display: inline-block; 458 animation: jump 0.5s 1; 459 animation-delay: 0.4s; 460 } 461 462 .jump-text6 { 463 display: inline-block; 464 animation: jump 0.5s 1; 465 animation-delay: 0.5s; 466 } 467 468 .jump-text7 { 469 display: inline-block; 470 animation: jump 0.5s 1; 471 animation-delay: 0.6s; 472 } 473 474 .jump-text8 { 475 display: inline-block; 476 animation: jump 0.5s 1; 477 animation-delay: 0.7s; 478 } 479 480 .jump-text9 { 481 display: inline-block; 482 animation: jump 0.5s 1; 483 animation-delay: 0.9s; 484 } 485 486 @keyframes jump { 487 0% { 488 transform: translateY(0); 489 } 490 50% { 491 transform: translateY(-20px); 492 } 493 100% { 494 transform: translateY(0); 495 } 496 } 497 498 .main-container .right-sidebar { 499 order: 2; 500 max-width: var(--right-sidebar-max-width); 501 502 /// Display right sidebar when min-width: lg 503 @include respond(lg) { 504 display: flex; 505 } 506 } 507 508 main.main { 509 order: 1; 510 min-width: 0; 511 max-width: 100%; 512 flex-grow: 1; 513 display: flex; 514 flex-direction: column; 515 gap: var(--section-separation); 516 517 @include respond(md) { 518 padding-top: var(--main-top-padding); 519 } 520 } 521 522//---------------------------------------------------------- 523 524.article-category { 525 display: flex; 526 flex-wrap: wrap; 527 gap: 10px; 528 529 a { 530 background: var(--card-background); 531 box-shadow: var(--shadow-l1); 532 border-radius: var(--category-border-radius); 533 padding: 8px 20px; 534 color: var(--card-text-color-main); 535 font-size: 1.4rem; 536 transition: box-shadow 0.3s ease; 537 538 \u0026amp;:hover { 539 box-shadow: var(--shadow-l2); 540 } 541 } 542} 543 544/* Category widget */ 545.category { 546 .category-label { 547 display: flex; 548 flex-wrap: wrap; 549 gap: 10px; 550 551 a { 552 border-left: 6px solid; 553 background: var(--card-background); 554 box-shadow: var(--shadow-l1); 555 border-radius: var(--category-border-radius); 556 padding: 12px 20px; 557 color: var(--card-text-color-main); 558 font-size: 1.5rem; 559 transition: box-shadow 0.3s ease; 560 561 \u0026amp;:hover { 562 box-shadow: var(--shadow-l2); 563 } 564 } 565 } 566 .category-count { 567 color: var(--body-text-color); 568 } 569} 570 571.article-subtitle { 572 margin-top: -5px; 573 font-size: 1.5rem; 574 575 @include respond(md) { 576 font-size: 1.6rem; 577 } 578} 579 580/*头像旋转动画*/ 581.sidebar header .site-avatar .site-logo { 582 transition: transform 1.65s ease-in-out; //旋转时间 583 584} 585 586.sidebar header .site-avatar .site-logo:hover { 587 transform: rotate(360deg); //旋转角度为360度 588} 589 590/*社交菜单居中*/ 591.social-menu svg { 592 gap: 15px; 593 justify-content: center; 594 width: 30px; 595 height: 25px; //社交菜单大小 596 stroke: var(--body-text-color); 597 stroke-width: 1.33; 598} 599 600/*页面加载动画部分*/ 601#loading-box .loading-left-bg, 602#loading-box .loading-right-bg { 603 position: fixed; 604 z-index: 1000; 605 width: 50%; 606 height: 100%; 607 // 我在这里小改了一下颜色， 608 background-color: #b1c0c7; 609 transition: all 0.5s; 610} 611 612#loading-box .loading-right-bg { 613 right: 0; 614} 615 616#loading-box\u0026gt;.spinner-box { 617 position: fixed; 618 z-index: 1001; 619 display: flex; 620 justify-content: center; 621 align-items: center; 622 width: 100%; 623 height: 100vh; 624} 625 626#loading-box .spinner-box .configure-border-1 { 627 position: absolute; 628 padding: 3px; 629 width: 115px; 630 height: 115px; 631 background: #ffab91; 632 animation: configure-clockwise 3s ease-in-out 0s infinite alternate; 633} 634 635#loading-box .spinner-box .configure-border-2 { 636 left: -115px; 637 padding: 3px; 638 width: 115px; 639 height: 115px; 640 background: rgb(63, 249, 220); 641 transform: rotate(45deg); 642 animation: configure-xclockwise 3s ease-in-out 0s infinite alternate; 643} 644 645#loading-box .spinner-box .loading-word { 646 position: absolute; 647 color: #ffffff; 648 // 我在这里小改了一下文字大小和字体，注意！ 649 font-size: 1.8rem; 650 font-family: \u0026#39;Zhi Mang Xing\u0026#39;, cursive; 651} 652 653#loading-box .spinner-box .configure-core { 654 width: 100%; 655 height: 100%; 656 background-color: #37474f; 657} 658 659div.loaded div.loading-left-bg { 660 transform: translate(-100%, 0); 661} 662 663div.loaded div.loading-right-bg { 664 transform: translate(100%, 0); 665} 666 667div.loaded div.spinner-box { 668 // 你可以把这个注释掉，这样就能一直看那个动画的效果了！ 669 display: none !important; 670} 671 672@keyframes configure-clockwise { 673 0% { 674 transform: rotate(0); 675 } 676 677 25% { 678 transform: rotate(90deg); 679 } 680 681 50% { 682 transform: rotate(180deg); 683 } 684 685 75% { 686 transform: rotate(270deg); 687 } 688 689 100% { 690 transform: rotate(360deg); 691 } 692} 693 694@keyframes configure-xclockwise { 695 0% { 696 transform: rotate(45deg); 697 } 698 699 25% { 700 transform: rotate(-45deg); 701 } 702 703 50% { 704 transform: rotate(-135deg); 705 } 706 707 75% { 708 transform: rotate(-225deg); 709 } 710 711 100% { 712 transform: rotate(-315deg); 713 } 714} 715 716 717/* 头像旋转 */ 718.home .home-profile .home-avatar img { 719 width: 5rem; 720 721 /* 设置循环动画 722 [animation: 723\t(play)动画名称 724\t(2s)动画播放时长单位秒或微秒 725\t(ease-out)动画播放的速度曲线为以低速结束 726\t(1s)等待1秒然后开始动画 727\t(1)动画播放次数(infinite为循环播放) ]*/ 728 729 /* 鼠标经过头像旋转360度 */ 730 -webkit-transition: -webkit-transform 1.0s ease-out; 731 -moz-transition: -moz-transform 1.0s ease-out; 732 transition: transform 1.0s ease-out; 733 \u0026amp;:hover { 734 /* 鼠标经过停止头像旋转 735 -webkit-animation-play-state:paused; 736 animation-play-state:paused;*/ 737 738 /* 鼠标经过头像旋转360度 */ 739 -webkit-transform: rotateZ(360deg); 740 -moz-transform: rotateZ(360deg); 741 transform: rotateZ(360deg); 742 } 743} 大多数都有注释，可以按需取用。\n总结 以上就是我在迁移博客时遇到的问题，和一些对应的解决办法，还有一些自定义配置，希望对你有所帮助。 解决问题大多数都是在 Google 上搜索，或者问 ChatGPT。\n因为这篇文章是在迁移后写的，所以有些问题可能会忘记，如果文中有错误，欢迎使用 邮箱 和我交流。\n","date":"2024-10-24T19:54:58+08:00","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/c93977adeb47543e974d7abfcb000757e682158f.jpg","permalink":"https://lqxhub.github.io/posts/a660c9b1/","title":"Hexo迁移到hugo指北|Hugo配置|自定义|美化"},{"content":"今年一直没怎么写东西，看了一下上一篇文章，都过去半年了。前段时间一直想写一点redis的东西，但是一直没有时间去研读源码，所以就一直没有写。 最近有时间，看了一点 iouring 的东西，就写了一篇文章，介绍了一下 iouring 的基本使用，实现了一个简单的TCP server\n很早就听说过 iouring ，但是一直没有时间学习。最近有时间就找了一些资料，学习了一下，写了一个简单的例子，实现了一个简单的tcp服务。\n这篇文章主要介绍了如何使用 iouring 实现一个简单的 tcp 服务，只是介绍了iouring的基本使用，没有涉及底层实现。 后面有时间再去学一下 liburing 的源码，看看底层是如何实现的。\n先解释一下两个名词：iouring 和 liburing。 iouring 是 Linux 内核在 5.1 版本引入的一个新的异步I/O接口。 liburing 是 iouring 的一个用户态库，封装了 iouring 的接口，使得用户可以更方便的使用 iouring。\n简单说就是 io_uring 是linux内核的功能，对外提供了一套异步I/O的接口。因为直接使用 linux内核的 io_uring 接口太麻烦了， 所以在就写了 liburing 这个库，对内核的 io_uring 封装，提供了一套更加友好的接口，使得用户可以更方便的使用 io_uring。\n什么是iouring io_uring是Linux内核在 5.1 版本引入的一个新的异步I/O接口。 io_uring的目标是提供一个高效的、统一的异步I/O接口，以替代现有的异步I/O接口（如aio、epoll、eventfd等）。 io_uring的设计目标是提供一个简单的、高效的、统一的异步I/O接口，以便应用程序可以更容易地利用异步I/O的优势。\n虽然linux内核提供了很多异步I/O的接口，比如aio。 在linux上可以使用\nfcntl(sockfd, F_SETFL, fcntl(sockfd, F_GETFL, 0) | O_NONBLOCK);\n来设置 socket 为非阻塞模式，后续在读写 socket 的 fd 时，使用 read 和 write 函数 就是非阻塞的了。\n在调用 read 和 write 函数时，如果 fd 没有数据，或者 fd 的缓冲区满了，那么 read 和 write 函数会立即返回， 不会阻塞\n但是这种方式有一个问题，就是 read 和 write 函数的调用是阻塞的，虽然 read 和 write 函数会立即返回，但是 read 和 write 函数的调用是阻塞的，会占用 CPU 的资源。\n因为之前的异步I/O接口不够好用，所以 io_uring 就诞生了。\nio_uring 的设计目标是提供一个简单的、高效的、统一的异步I/O接口，以便应用程序可以更容易地利用异步I/O的优势。 现在的 io_uring 支持 文件 I/O、网络 I/O、定时器、信号 等。真正的统一了 I/O 异步操作。\n说到异步I/O，就不得不提一下 epoll。 epoll 是 Linux 内核提供的一种 I/O 多路复用机制，可以同时监控多个 fd 的 I/O 事件。 epoll 只是这个 多路复用机制，只是用来监控 fd 的 I/O 事件，当 fd 有 I/O 事件时（fd 可以被读写时）， epoll 会通知应用程序。 真正的 I/O 操作还是由 read 和 write 函数来完成的。 所以说 epoll 并不是异步 I/O，只是 I/O 多路复用机制。\nio_uring的基础概念 io_uring 有两个重要的概念：Submission Queue 和 Completion Queue。 简称 sq 和 cq。\nSubmission Queue 是 io_uring 的提交队列，用来提交 I/O 请求。\nCompletion Queue 是 io_uring 的完成队列，用来存放 I/O 请求的完成状态。\n和 sq 和 cq 相对应的是 sqe 和 cqe。\nsqe 是 Submission Queue 的元素，用来描述一个 I/O 请求。\ncqe 是 Completion Queue 的元素，用来描述一个 I/O 请求的完成状态。\n放一张iouring的工作流程图：\nio_uring中非常重要的两个数据结构 sq 和 cq。是用户空间和内核空间之间的通信桥梁。\nio_uring 的工作流程如下：\n应用程序向 Submission Queue 中提交 I/O 请求。 io_uring 内核模块从 Submission Queue 中取出 I/O 请求，执行 I/O 操作。 io_uring 内核模块将 I/O 请求的完成状态写入 Completion Queue。 应用程序从 Completion Queue 中读取 I/O 请求的完成状态。 应用程序处理 I/O 请求的完成状态。 因为这次只是简单的介绍 iouring 的基本使用，所以就不深入讲 iouring 的原理了。\nliburing的使用 liburing 是 iouring 的一个用户态库，封装了 iouring 的接口，使得用户可以更方便的使用 iouring。\nliburing中封装了很多操作函数，这次也不会全部介绍，只介绍一些常用的函数。\nliburing常用的函数 io_uring_queue_init 初始化 io_uring 对象。\n1int io_uring_queue_init(unsigned entries, struct io_uring *ring,unsigned flags); 有三个参数：\nentries： Submission Queue 和 Completion Queue 的大小。 ring： io_uring 对象。 flags： 保留参数，传 0 即可。 io_uring_queue_exit 销毁 io_uring 对象。\n1void io_uring_queue_exit(struct io_uring *ring); 传入 io_uring 对象即可。\nio_uring_get_sqe 获取 Submission Queue 的元素。\n1struct io_uring_sqe *io_uring_get_sqe(struct io_uring *ring); 传入 io_uring 对象，返回一个 sqe 对象，用来描述一个 I/O 请求。\nio_uring_submit 提交 I/O 请求。\n1int io_uring_submit(struct io_uring *ring); 传入 io_uring 对象，提交 I/O 请求。\nio_uring_wait_cqe 等待 I/O 请求的完成状态。\n1int io_uring_wait_cqe(struct io_uring *ring, struct io_uring_cqe **cqe_ptr); 传入 io_uring 对象，返回 cqe 对象，用来描述一个 I/O 请求的完成状态。\nio_uring_submit_and_wait 提交 I/O 请求，并等待 I/O 请求的完成状态。\n1int io_uring_submit_and_wait(struct io_uring *ring, unsigned wait_nr); 传入 io_uring 对象，提交 I/O 请求，并等待 I/O 请求的完成状态。\n可以看做是 io_uring_submit 和 io_uring_wait_cqe 的组合。\nio_uring_prep_accept 向 Submission Queue 中添加一个 accept 请求。\n1void io_uring_prep_accept(struct io_uring_sqe *sqe, int fd, struct sockaddr *addr, socklen_t *addrlen, int flags); 有五个参数：\nsqe： Submission Queue 的元素。 fd： socket 的 fd。 addr： sockaddr 结构体。 addrlen： sockaddr 结构体的长度。 flags： 保留参数，传 0 即可。 io_uring_prep_recv 向 Submission Queue 中添加一个 recv 请求，也就是从fd中异步读取数据。\n1void io_uring_prep_recv(struct io_uring_sqe *sqe, int fd, void *buf, unsigned nbytes, unsigned flags); 有五个参数：\nsqe： Submission Queue 的元素。 fd： socket 的 fd。 buf： 接收数据的缓冲区,一般是 char 数组的地址。 nbytes： 缓冲区的大小。 flags： 保留参数，传 0 即可。 io_uring_prep_send 向 Submission Queue 中添加一个 send 请求，也就是向fd中异步写入数据。\n1void io_uring_prep_send(struct io_uring_sqe *sqe, int fd, const void *buf, unsigned nbytes, unsigned flags); 有五个参数：\nsqe： Submission Queue 的元素。 fd： socket 的 fd。 buf： 发送数据的缓冲区，一般是 char 指针的地址。 nbytes： 缓冲区的大小。 flags： 保留参数，传 0 即可。 io_uring_sqe_set_data 设置 sqe 的数据，把用户态的数据和内核绑定。\n1void io_uring_sqe_set_data(struct io_uring_sqe *sqe, void *data); 传入 sqe 对象和用户态的数据，把用户态的数据和内核绑定。\nio_uring_cqe_seen 标记 cqe 为已处理。\n1void io_uring_cqe_seen(struct io_uring *ring, struct io_uring_cqe *cqe); 传入 io_uring 对象和 cqe 对象，标记 cqe 为已处理。\n实现一个简单的tcp服务 io_uring 只能在 linux 内核 5.1 以上版本使用，所以在使用io_uring之前，需要先检查一下内核版本。 一般最新的 ubuntu 和 Debian 都是支持 io_uring 的。\n使用 liburing 需要安装 liburing 库。\n1sudo apt-get install liburing-dev 下面是一个简单的 tcp 服务，功能是接收客户端的连接，然后向客户端发送一条消息。\n1#include \u0026lt;iostream\u0026gt; 2 3#include \u0026lt;liburing.h\u0026gt; 4#include \u0026lt;netinet/in.h\u0026gt; 5#include \u0026lt;map\u0026gt; 6 7const int QUEUE_DEPTH = 128; 8const int BUFFER_SIZE = 4096; 9 10enum ConnectionType { 11 ACCEPT, 12 READ, 13 WRITE, 14}; 15 16struct Connection { 17 int fd; 18 int type{}; 19 char readBuf[BUFFER_SIZE]{}; 20 std::string writeBuf; 21 22 explicit Connection(int _fd) { fd = _fd; } 23}; 24 25std::map\u0026lt;int, Connection *\u0026gt; connections; 26 27int createListener(sockaddr_in *addr) { 28 int listener = socket(AF_INET, SOCK_STREAM, 0); 29 if (listener \u0026lt; 0) { 30 std::cerr \u0026lt;\u0026lt; \u0026#34;socket failed errno:\u0026#34; \u0026lt;\u0026lt; errno \u0026lt;\u0026lt; std::endl; 31 return -1; 32 } 33 34 int opt = 1; 35 if (setsockopt(listener, SOL_SOCKET, SO_REUSEADDR, \u0026amp;opt, sizeof(opt)) \u0026lt; 0) { 36 std::cerr \u0026lt;\u0026lt; \u0026#34;setsockopt failed errno:\u0026#34; \u0026lt;\u0026lt; errno \u0026lt;\u0026lt; std::endl; 37 close(listener); 38 return -1; 39 } 40 41 if (bind(listener, reinterpret_cast\u0026lt;sockaddr *\u0026gt;(addr), sizeof(*addr)) \u0026lt; 0) { 42 std::cerr \u0026lt;\u0026lt; \u0026#34;bind failed errno:\u0026#34; \u0026lt;\u0026lt; errno \u0026lt;\u0026lt; std::endl; 43 close(listener); 44 return -1; 45 } 46 47 if (listen(listener, 10) \u0026lt; 0) { 48 std::cerr \u0026lt;\u0026lt; \u0026#34;listen failed errno:\u0026#34; \u0026lt;\u0026lt; errno \u0026lt;\u0026lt; std::endl; 49 return -1; 50 } 51 52 return listener; 53} 54 55void acceptConnection(io_uring *ring, Connection *conn, sockaddr *addr, socklen_t *clientLen) { 56 conn-\u0026gt;type = ACCEPT; 57 auto sqe = io_uring_get_sqe(ring); 58 io_uring_prep_accept(sqe, conn-\u0026gt;fd, addr, clientLen, 0); 59 io_uring_sqe_set_data(sqe, conn); 60} 61 62void addSocketRead(io_uring *ring, Connection *conn) { 63 conn-\u0026gt;type = READ; 64 auto sqe = io_uring_get_sqe(ring); 65 io_uring_prep_recv(sqe, conn-\u0026gt;fd, \u0026amp;conn-\u0026gt;readBuf, BUFFER_SIZE, 0); 66 io_uring_sqe_set_data(sqe, conn); 67} 68 69void addSocketWrite(io_uring *ring, Connection *conn) { 70 conn-\u0026gt;type = WRITE; 71 auto sqe = io_uring_get_sqe(ring); 72 io_uring_prep_send(sqe, conn-\u0026gt;fd, conn-\u0026gt;writeBuf.data(), conn-\u0026gt;writeBuf.size(), 0); 73 io_uring_sqe_set_data(sqe, conn); 74} 75 76Connection *newConn(io_uring *ring, int fd) { 77 auto conn = new Connection(fd); 78 connections[fd] = conn; 79 addSocketRead(ring, conn); 80 return conn; 81} 82 83int uringRun() { 84 sockaddr_in addr{}; 85 addr.sin_family = AF_INET; 86 addr.sin_port = htons(8088); 87 addr.sin_addr.s_addr = INADDR_ANY; 88 89 int listenFd = createListener(\u0026amp;addr); 90 if (listenFd \u0026lt; 0) { 91 return 1; 92 } 93 socklen_t clientLen = sizeof(addr); 94 io_uring ring{}; 95 if (io_uring_queue_init(QUEUE_DEPTH, \u0026amp;ring, 0) \u0026lt; 0) { 96 std::cerr \u0026lt;\u0026lt; \u0026#34;io_uring_queue_init failed errno:\u0026#34; \u0026lt;\u0026lt; errno \u0026lt;\u0026lt; std::endl; 97 return 1; 98 } 99 auto lConn = newConn(\u0026amp;ring, listenFd); 100 acceptConnection(\u0026amp;ring, lConn, reinterpret_cast\u0026lt;sockaddr *\u0026gt; (\u0026amp;addr), \u0026amp;clientLen); 101 if (io_uring_submit(\u0026amp;ring) \u0026lt; 0) { 102 std::cerr \u0026lt;\u0026lt; \u0026#34;io_uring_submit failed errno:\u0026#34; \u0026lt;\u0026lt; errno \u0026lt;\u0026lt; std::endl; 103 return 1; 104 } 105 106 io_uring_cqe *cqes[QUEUE_DEPTH]; 107 while (true) { 108 //等待事件完成 109 int ret = io_uring_submit_and_wait(\u0026amp;ring, 1); 110 if (ret \u0026lt; 0) { 111 std::cerr \u0026lt;\u0026lt; \u0026#34;io_uring_wait_cqe failed errno:\u0026#34; \u0026lt;\u0026lt; errno \u0026lt;\u0026lt; std::endl; 112 break; 113 } 114 115 //获取完成的事件 116 auto num = io_uring_peek_batch_cqe(\u0026amp;ring, cqes, QUEUE_DEPTH); 117 for (int i = 0; i \u0026lt; num; ++i) { 118 auto conn = reinterpret_cast\u0026lt;Connection *\u0026gt; (cqes[i]-\u0026gt;user_data); 119 if (conn-\u0026gt;type == ACCEPT) {//新连接 120 int clientFd = cqes[i]-\u0026gt;res; 121 auto newCLi = newConn(\u0026amp;ring, clientFd); 122 addSocketRead(\u0026amp;ring, newCLi); 123 acceptConnection(\u0026amp;ring, lConn, reinterpret_cast\u0026lt;sockaddr *\u0026gt; (\u0026amp;addr), \u0026amp;clientLen); 124 } else if (conn-\u0026gt;type == READ) { 125 int readSize = cqes[i]-\u0026gt;res; 126 if (readSize \u0026lt; 0) {//读取失败(比如客户端断开连接) 127 shutdown(conn-\u0026gt;fd, SHUT_RDWR); 128 connections.erase(conn-\u0026gt;fd); 129 delete conn; 130 } else { 131 std::cout \u0026lt;\u0026lt; \u0026#34;read:\u0026#34; \u0026lt;\u0026lt; conn-\u0026gt;readBuf \u0026lt;\u0026lt; std::endl; 132 conn-\u0026gt;writeBuf = \u0026#34;hello client\u0026#34;; 133 addSocketWrite(\u0026amp;ring, conn);//向客户端写数据 134 } 135 } else if (conn-\u0026gt;type == WRITE) { 136 addSocketRead(\u0026amp;ring, conn);// 把这个连接加入读事件 137 } 138 io_uring_cqe_seen(\u0026amp;ring, cqes[i]);// mark the cqe as processed 139 } 140 } 141 io_uring_queue_exit(\u0026amp;ring); 142 return 0; 143} 144 145int main() { 146 uringRun(); 147 return 0; 148} 编译这段代码的时候，需要链接 liburing 库。\n1g++ -o server server.cpp -luring createListener 函数用来创建一个 socket 监听 8088 端口。这个函数没什么特别的，就是创建一个 socket，然后绑定 8088 端口，然后监听。\nacceptConnection 函数用来接收客户端的连接。这个函数调用 io_uring_prep_accept 函数，向 Submission Queue 中添加一个 accept 请求。\naddSocketRead 函数用来向 Submission Queue 中添加一个 recv 请求，也就是从 fd 中异步读取数据。\naddSocketWrite 函数用来向 Submission Queue 中添加一个 send 请求，也就是向 fd 中异步写入数据。\nnewConn 函数用来创建一个新的连接。这个函数会调用 addSocketRead 函数，向 Submission Queue 中添加一个 recv 请求。\nuringRun 函数是主函数。这个函数会创建一个 io_uring 对象，然后调用 createListener 函数创建一个监听 socket，然后调用 newConn 函数创建一个新的连接。\n有一个知识点需要注意一下，在 io_uring中，每次获取的 cqe 在使用完之后，需要调用 io_uring_cqe_seen 函数，标记 cqe 为已处理。 同时处理的时候，也会把 这个 cqe 从 Completion Queue 中移除，对应的 fd 也会从 io_uring 中移除。 所以，为了保证后续能继续接收到 fd 的 I/O 事件，需要在处理完 cqe 之后，再次调用 addSocketRead 函数，向 Submission Queue 中添加一个 recv 请求。\n这些函数的内容都比较简单，就不再详细介绍了。主要看一下 while 循环的内容。\nint ret = io_uring_submit_and_wait(\u0026amp;ring, 1); 这个函数会提交 I/O 请求，并等待 I/O 请求的完成状态。这个函数会阻塞，直到有 1个 I/O 请求完成。\n这里可以使用 io_uring_submit 这个函数只提交 I/O 请求，不等待 I/O 请求的完成状态。但是这样的话，while循环会一直循环，不会阻塞，对应的表现就是 CPU 占用率会很高。 这种情况适用于 I/O 请求比较多的情况，比如 nginx 这种 web 服务器。\n一般情况下，使用 io_uring_submit_and_wait 这个函数就可以了。\n如果 返回的 ret 小于 0，说明出错了，这里简单的打印一下错误信息，然后退出。\nauto num = io_uring_peek_batch_cqe(\u0026amp;ring, cqes, QUEUE_DEPTH); 这个函数会获取 Completion Queue 中的 cqe，一次最多获取 QUEUE_DEPTH 个 cqe。\n这个函数有点类似于 epoll 的 epoll_wait 函数，会一次性获取多个 cqe。\n然后遍历 cqe，根据 cqe 的 type 来处理 I/O 事件。在之前的submit的时候，指定了有 ACCEPT、READ、WRITE 三种 I/O 事件。\n因为之前的 cqe 中的 user_data 是 Connection 对象的指针，所以可以根据 cqe 的 user_data 来获取 Connection 对象，然后根据 Connection 对象的 type 来处理 I/O 事件。 所以可以 reinterpret_cast\u0026lt;Connection *\u0026gt; (cqes[i]-\u0026gt;user_data);强转来获取 Connection 对象。\n如果 type 是 ACCEPT，说明是新的连接，就调用 newConn 函数创建一个新的连接，然后调用 acceptConnection 函数接收新的连接。 在接收新的连接之后，需要再次调用 acceptConnection 函数，把listener的socket放回io_uring中，后面才能继续工作。\n如果 type 是 READ，说明是读事件，就读取 cqe 的 res 字段，如果小于 0，说明读取失败，比如客户端断开连接，就关闭 fd，然后从 connections 中移除这个 fd，然后释放 Connection 对象。 如果读取成功，就打印读取的数据，然后向客户端发送一条消息。\n如果 type 是 WRITE，说明是写事件，在这里就是向客户端写数据完成了。 调用 addSocketRead 函数，向 Submission Queue 中添加一个 读的请求，然后这个 fd 就会继续接收 I/O 事件。\n最后调用 io_uring_cqe_seen 函数，标记 cqe 为已处理。\n这样一个简单的 tcp 服务就实现了。这个服务只是一个简单的例子，没法用在生产环境中，只是用来学习 iouring 的基本使用。\n像是中间的错误处理，连接的超时等问题都没有处理，这些问题需要根据实际情况来处理。\n这个例子中，一个 socket 同时只能读或者写，不能同时读写，这个问题也需要根据实际情况来处理。\n总结 这篇文章主要介绍了 iouring 的基本使用，实现了一个简单的 tcp 服务。只是介绍了 iouring 的基本使用，没有涉及底层实现。 后面有时间再去学一下 liburing 的源码，看看底层是如何实现的。\n其实 iouring 最主要的两个操作是提交 I/O 请求到 sq ，然后等待 I/O 请求的完成后,从 cq 获取然后处理。\n看很多人都说 iouring 性能很高，尤其是在 I/O 密集型的场景下，性能提升很明显。这部分内容还没有验证，后面有时间再去验证一下。\n因为也是初学 iouring，所以文章中可能有错误，欢迎批评指正。\n追更 2024-10-23\n在服务端加了一点代码，写了一个简单的 HTTP 服务器，可以通过浏览器访问，然后找了一个 HTTP 压测工具，测试了一下性能。\nHTTP 服务器返回的内容：\n1conn-\u0026gt;writeBuf = \u0026#34;HTTP/1.1 200 OK\\r\\n\u0026#34; 2 \u0026#34;Content-Length: 55\\r\\n\u0026#34; 3 \u0026#34;Content-Type: text/html\\r\\n\u0026#34; 4 \u0026#34;Connection: keep-alive\\r\\n\u0026#34; 5 \u0026#34;Date: Mon, 23 Oct 2024 13:24:24 GMT\\r\\n\\r\\n\u0026#34; 6 \u0026#34;\u0026lt;!DOCTYPE html\u0026gt;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt;\u0026lt;h1\u0026gt;hello\u0026lt;/h1\u0026gt;\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\u0026#34;; 同样的，使用 epoll 也实现了一个 HTTP 服务器，返回了同样的内容。\n几轮测试下来，发现 epoll 的性能要比 iouring 高一点。至于原因还在研究中。\n猜测的原因可能是 在数据量很小的时候， iouring 的性能发挥不出来，甚至效果更差了。 还有一个原因可能是我使用的方法有问题，这个等后面继续研究。\n","date":"2024-10-20T17:31:37+08:00","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/6a84474a44a97bccecbbc9c5a3b9f7aea2571c97.jpg","permalink":"https://lqxhub.github.io/posts/f0e9829c/","title":"Linux下使用iouring实现一个tcp服务"},{"content":"redis在 6.0 版本加入了ACL支持，虽然已经发布很久了，但是这个命令属于不太常用的命令，导致很多人对ACL还不太了解。比较好的文档就是redis ACL的官方文档 ，其他网上搜索到的相关知识大多数不全面，尤其中文文档缺失比较多。\n我之前写过一篇 redis ACL源码分析的文章。但是这篇文章偏向源码学习，对ACL的使用基本没有介绍。所以这次就来写一下 ACL 的使用。我作为 pika ACL 功能的贡献者，pika ACL PR，自认为对ACL有一些了解，如果文中有错误，还请不吝赐教。\n我会从 ACL功能的介绍 和 ACL命令的使用 两方面来写\nACL功能 ACL简单来说，就是给redis加了用户的概念。以前的redis中，没有用户这个概念，只有一个密码。当一个连接完成认证后，可以执行所有命令。这样是有风险的，如果一个普通的用户，执行了 flushall 这样的命令，整个redis的数据都会被删除。当加入了用户这个概念以后，redis可以通过给不同的用户划分不同的权限，比如普通用户只给数据的读写权限，不能对redis服务做任何管理。这样就能保证redis服务的安全和稳定。\n就像MySQL一样，有一个默认的 root 用户，这个用户拥有最高的权限。但是在实际使用中，不会在业务处理的连接中使用root用户，而是创建一个普通的用户。限制这个用户的权限，只能操作自己业务的库。当redis有了ACL功能后，也可以实现类似的功能了\n使用ACL 在redis使用ACL不需要特殊的配置，只要redis版本支持这个功能即可。redis在启动的时候，会初始化一个默认用户 default 这个用户就相当于MySQL中的 root 用户。默认拥有所有权限。\n操作和修改redis的ACL，可以使用redis中ACL的相关命令（后面会逐个介绍），可以在配置文件中预先设定，启动redis的时候会自动加载预设的ACL规则。\n可以在redis的配置文件（默认是redis.conf）中进行配置。\n例：\n1user default on nopass ~* \u0026amp;* +@ALL 这就是一条ACL的配置。\n除了在 redis.conf这配置以外，还可以在 redis.conf 中指定一个文件，然后在指定的文件中配置ACL规则。 ACL文件在redis.conf配置如下\n1aclfile /etc/redis/users.acl 除了这两个外，ACL几个个配置\nACL log记录的条数，log的作用就是记录用户越权行为。\n配置：\n1acllog-max-len 128 ACL 中channel 的默认状态。可以配置 allchannels 或 resetchannels。\nallchannels： 可以访问所有Pub/Sub频道的权限 resetchannels： 撤销对所有Pub/Sub频道的访问 配置：\n1acl-pubsub-default resetchannels ACL配置语法 首先，ACL可以对 命令，key的名字，channel 做限制，多个规则之间用空格分割。\nuser1 on \u0026gt;123 ~* \u0026amp;* +@ALL 这条配置中。\nuser1：用户名 on：用户启用，如果设置为 off 那么用户不能使用 \u0026gt;123： 用户密码 ~*：不做任何 key名字的限制 \u0026amp;*：不做 pub/sub 的限制 +@ALL：允许执行所有命令 密码 redis ACL中，一个用户可以有多个密码，只要有一个密码认证成功就可以。也可以使用 nopass 这个关键词来表示该用户没有密码。\n在设置密码的时候，使用 \u0026gt;password 来设置密码，使用\u0026lt;password 来删除对应的密码。\n还可以使用 #5baa61e4c9b93f3f0682250b6cf8331b7ee68fd8 来设置密码，5baa61e4c9b93f3f0682250b6cf8331b7ee68fd8 是 password 的 sha1 值。为了密码安全，redis内部存储密码使用的是密码的 sha1，这样在配置文件和转储ACL规则的时候，可以保证密码的安全。\n同样的，可以使用 !5baa61e4c9b93f3f0682250b6cf8331b7ee68fd8 来删除对应的密码。\nkey名限制 redis中每个key都有一个名字，使用 ~ 来做key名字限制，支持 * 通配符，而且支持key的只读 R 和 写 W 区分。\n比如 对 app1 这个key只读 %R~app1。对所有 app2 开头的key都有权限 ~app2*\npub/sub限制 pub/sub限制和key名限制类似，要使用pub/sub的前提是可以使用 pub/sub相关的命令，这部分在命令限制中配置，这里是限制 channel 的名字。\n和key限制不同的是，channel 使用 \u0026amp; 符号\n这里有两个关键词\nallchannels： 可以访问所有Pub/Sub频道的权限 resetchannels： 撤销对所有Pub/Sub频道的访问 命令限制 命令最好理解了，就是限制当前用户可以执行哪些命令，不能执行哪些命令。 在ACL中使用 + 来赋予命令的权限，用 - 来撤销命令的权限。比如 +get -set 这就表示赋予 get 命令，撤销 set命令。\n除了直接指定具体的命令外，还可以对一类命令做限制。比如 +@hash -@zset，这表示可以执行所有的 hash 类的命令，不能执行所有的 zset 类的命令。\nredis ACL 还可以限制子命令。比如 CONFIG SET acllog-max-len 128 中，SET 就是 CONFIG 命令的子命令。如果想要限制用户不能修改配置，那ACL可以这样配置 +config -config|set。此时用户可以执行 config set 以外的所有 config 命令。\n还有一种用法，允许阻塞命令的第一个参数，不过这个功能自Redis 7.0起已弃用，将来可能会被删除。所以不建议使用了。\n用redis官方文档的例子来说\n有时，排除或包含命令或子命令作为一个整体的能力是不够的。许多部署可能不愿意为任何DB提供执行SELECT的能力，但可能仍然希望能够运行SELECT 0。\n此时的配置 ACL SETUSER myuser -select +select|0。这样，该用户只能执行 select 0 这一个 select 命令。如果想 select 2 等等进入别的库是不允许的。\n我个人感觉，要淘汰这个功能的原因，是应用面太少了，而且像上面的这个例子中，并没有完全限制了对库的使用权限。如果先在别的用户下，选择了 1 这个库，然后再 auth myuser 这个用户，虽然这个用户限制了，只能 select 0，但是此时依然可以访问 1 这个库。\nredis命令的分类：\nadmin 管理redis服务相关的命令 包含 REPLICAOF CONFIG SAVE MONITOR ACL SHUTDOWN等等 bitmap bitmap这个数据类型相关的命令 blocking 可能会阻塞连接，直到被另一个命令释放 connection 影响连接或其他连接的命令。包含 AUTH SELECT COMMAND CLIENT ECHO PING等等 dangerous 有潜在危险的命令(由于各种原因，应该仔细考虑每个命令)。包含 FLUSHALL MIGRATE RESTORE SORT KEYS CLIENT INFO CONFIG SAVE REPLICAOF等等 geo geo这个数据类型相关的命令 hash hash这个数据类型相关的命令 hyperloglog hyperloglog 这个数据类型相关的命令 fast 快 O(1) 的命令，可以循环参数的个数，但不能循环键中的元素个数。 keyspace 以与类型无关的方式从键、数据库或它们的元数据写入或读取。包含 DEL RESTORE DUMP RENAME EXISTS DBSIZE KEYS EXPIRE TTL FLUSHALL 可能修改键空间、键或元数据的命令也将具有 write 类别。仅读取键空间、键或元数据的命令将具有 read 类别。 list list这个数据类型相关的命令 pubsub PubSub 订阅发布相关的命令 read 从键(值或元数据)读取。不与键交互的命令既没有 read 也没有 write scripting lua脚本执行相关的命令 set set 这个数据结构相关的命令 sortedset zset数据结构相关的命令 slow 慢命令，非 fast的命令 stream stream 这个数据类型相关的命令 string string 这个数据类型相关的命令 transaction WATCH MULTI EXEC 这几个和事务相关的命令 write 写入键(值或元数据)的命令 ACL相关命令 使用 ACL HELP 命令可以看到ACL所有的命令\n1 1) ACL \u0026lt;subcommand\u0026gt; [\u0026lt;arg\u0026gt; [value] [opt] ...]. Subcommands are: 2 2) CAT [\u0026lt;category\u0026gt;] 3 3) List all commands that belong to \u0026lt;category\u0026gt;, or all command categories 4 4) when no category is specified. 5 5) DELUSER \u0026lt;username\u0026gt; [\u0026lt;username\u0026gt; ...] 6 6) Delete a list of users. 7 7) DRYRUN \u0026lt;username\u0026gt; \u0026lt;command\u0026gt; [\u0026lt;arg\u0026gt; ...] 8 8) Returns whether the user can execute the given command without executing the command. 9 9) GETUSER \u0026lt;username\u0026gt; 1010) Get the user\u0026#39;s details. 1111) GENPASS [\u0026lt;bits\u0026gt;] 1212) Generate a secure 256-bit user password. The optional `bits` argument can 1313) be used to specify a different size. 1414) LIST 1515) Show users details in config file format. 1616) LOAD 1717) Reload users from the ACL file. 1818) LOG [\u0026lt;count\u0026gt; | RESET] 1919) Show the ACL log entries. 2020) SAVE 2121) Save the current config to the ACL file. 2222) SETUSER \u0026lt;username\u0026gt; \u0026lt;attribute\u0026gt; [\u0026lt;attribute\u0026gt; ...] 2323) Create or modify a user with the specified attributes. 2424) USERS 2525) List all the registered usernames. 2626) WHOAMI 2727) Return the current connection username. 2828) HELP 2929) Prints this help. 那就一个个来吧\nACL CAT 列出所有的命令分类，如果制定了分类名，就列出当前分类中所有的命令\n使用：ACL CAT\n1 1) \u0026#34;keyspace\u0026#34; 2 2) \u0026#34;read\u0026#34; 3 3) \u0026#34;write\u0026#34; 4 4) \u0026#34;set\u0026#34; 5 5) \u0026#34;sortedset\u0026#34; 6 6) \u0026#34;list\u0026#34; 7 7) \u0026#34;hash\u0026#34; 8 8) \u0026#34;string\u0026#34; 9 9) \u0026#34;bitmap\u0026#34; 1010) \u0026#34;hyperloglog\u0026#34; 1111) \u0026#34;geo\u0026#34; 1212) \u0026#34;stream\u0026#34; 1313) \u0026#34;pubsub\u0026#34; 1414) \u0026#34;admin\u0026#34; 1515) \u0026#34;fast\u0026#34; 1616) \u0026#34;slow\u0026#34; 1717) \u0026#34;blocking\u0026#34; 1818) \u0026#34;dangerous\u0026#34; 1919) \u0026#34;connection\u0026#34; 2020) \u0026#34;transaction\u0026#34; 2121) \u0026#34;scripting\u0026#34; 使用：ACL CAT HASH，列出 hash 这个分类下所有的命令。\nACL DELUSER 这个没什么好说的，就是删除指定的用户。例如：ACL DELUSER user1 user2\nACL DRYRUN 用来测试指定用户是否可以执行特定的命令。\n比如测试 user1 是否可以执行 hset hkey field1 1111 命令如下\nACL DRYRUN user1 hset hkey field1 1111 如果有权限执行，会返回 OK，否则会提示具体的错误。\nACL GETUSER 就如字面意思，获取指定用户的详细信息，例：ACL GETUSER user1\nACL GENPASS 生成一个随机密码，默认长度是 256 位的密码，也可以指定长度。\nACL LIST 使用 ACL 配置文件中的格式，列出当前系统中所有的用户的详细信息\nACL LOAD 从配置中重新加载ACL的配置，如果redis的配置文件中，没有配置 aclfile 的文件路径，那么这个命令会报错。\nACL LOG 查询所有没有通过校验的行为，比如 user1 没有 hash 类型数据操作的权限，在使用 hash 类型的命令后，会记录一条log\nlog记录的最大值，从 配置文件中的 acllog-max-len 中读取。\n这个命令可以通过参数，来指定一次获取的log数量，例：ACL LOG 10 只获取10条\n还可以重置所有log，例：ACL LOG reset\nACL SAVE 和 ACL LOAD 命令相反，这个是把当前的ACL规则保存到文件中。这个命令也需要在配置了 aclfile 后才能执行，否则也会报错。\nACL SETUSER 这个是ACL中最常用的命令了，用来创建和设置ACL用户属性。创建和修改用户，使用 ACL 语法，同配置中的语法是一致的。\n例：ACL SETUSER user1 on \u0026gt;123 ~app1* +@all 会修改 user1 这个用户的属性，如果之前没有这个用户，那么会创建这个用户，并设置属性。\nACL还支持子属性，例：ACL SETUSER user1 on \u0026gt;123 ~app1* +@all (+@read ~app2) 在这个规则下，user1 用户对 app1 前缀的key拥有读写权限，对 app2 前缀的key只有读的权限。\nACL USERS 只列出当前系统所有的用户名，相当于是 ACL LIST 命令的简化版\nACL WHOAMI 获取当前用户的名字，类似Linux系统中的 whoami 命令。\n到这整个ACL命令使用差不多就介绍完了。整个ACL就是命令多点，使用起来也没有那么复杂吗。\n","date":"2024-03-10T18:32:52Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/20210321231957647.png","permalink":"https://lqxhub.github.io/posts/1cb4847b/","title":"redis ACL使用手册，redis6.0 redis 中使用ACL手册 - QX's blog"},{"content":"去年写过两篇redis的源码分析文章（redis的watch和ACL），现在回头看，已经过去好久了。说起那两篇文章，收益还是挺大的。这周有时间了，继续学习redis的源码。先来看一下redis的网络处理。\n本次的源码基于redis的 7.2 分支，不同版本下，一些细节可能会有差异。\n这篇文章因为篇幅所限，没法把redis网络读写的所有细节都分析到，只能把这个网络处理的大概流程走一遍。\n看完这篇文章，能对redis网络处理流程有个基本了解，能知道redis加入了多线程后，为什么还是单线程处理数据。能知道redis是如何实现适配不同系统下网络接口。\n先来写一下redis网络需要的一些数据结构。\n数据结构： redis可以支持多个平台（Linux，Unix），这两个平台的网络调用是不一样的，Linux中高性能的网络接口是epoll，Unix上是kqueue。因为版本的原因，在低版本的Linux内核中，epool也是不支持的，这时候就需要用到select。redis使用了 aeEvent 这个结构来封装了网络，实现了对不同网络接口的兼容。 结构的定义在 ae.h 文件中 aeEventLoop\naeEventLoop 是redis网络中，所有网络事件的管理器。我们知道，现在的网络一般都是通过多路复用来处理多个链接，多路复用的实现在不同的系统中有不同的实现，所有redis使用 aeEventLoop 的封装来实现不同平台的兼容。这个结构是全局唯一的，redis启动后完成初始化。\n1typedef struct aeEventLoop { 2 int maxfd; /* highest file descriptor currently registered */ 3 int setsize; /* max number of file descriptors tracked */ 4 long long timeEventNextId; 5 aeFileEvent *events; /* Registered events */ 6 aeFiredEvent *fired; /* Fired events */ 7 aeTimeEvent *timeEventHead; 8 int stop; 9 void *apidata; /* This is used for polling API specific data */ 10 aeBeforeSleepProc *beforesleep; 11 aeBeforeSleepProc *aftersleep; 12 int flags; 13} aeEventLoop; aeFileEvent 和 aeFiredEvent 是处理网络事件的数组结构，aeTimeEvent 是处理redis定时回调的结构数组。\naeFileEvent 是注册到系统中的事件，在 epoll 中就是 struct epoll_event 结构。 aeFiredEvent 是这次要处理的事件。在 epoll 中就是 通过 epoll_wait 返回的事件。 timeEventHead 是定时器要处理的事件。 aeFileEvent 是redis中，多路复用的事件封装。每一个网络链接都会被包装成一个 aeFileEvent 对象，（因为在 Unix系列的系统中，万物皆是文件嘛，所有这里也就叫 aeFileEvent了），然后加入到 aeEventLoop 中，最后交给操作系统中的多路复用管理。当被管理的事件被触发后，会回调对应的函数，也就是 rfileProc 或者 wfileProc 函数指针，来完成操作。\n1typedef struct aeFileEvent { 2 int mask; /* one of AE_(READABLE|WRITABLE|BARRIER) */ 3 aeFileProc *rfileProc; 4 aeFileProc *wfileProc; 5 void *clientData; 6} aeFileEvent; 网络处理的实现在 ae.c 中\n在ae.c中，通过宏定义，来实现对不同平台的兼容\n1#ifdef HAVE_EVPORT 2#include \u0026#34;ae_evport.c\u0026#34; 3#else 4 #ifdef HAVE_EPOLL 5 #include \u0026#34;ae_epoll.c\u0026#34; 6 #else 7 #ifdef HAVE_KQUEUE 8 #include \u0026#34;ae_kqueue.c\u0026#34; 9 #else 10 #include \u0026#34;ae_select.c\u0026#34; 11 #endif 12 #endif 13#endif ae.c#L52-L65 通过判断宏定义，然后include不同的 .c文件。\n这里可能有对C语言了解不深的同学可能会疑问，include 关键字不是用来包含头文件的吗，还能用来引入 .c文件吗？其实include是编译器的一个预处理指令，就是简单的把对应的文件里的所有内容，放到include的地方而已。\n打开 ae_evport.c ae_epoll.c ae_kqueue.c ae_select.c 这四个文件来看，对外暴露的函数接口都是一样的。只是在不同的平台上内部的处理不同。\n对外暴露了这些函数，来完成网络的处理\n1//创建一个loop 2static int aeApiCreate(aeEventLoop *eventLoop) 3//设置loop的大小 4static int aeApiResize(aeEventLoop *eventLoop, int setsize) 5//释放一个 loop 6static void aeApiFree(aeEventLoop *eventLoop) 7//添加一个 eventLoop 8static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) 9//删除一个 eventLoop 10static void aeApiDelEvent(aeEventLoop *eventLoop, int fd, int delmask) 11//不同的网络处理中,返回需要处理的事件 12static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) 13//返回这个ae的名字,在epoll中就是返回 \u0026#34;epoll\u0026#34; 14static char *aeApiName(void) 这里我们以Linux平台为主，所以使用的是 ae_epoll.c文件中的内容。这里先不展开分析每一个函数，因为这不是本次的重点。\n启动网络服务 基本的数据结构介绍完，下面开始启动网络服务\n监听client 第一步是调用 aeEventLoop *aeCreateEventLoop(int setsize) 函数，创建 aeEventLoop 这个对象。\n1aeEventLoop *aeCreateEventLoop(int setsize) { 2 aeEventLoop *eventLoop; 3 int i; 4 5 monotonicInit(); /* just in case the calling app didn\u0026#39;t initialize */ 6 7 if ((eventLoop = zmalloc(sizeof(*eventLoop))) == NULL) goto err; 8 eventLoop-\u0026gt;events = zmalloc(sizeof(aeFileEvent)*setsize); 9 eventLoop-\u0026gt;fired = zmalloc(sizeof(aeFiredEvent)*setsize); 10 if (eventLoop-\u0026gt;events == NULL || eventLoop-\u0026gt;fired == NULL) goto err; 11 eventLoop-\u0026gt;setsize = setsize; 12 eventLoop-\u0026gt;timeEventHead = NULL; 13 eventLoop-\u0026gt;timeEventNextId = 0; 14 eventLoop-\u0026gt;stop = 0; 15 eventLoop-\u0026gt;maxfd = -1; 16 eventLoop-\u0026gt;beforesleep = NULL; 17 eventLoop-\u0026gt;aftersleep = NULL; 18 eventLoop-\u0026gt;flags = 0; 19 if (aeApiCreate(eventLoop) == -1) goto err; 20 /* Events with mask == AE_NONE are not set. So let\u0026#39;s initialize the 21 * vector with it. */ 22 for (i = 0; i \u0026lt; setsize; i++) 23 eventLoop-\u0026gt;events[i].mask = AE_NONE; 24 return eventLoop; 25 26err: 27 if (eventLoop) { 28 zfree(eventLoop-\u0026gt;events); 29 zfree(eventLoop-\u0026gt;fired); 30 zfree(eventLoop); 31 } 32 return NULL; 33} 这里的处理逻辑比较简单，就是初始化 aeEventLoop 中的数据结构。如果中间出错了，就返回 NULL\n这个在 void initServer(void) 函数中被调用。 aeCreateEventLoop\n创建一个aeEventLoop 并赋值给 server。再往上翻，最终的调用位置是 main 函数中的initServer();\n在往下，还有一个比较重要的函数，通过调用 aeCreateTimeEvent 函数，完成定时器 对应的 eventLoop 的创建。\n1long long aeCreateTimeEvent(aeEventLoop *eventLoop, long long milliseconds, 2 aeTimeProc *proc, void *clientData, 3 aeEventFinalizerProc *finalizerProc) 4{ 5 long long id = eventLoop-\u0026gt;timeEventNextId++; 6 aeTimeEvent *te; 7 8 te = zmalloc(sizeof(*te)); 9 if (te == NULL) return AE_ERR; 10 te-\u0026gt;id = id; 11 te-\u0026gt;when = getMonotonicUs() + milliseconds * 1000; 12 te-\u0026gt;timeProc = proc; 13 te-\u0026gt;finalizerProc = finalizerProc; 14 te-\u0026gt;clientData = clientData; 15 te-\u0026gt;prev = NULL; 16 te-\u0026gt;next = eventLoop-\u0026gt;timeEventHead; 17 te-\u0026gt;refcount = 0; 18 if (te-\u0026gt;next) 19 te-\u0026gt;next-\u0026gt;prev = te; 20 eventLoop-\u0026gt;timeEventHead = te; 21 return id; 22} 都是常规的处理，注意一下传递进来的几个参数\neventLoop 是之前创建的 eventLoop对象 proc 是定时器触发时的回调函数 milliseconds 定时器触发的时间间隔 proc 函数的定义\n这里不详细展开了，就是redis中的一些定时操作。\n在 main 函数中继续往下，会看到 initListeners(); 这个函数，中这里也能知道，这里创建 网络的监听\n1void initListeners(void) { 2 /* Setup listeners from server config for TCP/TLS/Unix */ 3 int conn_index; 4 connListener *listener; 5 //判断是否需要监听普通的TCP 6 if (server.port != 0) { 7 conn_index = connectionIndexByType(CONN_TYPE_SOCKET); 8 if (conn_index \u0026lt; 0) 9 serverPanic(\u0026#34;Failed finding connection listener of %s\u0026#34;, CONN_TYPE_SOCKET); 10 listener = \u0026amp;server.listeners[conn_index]; 11 listener-\u0026gt;bindaddr = server.bindaddr; 12 listener-\u0026gt;bindaddr_count = server.bindaddr_count; 13 listener-\u0026gt;port = server.port; 14 listener-\u0026gt;ct = connectionByType(CONN_TYPE_SOCKET); 15 } 16 //判断是否需要监听,如果需要,检查tls需要的配置是否正确 17 if (server.tls_port || server.tls_replication || server.tls_cluster) { 18 ConnectionType *ct_tls = connectionTypeTls(); 19 if (!ct_tls) { 20 serverLog(LL_WARNING, \u0026#34;Failed finding TLS support.\u0026#34;); 21 exit(1); 22 } 23 if (connTypeConfigure(ct_tls, \u0026amp;server.tls_ctx_config, 1) == C_ERR) { 24 serverLog(LL_WARNING, \u0026#34;Failed to configure TLS. Check logs for more info.\u0026#34;); 25 exit(1); 26 } 27 } 28 //判断是否需要监听 TLS的TCP 29 if (server.tls_port != 0) { 30 conn_index = connectionIndexByType(CONN_TYPE_TLS); 31 if (conn_index \u0026lt; 0) 32 serverPanic(\u0026#34;Failed finding connection listener of %s\u0026#34;, CONN_TYPE_TLS); 33 listener = \u0026amp;server.listeners[conn_index]; 34 listener-\u0026gt;bindaddr = server.bindaddr; 35 listener-\u0026gt;bindaddr_count = server.bindaddr_count; 36 listener-\u0026gt;port = server.tls_port; 37 listener-\u0026gt;ct = connectionByType(CONN_TYPE_TLS); 38 } 39 //判断是否需要unixsocket 40 if (server.unixsocket != NULL) { 41 conn_index = connectionIndexByType(CONN_TYPE_UNIX); 42 if (conn_index \u0026lt; 0) 43 serverPanic(\u0026#34;Failed finding connection listener of %s\u0026#34;, CONN_TYPE_UNIX); 44 listener = \u0026amp;server.listeners[conn_index]; 45 listener-\u0026gt;bindaddr = \u0026amp;server.unixsocket; 46 listener-\u0026gt;bindaddr_count = 1; 47 listener-\u0026gt;ct = connectionByType(CONN_TYPE_UNIX); 48 listener-\u0026gt;priv = \u0026amp;server.unixsocketperm; /* Unix socket specified */ 49 } 50 51 /* create all the configured listener, and add handler to start to accept */ 52 int listen_fds = 0; 53 for (int j = 0; j \u0026lt; CONN_TYPE_MAX; j++) { 54 listener = \u0026amp;server.listeners[j]; 55 if (listener-\u0026gt;ct == NULL) 56 continue; 57 58 if (connListen(listener) == C_ERR) { 59 serverLog(LL_WARNING, \u0026#34;Failed listening on port %u (%s), aborting.\u0026#34;, listener-\u0026gt;port, listener-\u0026gt;ct-\u0026gt;get_type(NULL)); 60 exit(1); 61 } 62 //创建新的连接处理事件 63 if (createSocketAcceptHandler(listener, connAcceptHandler(listener-\u0026gt;ct)) != C_OK) 64 serverPanic(\u0026#34;Unrecoverable error creating %s listener accept handler.\u0026#34;, listener-\u0026gt;ct-\u0026gt;get_type(NULL)); 65 66 listen_fds += listener-\u0026gt;count; 67 } 68 69 if (listen_fds == 0) { 70 serverLog(LL_WARNING, \u0026#34;Configured to not listen anywhere, exiting.\u0026#34;); 71 exit(1); 72 } 73} 在这个函数里，根据配置文件，开始监听对应的端口或者 unixsockt。\n这里引入了 connListener connection ConnectionType 这三个结构\nconnListener 是对网络监听的封装 connection 是对网络连接的封装 ConnectionType 封装了操作网络需要的函数 ConnectionType 有三个不同的实现，分别是:\nCT_Socket 对应的TCP CT_Socket CT_Unix 对应的是 unix socket CT_Unix CT_TLS 对应的 使用了 TLS的TCP CT_TLS ConnectionType 定义\nConnectionType内部的函数这里就不展开详细介绍了。\n在 initListeners 中调用了 connListen 函数，来完成对不同网络的监听，这里实现也挺简单的，就是调用了ConnectionType 中的 listen 函数，完成了对端口或者unixsocket的监听。\n1static inline int connListen(connListener *listener) { 2 return listener-\u0026gt;ct-\u0026gt;listen(listener); 3} 以 socket 为例，对应的listen函数就是 connSocketListen 对应的初始化在这里.listen = connSocketListen\n最终实现对端口监听的函数是 listenToPort(connListener *sfd)\n话题收回来，回到 initListeners 函数中 调用 connListen 函数完成监听后，会再调用createSocketAcceptHandler 函数 完成网络的 Accept 处理逻辑。\n1int createSocketAcceptHandler(connListener *sfd, aeFileProc *accept_handler) { 2 int j; 3 4 for (j = 0; j \u0026lt; sfd-\u0026gt;count; j++) { 5 if (aeCreateFileEvent(server.el, sfd-\u0026gt;fd[j], AE_READABLE, accept_handler,sfd) == AE_ERR) { 6 /* Rollback */ 7 for (j = j-1; j \u0026gt;= 0; j--) aeDeleteFileEvent(server.el, sfd-\u0026gt;fd[j], AE_READABLE); 8 return C_ERR; 9 } 10 } 11 return C_OK; 12} 这里逻辑也挺简单，遍历之前accept的 fd，将fd加入到 aeEventLoop 中，如果失败了，就回滚所有数据，也就是中 aeEventLoop 中删除对应的事件。\naeCreateFileEvent的实现\n1int aeCreateFileEvent(aeEventLoop *eventLoop, int fd, int mask, 2 aeFileProc *proc, void *clientData) 3{ 4 if (fd \u0026gt;= eventLoop-\u0026gt;setsize) { 5 errno = ERANGE; 6 return AE_ERR; 7 } 8 aeFileEvent *fe = \u0026amp;eventLoop-\u0026gt;events[fd]; 9 //调用对应平台的系统函数,把对应的事件加入到操作系统中 10 //比如在epoll中就是调用 epoll_ctl 函数把 事件加入 epoll中 11 if (aeApiAddEvent(eventLoop, fd, mask) == -1) 12 return AE_ERR; 13 fe-\u0026gt;mask |= mask; 14 if (mask \u0026amp; AE_READABLE) fe-\u0026gt;rfileProc = proc; 15 if (mask \u0026amp; AE_WRITABLE) fe-\u0026gt;wfileProc = proc; 16 fe-\u0026gt;clientData = clientData; 17 if (fd \u0026gt; eventLoop-\u0026gt;maxfd) 18 eventLoop-\u0026gt;maxfd = fd; 19 return AE_OK; 20} 也是常规的处理逻辑，这里需要注意一下，传递的几个参数。\naeEventLoop 就是之前通过 aeCreateEventLoop 函数创建的对象。 fd 是对应的文件描述符 mask 对应的这个event 需要处理的事件类型，比如 读，写等等 proc 这个是一个回调函数，当对应的事件触发时，使用这个函数来处理。比如这里就是当fd有读写事件触发时，就会调用这个函数，也就是当有新的客户端连接时，就通过这个函数来处理 clientData 是这个event的数据 这里的 proc 是socket.c文件中的 connSocketAcceptHandler 函数。这个函数后面网络读写在分析。到这里，redis对client的网络监听基本完成了。\n监听cluster 如果redis开启了集群，需要对集群中其他的redis做网络监听，与其他的redis互联\n开启cluster\n在这里调用 clusterInitListeners 开启对 cluster 的监听。\n1void clusterInitListeners(void) { 2 if (connectionIndexByType(connTypeOfCluster()-\u0026gt;get_type(NULL)) \u0026lt; 0) { 3 serverLog(LL_WARNING, \u0026#34;Missing connection type %s, but it is required for the Cluster bus.\u0026#34;, connTypeOfCluster()-\u0026gt;get_type(NULL)); 4 exit(1); 5 } 6 7 int port = defaultClientPort(); 8 connListener *listener = \u0026amp;server.clistener; 9 listener-\u0026gt;count = 0; 10 listener-\u0026gt;bindaddr = server.bindaddr; 11 listener-\u0026gt;bindaddr_count = server.bindaddr_count; 12 listener-\u0026gt;port = server.cluster_port ? server.cluster_port : port + CLUSTER_PORT_INCR; 13 listener-\u0026gt;ct = connTypeOfCluster(); 14 if (connListen(listener) == C_ERR ) { 15 /* Note: the following log text is matched by the test suite. */ 16 serverLog(LL_WARNING, \u0026#34;Failed listening on port %u (cluster), aborting.\u0026#34;, listener-\u0026gt;port); 17 exit(1); 18 } 19 20 if (createSocketAcceptHandler(\u0026amp;server.clistener, clusterAcceptHandler) != C_OK) { 21 serverPanic(\u0026#34;Unrecoverable error creating Redis Cluster socket accept handler.\u0026#34;); 22 } 23} 这里的逻辑和client那部分类似，不同的地方是 aeFileEvent 中的回调函数变成了 clusterAcceptHandler 这里不展开了。\n然后会调用 InitServerLast 函数\n这里注意关注 initThreadedIO 这个函数\nredis 在6.0 版本加入了多线程支持，其实redis的多线程只是在 网络 I/O 加入了多线程处理，在处理命令时还是单线程，这里就是做了多线程的处理。\n1void initThreadedIO(void) { 2 server.io_threads_active = 0; /* We start with threads not active. */ 3 4 /* Indicate that io-threads are currently idle */ 5 io_threads_op = IO_THREADS_OP_IDLE; 6 7 //如果就一个线程，也没必要开新的线程了 8 if (server.io_threads_num == 1) return; 9 10 //判断一下，如果线程太多了，就提示错误，不能开启太多线程 11 if (server.io_threads_num \u0026gt; IO_THREADS_MAX_NUM) { 12 serverLog(LL_WARNING,\u0026#34;Fatal: too many I/O threads configured. \u0026#34; 13 \u0026#34;The maximum number is %d.\u0026#34;, IO_THREADS_MAX_NUM); 14 exit(1); 15 } 16 17 /* Spawn and initialize the I/O threads. */ 18 for (int i = 0; i \u0026lt; server.io_threads_num; i++) { 19 /* Things we do for all the threads including the main thread. */ 20 io_threads_list[i] = listCreate(); 21 if (i == 0) continue; /* Thread 0 is the main thread. */ 22 23 /* Things we do only for the additional threads. */ 24 pthread_t tid; 25 pthread_mutex_init(\u0026amp;io_threads_mutex[i],NULL); 26 setIOPendingCount(i, 0); 27 pthread_mutex_lock(\u0026amp;io_threads_mutex[i]); /* Thread will be stopped. */ 28 if (pthread_create(\u0026amp;tid,NULL,IOThreadMain,(void*)(long)i) != 0) { 29 serverLog(LL_WARNING,\u0026#34;Fatal: Can\u0026#39;t initialize IO thread.\u0026#34;); 30 exit(1); 31 } 32 io_threads[i] = tid; 33 } 34} 使用 pthread_create 创建线程线程，IOThreadMain 是对应线程的处理函数。\n这个函数先不展开，等后面处理网络读写的时候，会提到。\n回到 main 函数里，继续往下走，最后会调用 aeMain 来阻塞当前线程，然后处理网络。\n1void aeMain(aeEventLoop *eventLoop) { 2 eventLoop-\u0026gt;stop = 0; 3 while (!eventLoop-\u0026gt;stop) { 4 aeProcessEvents(eventLoop, AE_ALL_EVENTS| 5 AE_CALL_BEFORE_SLEEP| 6 AE_CALL_AFTER_SLEEP); 7 } 8} aeProcessEvents 中处理之前 添加的 aeEvent 事件回调\n1int aeProcessEvents(aeEventLoop *eventLoop, int flags) 2{ 3 int processed = 0, numevents; 4 5 /* Nothing to do? return ASAP */ 6 if (!(flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_FILE_EVENTS)) return 0; 7 8 if (eventLoop-\u0026gt;maxfd != -1 || 9 ((flags \u0026amp; AE_TIME_EVENTS) \u0026amp;\u0026amp; !(flags \u0026amp; AE_DONT_WAIT))) { 10 int j; 11 struct timeval tv, *tvp = NULL; /* NULL means infinite wait. */ 12 int64_t usUntilTimer; 13 //检查beforesleep函数指针,如果有对应的函数,调用这个函数 14 if (eventLoop-\u0026gt;beforesleep != NULL \u0026amp;\u0026amp; (flags \u0026amp; AE_CALL_BEFORE_SLEEP)) 15 eventLoop-\u0026gt;beforesleep(eventLoop); 16 17 if ((flags \u0026amp; AE_DONT_WAIT) || (eventLoop-\u0026gt;flags \u0026amp; AE_DONT_WAIT)) { 18 tv.tv_sec = tv.tv_usec = 0; 19 tvp = \u0026amp;tv; 20 } else if (flags \u0026amp; AE_TIME_EVENTS) { 21 usUntilTimer = usUntilEarliestTimer(eventLoop); 22 if (usUntilTimer \u0026gt;= 0) { 23 tv.tv_sec = usUntilTimer / 1000000; 24 tv.tv_usec = usUntilTimer % 1000000; 25 tvp = \u0026amp;tv; 26 } 27 } 28 29 numevents = aeApiPoll(eventLoop, tvp); 30 31 /* Don\u0026#39;t process file events if not requested. */ 32 if (!(flags \u0026amp; AE_FILE_EVENTS)) { 33 numevents = 0; 34 } 35 36 //检查aftersleep函数指针,如果有对应的函数,调用这个函数 37 if (eventLoop-\u0026gt;aftersleep != NULL \u0026amp;\u0026amp; flags \u0026amp; AE_CALL_AFTER_SLEEP) 38 eventLoop-\u0026gt;aftersleep(eventLoop); 39 //检查就绪的事件,然后做对应的处理 40 for (j = 0; j \u0026lt; numevents; j++) { 41 int fd = eventLoop-\u0026gt;fired[j].fd; 42 aeFileEvent *fe = \u0026amp;eventLoop-\u0026gt;events[fd]; 43 int mask = eventLoop-\u0026gt;fired[j].mask; 44 int fired = 0; /* Number of events fired for current fd. */ 45 46 int invert = fe-\u0026gt;mask \u0026amp; AE_BARRIER; 47 //需要翻转的话,先处理读的回调函数 48 if (!invert \u0026amp;\u0026amp; fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_READABLE) { 49 fe-\u0026gt;rfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); 50 fired++; 51 fe = \u0026amp;eventLoop-\u0026gt;events[fd]; /* Refresh in case of resize. */ 52 } 53 54 //如果有写事件,做回调 55 if (fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_WRITABLE) { 56 if (!fired || fe-\u0026gt;wfileProc != fe-\u0026gt;rfileProc) { 57 fe-\u0026gt;wfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); 58 fired++; 59 } 60 } 61 62 if (invert) {//如果之前没有处理读事件 63 fe = \u0026amp;eventLoop-\u0026gt;events[fd]; /* Refresh in case of resize. */ 64 if ((fe-\u0026gt;mask \u0026amp; mask \u0026amp; AE_READABLE) \u0026amp;\u0026amp; 65 (!fired || fe-\u0026gt;wfileProc != fe-\u0026gt;rfileProc)) 66 {//读回调函数指针和写回调函数指针不是同一个, 并且有读事件,回调读函数 67 fe-\u0026gt;rfileProc(eventLoop,fd,fe-\u0026gt;clientData,mask); 68 fired++; 69 } 70 } 71 72 processed++; 73 } 74 } 75 //如果有时间回调事件,回调时间的回调函数 76 if (flags \u0026amp; AE_TIME_EVENTS) 77 processed += processTimeEvents(eventLoop); 78 79 return processed; /* return the number of processed file/time events */ 80} beforeSleep 函数\nafterSleep 函数\n这两个函数内容非常多，很多和网络是无关的，不展开分析，后面有用的再回来介绍。\naeApiPoll 函数在不同的平台上有不同的实现，最终的目的是等待系统的回调事件。在 epoll 中是等待 epoll_wait 的回调。\n简单画图理解一下\n如图所示，redis虽然开启了多线程，但是每个连接还是在主线程中，而且处理命令也是在主线程中。\n那么在什么时候用到多线程，以及怎样使用呢。\n在上面的代码中也提到了，就是在网络IO中会用到多线程。\n如图：\n拿从网络中读取数据来举例，当图中的 client1 client2 client3 同时有数据需要读取的时候，这时候会把这三个 client的 fd 分配到空闲的线程中，由不同的线程来读取数据，把读到的数据写入 client 的 buff中。当所有的 fd 读取完成后， 然后在线程中，依次处理每个client。具体代码在下文中。\n网络读写处理 Listener 回调 之前在添加 listener 的时候，添加的是 AE_READABLE 事件， aeCreateFileEvent(server.el, sfd-\u0026gt;fd[j], AE_READABLE, accept_handler,sfd)\n所以，accept 的回调会在 可读的回调函数中。\naccept_handler指针是 connSocketAcceptHandler 函数\n1static void connSocketAcceptHandler(aeEventLoop *el, int fd, void *privdata, int mask) { 2 int cport, cfd, max = MAX_ACCEPTS_PER_CALL; 3 char cip[NET_IP_STR_LEN]; 4 UNUSED(el); 5 UNUSED(mask); 6 UNUSED(privdata); 7 8 while(max--) { 9 //把当前的 accept 的 fd 转换成一个TCP连接 10 cfd = anetTcpAccept(server.neterr, fd, cip, sizeof(cip), \u0026amp;cport); 11 if (cfd == ANET_ERR) { 12 if (errno != EWOULDBLOCK) 13 serverLog(LL_WARNING, 14 \u0026#34;Accepting client connection: %s\u0026#34;, server.neterr); 15 return; 16 } 17 serverLog(LL_VERBOSE,\u0026#34;Accepted %s:%d\u0026#34;, cip, cport); 18 acceptCommonHandler(connCreateAcceptedSocket(cfd, NULL),0,cip); 19 } 20} 在 anetTcpAccept 中 调用 anetGenericAccept 函数， 在函数中\n1#ifdef HAVE_ACCEPT4 2 fd = accept4(s, sa, len, SOCK_NONBLOCK | SOCK_CLOEXEC); 3#else 4 fd = accept(s,sa,len); 5#endif 最终通过 accept4 或者 accept 系统调用，接受一个新的TCP链接。\n最后调用 acceptCommonHandler 函数, 这个函数里会调用 createClient(conn) 来创建一个 client\n在 createClient 中，关注这段函数\n1 client *c = zmalloc(sizeof(client)); 2 if (conn) { 3 connEnableTcpNoDelay(conn); 4 if (server.tcpkeepalive) 5 connKeepAlive(conn,server.tcpkeepalive); 6 //把当前的conn加入到 eventPool中,并且把 readQueryFromClient 设置为回调函数 7 connSetReadHandler(conn, readQueryFromClient); 8 connSetPrivateData(conn, c); 9 } 10 //初始化client的buffer 11 c-\u0026gt;buf = zmalloc_usable(PROTO_REPLY_CHUNK_BYTES, \u0026amp;c-\u0026gt;buf_usable_size); 12 selectDb(c,0); 13 uint64_t client_id; connEnableTcpNoDelay 最终会调用 anet.c中的 anetSetTcpNoDelay 函数，来完成对TCP连接的设置。\nconnKeepAlive 最终调用到 anet.c中的 anetKeepAlive 对 KeepAlive 的设置\nconnSetReadHandler 通过这个函数，完成把 该TCP连接的 fd 加入的 eventLoop 中进行管理。\n1static inline int connSetReadHandler(connection *conn, ConnectionCallbackFunc func) { 2 return conn-\u0026gt;type-\u0026gt;set_read_handler(conn, func); 3} 通过 set_read_handler 这个函数指针调用到 socket.c 中的 connSocketSetReadHandler 函数\n1static int connSocketSetReadHandler(connection *conn, ConnectionCallbackFunc func) { 2 if (func == conn-\u0026gt;read_handler) return C_OK; 3 4 conn-\u0026gt;read_handler = func; 5 if (!conn-\u0026gt;read_handler) 6 aeDeleteFileEvent(server.el,conn-\u0026gt;fd,AE_READABLE); 7 else 8 if (aeCreateFileEvent(server.el,conn-\u0026gt;fd, 9 AE_READABLE,conn-\u0026gt;type-\u0026gt;ae_handler,conn) == AE_ERR) return C_ERR; 10 return C_OK; 11} 调用 aeCreateFileEvent 把当前的 conn 加入到 server.el 也就是启动redis时，创建的 aeEventPool 中。\n回到 createClient 函数中，connSetReadHandler(conn, readQueryFromClient); 第二参数传递的是 readQueryFromClient 这个函数的指针。这个函数 会赋值给 aeFileEvent 的 rfileProc 函数指针中。后续，如果这个 conn 有可读事件回调时，会使用 readQueryFromClient 这个函数来处理。\n到这里，一个新TCP连接的处理基本就完成了。\n处理client读写 读处理 当redis-server 收到client发来的数据后，也是通过 aeEventPool 来回调通知对应的 client来处理。\n上面我们说过了，client收到读事件的回调函数是 readQueryFromClient，当client对应的网络有可读事件触发时，会回调这个函数。\n1void readQueryFromClient(connection *conn) { 2 client *c = connGetPrivateData(conn); 3 int nread, big_arg = 0; 4 size_t qblen, readlen; 5 //判断一下,是否开启了IO线程,如果开启了那么会从IO线程读取数据 6 if (postponeClientRead(c)) return; 7 8 //读取次数 原子性的 +1 9 atomicIncr(server.stat_total_reads_processed, 1); 10 11 readlen = PROTO_IOBUF_LEN; 12 //如果是一个multi请求,那么调整一下缓冲区的大小 13 if (c-\u0026gt;reqtype == PROTO_REQ_MULTIBULK \u0026amp;\u0026amp; c-\u0026gt;multibulklen \u0026amp;\u0026amp; c-\u0026gt;bulklen != -1 14 \u0026amp;\u0026amp; c-\u0026gt;bulklen \u0026gt;= PROTO_MBULK_BIG_ARG) 15 { 16 ssize_t remaining = (size_t)(c-\u0026gt;bulklen+2)-(sdslen(c-\u0026gt;querybuf)-c-\u0026gt;qb_pos); 17 big_arg = 1; 18 19 if (remaining \u0026gt; 0) readlen = remaining; 20 21 if (c-\u0026gt;flags \u0026amp; CLIENT_MASTER \u0026amp;\u0026amp; readlen \u0026lt; PROTO_IOBUF_LEN) 22 readlen = PROTO_IOBUF_LEN; 23 } 24 25 qblen = sdslen(c-\u0026gt;querybuf); 26 if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; 27 (big_arg || sdsalloc(c-\u0026gt;querybuf) \u0026lt; PROTO_IOBUF_LEN)) { 28 c-\u0026gt;querybuf = sdsMakeRoomForNonGreedy(c-\u0026gt;querybuf, readlen); 29 if (c-\u0026gt;querybuf_peak \u0026lt; qblen + readlen) c-\u0026gt;querybuf_peak = qblen + readlen; 30 } else { 31 c-\u0026gt;querybuf = sdsMakeRoomFor(c-\u0026gt;querybuf, readlen); 32 33 readlen = sdsavail(c-\u0026gt;querybuf); 34 } 35 36 //从网络中读取数据,如果是 socket,使用 connSocketRead 函数 37 nread = connRead(c-\u0026gt;conn, c-\u0026gt;querybuf+qblen, readlen); 38 if (nread == -1) { 39 if (connGetState(conn) == CONN_STATE_CONNECTED) { 40 return; 41 } else { 42 serverLog(LL_VERBOSE, \u0026#34;Reading from client: %s\u0026#34;,connGetLastError(c-\u0026gt;conn)); 43 freeClientAsync(c); 44 goto done; 45 } 46 } else if (nread == 0) { 47 if (server.verbosity \u0026lt;= LL_VERBOSE) { 48 sds info = catClientInfoString(sdsempty(), c); 49 serverLog(LL_VERBOSE, \u0026#34;Client closed connection %s\u0026#34;, info); 50 sdsfree(info); 51 } 52 freeClientAsync(c); 53 goto done; 54 } 55 56 sdsIncrLen(c-\u0026gt;querybuf,nread); 57 qblen = sdslen(c-\u0026gt;querybuf); 58 if (c-\u0026gt;querybuf_peak \u0026lt; qblen) c-\u0026gt;querybuf_peak = qblen; 59 60 c-\u0026gt;lastinteraction = server.unixtime; 61 if (c-\u0026gt;flags \u0026amp; CLIENT_MASTER) { 62 c-\u0026gt;read_reploff += nread; 63 atomicIncr(server.stat_net_repl_input_bytes, nread); 64 } else { 65 atomicIncr(server.stat_net_input_bytes, nread); 66 } 67 68 if (!(c-\u0026gt;flags \u0026amp; CLIENT_MASTER) \u0026amp;\u0026amp; sdslen(c-\u0026gt;querybuf) \u0026gt; server.client_max_querybuf_len) { 69 sds ci = catClientInfoString(sdsempty(),c), bytes = sdsempty(); 70 71 bytes = sdscatrepr(bytes,c-\u0026gt;querybuf,64); 72 serverLog(LL_WARNING,\u0026#34;Closing client that reached max query buffer length: %s (qbuf initial bytes: %s)\u0026#34;, ci, bytes); 73 sdsfree(ci); 74 sdsfree(bytes); 75 freeClientAsync(c); 76 goto done; 77 } 78 //处理读到的数据,尝试解析RESP协议 79 if (processInputBuffer(c) == C_ERR) 80 c = NULL; 81 82done: 83 beforeNextClient(c); 84} 在这个函数中判断是否需要使用多线程。\n1int postponeClientRead(client *c) { 2 //在这里判断是否需要使用多线程从网络读取数据 3 if (server.io_threads_active \u0026amp;\u0026amp; 4 server.io_threads_do_reads \u0026amp;\u0026amp; 5 !ProcessingEventsWhileBlocked \u0026amp;\u0026amp; 6 !(c-\u0026gt;flags \u0026amp; (CLIENT_MASTER|CLIENT_SLAVE|CLIENT_BLOCKED)) \u0026amp;\u0026amp; 7 io_threads_op == IO_THREADS_OP_IDLE) 8 { 9 //如果需要多线程读取,把当前client加入到`clients_pending_read`中,等待后续调用 10 listAddNodeHead(server.clients_pending_read,c); 11 c-\u0026gt;pending_read_list_node = listFirst(server.clients_pending_read); 12 return 1; 13 } else { 14 return 0; 15 } 16} 在配置文件中\nio-threads IO线程数量,默认只有一个，也就是不用多线程读写网络 io-threads-do-reads 是否开启多线程读和解析RESP功能，如果不开启，那么多线程只会处理写 如果只有一个client就绪（也就是没有并发请求）时，即使开了多线程和IO线程读，也不会使用多线程去读网络，只有当多个client同时读写数据，这时候会在 handleClientsWithPendingReadsUsingThreads 中开启 多线程处理。\n开启多线程读写\n1if (!server.io_threads_active) startThreadedIO(); 此时，当client读事件就绪后，再次回调 readQueryFromClient 函数后，会进入 listAddNodeHead(server.clients_pending_read,c); 加入链表，等待IO线程处理\n如果需要多线程\n在主线程里调用 使用 aeEventPool 的 beforesleep 函数指针调用 beforeSleep 函数来执行 sleep前的处理函数，然后在调用 handleClientsWithPendingReadsUsingThreads 函数来判断是否需要使用多线程来读数据。\n最后的读取是由 readQueryFromClient 函数来完成数据的读取。\nreadQueryFromClient 函数可以通过 handleClientsWithPendingReadsUsingThreads 函数在主线程调用，也可以通过 IOThreadMain 函数通过IO线程并发读取。\n1//启动IO多线程读取数据 2io_threads_op = IO_THREADS_OP_READ; 3for (int j = 1; j \u0026lt; server.io_threads_num; j++) { 4 int count = listLength(io_threads_list[j]); 5 setIOPendingCount(j, count); 6} 7....... 8//等待IO线程读取完成 9while(1) { 10 unsigned long pending = 0; 11 for (int j = 1; j \u0026lt; server.io_threads_num; j++) 12 pending += getIOPendingCount(j); 13 if (pending == 0) break; 14} 当执行完 beforesleep 函数后，再由 aeFileEvent 的 rfileProc 函数指针调用 processInputBuffer 函数内主要是判断和解析字符串，就不展开分析了\n主要关注这部分逻辑\n1 if (c-\u0026gt;reqtype == PROTO_REQ_INLINE) { 2 //如果是一行的字符串,解析方式 3 if (processInlineBuffer(c) != C_OK) break; 4 } else if (c-\u0026gt;reqtype == PROTO_REQ_MULTIBULK) { 5 //如果是多行的,解析方式 6 if (processMultibulkBuffer(c) != C_OK) break; 7 } else { 8 serverPanic(\u0026#34;Unknown request type\u0026#34;); 9 } 10 11 //如果解析到的参数个数是0,那么说明还没有解析完成,重置client 12 if (c-\u0026gt;argc == 0) { 13 resetClient(c); 14 } else { 15 //判断一下是否在IO线程里,如果是的话,设置一下flag,然后结束. 16 //因为redis的多线程只能用来读写网络,操作redis的数据库还是用单线的 17 if (io_threads_op != IO_THREADS_OP_IDLE) { 18 serverAssert(io_threads_op == IO_THREADS_OP_READ); 19 c-\u0026gt;flags |= CLIENT_PENDING_COMMAND; 20 break; 21 } 22 23 //开始执行命令了 24 if (processCommandAndResetClient(c) == C_ERR) { 25 return C_ERR; 26 } 27 } 最终会调用 processCommand 函数执行命令\n执行命令的逻辑先不管，这不是本文的重点。\n写处理 当命令处理完成后，把有需要回复客户端的数据写入client的buf中。\n最后会调用 writeToClient 函数把 client buf 中的数据写入到网络中，完成数据返回。\nwriteToClient 有多个回调路径。但是都是由 aeEventpool 中的 aftersleep 函数指针 调用 beforeSleep 函数来完成的。\n在 beforeSleep 中调用 handleClientsWithPendingWritesUsingThreads 函数。\n这个函数也比较长，就不贴了，只挑一些重点的。这期贴了不少源码，一直看源码，也挺枯燥的。这个函数的大概逻辑和 handleClientsWithPendingReadsUsingThreads 函数的差不多，只不过这里处理的是写网络。\n1if (server.io_threads_num == 1 || stopThreadedIOIfNeeded()) { 2 return handleClientsWithPendingWrites(); 3} 这里判断一下，如果没有开启多线程或者停了IO线程，就使用 handleClientsWithPendingWrites 函数在主线程处理写逻辑。\nhandleClientsWithPendingWrites 里的逻辑很简单，遍历 server.clients_pending_write 中的client，然后调用 writeToClient 把数据写入到网络中。\n回到 handleClientsWithPendingWritesUsingThreads 函数中，调用 startThreadedIO() 启动 IO线程并发处理写入。\n1//在主线程中也会处理写入 2listRewind(io_threads_list[0],\u0026amp;li); 3while((ln = listNext(\u0026amp;li))) { 4 client *c = listNodeValue(ln); 5 writeToClient(c,0); 6} 7listEmpty(io_threads_list[0]); 8//和上面的多线程读一样,这里也会等待所有IO线程任务结束 9while(1) { 10 unsigned long pending = 0; 11 for (int j = 1; j \u0026lt; server.io_threads_num; j++) 12 pending += getIOPendingCount(j); 13 if (pending == 0) break; 14} 到这基本redis的整个网络处理流程大概就写完了。注意，这只是个大概，其中的一些细节还没有深入分析。比如在 aeProcessEvents 函数中，为什么有 beforesleep 和 aftersleep 这两个函数指针，以及调用两个函数中的先后调用顺序。 aeFileEvent 中 rfileProc 和 wfileProc 这两个函数指针的调用顺序，以及调用的函数的逻辑。每一个都可以拿出来单独写一篇。\n以后有时间在单独拿出来分析吧。如果有时间再这篇文章补一个流程图。\nredis用C写的，C对多态的支持不太好，不像面向对象的语言那样，可以很方便的使用多态。所以在redis的源码里，大量使用了函数指针和回调函数，来间接的实现了多态。这样会在阅读源码的时候增加了很多理解成本。\n但是鲁迅先生曾经说过，在断点面前，一切语法都是纸老虎。所以遇到复杂的函数调用逻辑，使用断点去看一下函数的调用关系，堆栈，基本都能解决问题。\n也快过年了，提前祝所有读者 新年快乐\n","date":"2024-01-28T20:10:27Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/OIP-C.R8n6zHAP4N2M01vSoRwkSQHaDW","permalink":"https://lqxhub.github.io/posts/bce71a0/","title":"redis源码学习|网络 redis 网络部分源码分析，学习。redis网络多路复用 - QX's blog"},{"content":"2023马上就结束了，在年底回忆总结一下今年的一些事情，顺便思考一下明年的一些计划。 以前每年我也会写一下，只是没有公开出来，今年想着公开一下，一些事情公开出来，可能还会有鞭策的作用 0.0\n还是从 生活 与 工作 两方面来写吧\n生活 今年没有口罩管控了，能出去玩，一些搁置了好久的事情终于可以做了。回想一下，毕业半年后就遇到了口罩，这几年一直没有怎么出去玩过，今年算是忙里偷闲出去玩了几次。\nLPL 今年，去看了一场 LPL 的线下赛，见到了shy哥。虽然那天shy哥输了。(WBG 不敌 RNG) 但是看到了 GALA 的卡莎五杀，也算值回票价了\n我也没有拍照的习惯，好多照片找不到了，就凑合放这两张吧\n演唱会 今年明星扎堆开演唱会，热闹的时候，上海一周好几场。有几个热门的没有抢到，但是抢到了 大张伟 的。不得不说，大张伟老师绝对没有假唱(手动狗头)现场氛围拉满，太嗨了。买的是演唱会的门票，还能现场听脱口秀，太值了。\n今年有几个没有抢到有点可惜。一个是 房东的猫 还一个是 陈粒 我比较喜欢的两个民谣歌手，还有 伍佰 没有抢到有点可惜，等下次有机会吧。至于 周董的，我都没抢过，我知道我抢不到。\n玩 今年没有管控了，可以自由出去玩了。以前我姐姐和妹妹就想来上海玩了，可惜以前不能说来就来，今年暑假终于有机会了。她们来上海玩了好几天，然后又一起去杭州玩了几天。暑假出去玩的缺点就是人多和太热，感觉杭州比上海还热。\n今年我一些同学也有来上海玩的，然后就是在上海豪饮，给旁边的人都看蒙了，你们这是什么喝法，一人奔着一箱啤酒喝0.0\n好久之前就计划着去重庆玩了，今年终于去了。十月底去的，为了避开国庆假期。去玩了三天，老年特种兵旅游，一天走三万步。整体感觉还是非常棒的，非常喜欢重庆的美食，也喜欢那里的生活氛围。如果只是生活的话，感觉比上海要舒适\n当时是一个人去的，去的时候认识了两个搭子（今年好像流行找搭子）为了保护隐私，不放她们照片了。出去玩了一圈，还认识了新的朋友，快乐又神奇。\n本来今年还计划秋天去一趟南京，看一场南京的落叶，因为一些事情没有去成。等到有空的时候，已经是冬季了。明年一定吧哈哈哈。\n🧑‍🤝‍🧑 去年结婚的同学多，但是我没办法回去。今年两个同学的婚礼都回去，还给一个同学还当了一次伴郎。\n至于我自己，还是一个人。去年就说今年努力，现在来看，明年还要继续努力。\n工作 今年工作算是比较忙，事情挺多的。整体看下来，也算是在工作和生活中找到了一个平衡点。工作这么多年了，很多事情处理起来也算是比较得心应手，今年在工作上算是没有遇到大的困难。去年算是给了我一个title，负责的事情多了。但是我感觉还是，处理代码比处理人际关系要简单，所以我现在也还是只管代码，不管人吧。\n我自己也知道，这些东西需要去突破，可能还是不想走出舒适圈。至于我不想管人，也不是说自己内向，或者不会说话，我想可能就是不想操心太多事吧，因为代码比人要简单，代码出问题了一定是我的问题，人就太复杂了。\n还有前几天，一张文件下来，直接给我吓尿了。我都在想，这要是真实施了，我怕不是要失业了。游戏还是太看政策了，希望一切稳中向好吧。\n今年工作中好像没有发生太多的事情，也没有太多想记录。就这样一笔带过吧\n开源社区 今年参与开源社区比较多，虽然以前也给开源项目提交过代码，但是没有像今年这样深度参与\n放一张 GitHub的 截图吧，虽远不及大佬们，对自己来说也是进步了。\n今年发现了 redis的一个bug，给他们提了 issue，原本还想修一下，混个pr呢。没想到，redis社区的大佬处理的太及时了，我晚上11点多左右提的issue，第二天我上班打开GitHub，发现那老哥（美国的）已经回复我了，确认那是bug，并且将bug修复了。就这样pr没混成🤣\n今年主要给 pika （将要改名为 pikiwidb）贡献代码。今年社区是雨哥在带领，社区发展很快，以前盼望的一些功能，今年实现了不少。\n这一年参与下来，收获还是很大的，也结识了不少大佬，后面继续参与开源社区，继续学习。\n感谢社区的肯定\n今年参与开源社区比较多，游戏也不怎么玩了，一年好像没有打开过几次游戏了。\n其他 也不知道这些怎么分类了，想到哪写到哪吧\n今年大A还是亏钱的一年，亏得肉疼。\n今年有一段时间还是焦虑，有时候还是失眠。至于在焦虑些什么我也说不上来。很多时候，可能看到一些事情，有些什么感想，有时候就会一个人在深夜的时候想很多。人总是劝别人容易，和自己和解却没有那么简单。有时候和我姐聊天，我还劝她，但是一些事情自己却会emo。今年听了很多李宗盛的歌，尤其是深夜的时候。\n就在昨天我一个大学同学来上海，两人吃完饭在街上溜达聊天，回去睡前也一直在聊，聊到凌晨一点多。从大学时候，聊到现在工作。从工作聊到家庭。从我俩聊到了一些其他的同学。最后感慨，很多时候就是命中注定。每个人的生活都有光鲜亮丽的一面，也有一地鸡毛的窘迫。\n这两年身边好多同学都结婚了，好多还有孩子。说是自己不着急，但有时候也会在想，自己什么时候能结婚呢。就是怎么说呢，别人都交卷了，我还没有开始答题。之前我想过，我一直在外地，算是一种逃避，逃避家里的催。一直这样逃避有点自私，只顾自己，没有考虑家人的感受以前总是听大人们是谁家孩子多大了，多大了，没想到我现在也成了别人口中谁家的孩子了。\n之前总是说工作忙，接触不到人作为借口。现在发现，这确实是一部分原因，但是自己也有一些问题。自己没有想着去改变，走出这个舒适圈，永远这样，永远不可能有改变。还有一部分原因，自己不善于处理人与人之间的关系。和家人还有那些熟悉的朋友之间还好，因为都熟悉了，很多事情知道该怎么做，他们也知道我的一些性格。相处起来就会简单很多。但是和一个不熟悉的人交流我就有点力不从心了。说是不擅长和陌生人交流吧，但是今年在开源社区，和很多人交流感觉却挺好的，可能是因为在讨论技术问题吧。今年我姐给我介绍了一个女孩认识，老家一个地方的，她也是在上海工作，接触下来感觉就是两个人没什么话聊，后来也就不怎么联系了，可能很大一部分原因在我吧。\n明年 明年尝试去改变一下吧，把自己的一些问题尝试去突破。把工作做好，多参与开源社区，多学习。\n明年有时间的话，还想出去玩一趟。至于去哪还没想好，西安，广州，厦门，北京，香港，武汉？到时候再定吧\n以前的时候，还计划着将来和那个她去重庆吃火锅，去鼓浪屿看海，去广州吃好吃的，去西安的城墙下散步等等好多地方。着等了这么多年还是没等到，我就自己先去了🤣\n今年好像没怎么读书，那明年要多读几本书，或者翻翻以前读的书。为故而知新嘛。\nGood luck next year\n","date":"2023-12-25T19:26:56Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/1703414244771.jpg","permalink":"https://lqxhub.github.io/posts/f5a4584b/","title":"我的2023"},{"content":"在C++使用动态库，(linux下是.so，windows下是.dll) 比较常见的方式是在编译时，直接连接到程序中。但是除了这种方式外，还可以使用的动态加载的方式去使用动态库。\n两种方式的区别 在编译时把库连接到程序：这种方式是在编译的时候，就确定了要链接的库文件，然后通过编译参数在链接时直接把动态库的地址空间等等信息连接到程序中。程序在运行时，可以直接根据路径去寻找动态库，然后加载到程序中，然后运行，这种方式在日常开发中用的比较多。\n在程序运行时动态加载库：这种方式是在程序运行时，通过调用系统函数，把动态库加载到程序中，然后执行动态库中的代码。这种方式和编译时链接的优势是可以在程序运行的过程中动态加载和卸载库。可以在不修改源程序的前提下，使用新的库。这种方式，比较常见的应用是程序的插件系统。还有一个就是服务器的热更可以用这个来实现。\n在编译时使用动态库的例子传送门\n动态加载库 不废话了，直接开始上代码\n在程序运行的过程中动态加载库，需要依赖操作系统，所以在不同的系统上有不同的系统调用函数。\n在linux 上需要用到 dlopen 函数加载库，dlclose 函数释放库，dlsym 函数 查找库函数 需要的头文件 #include \u0026lt;dlfcn.h\u0026gt;\n在windows 上需要 LoadLibrary 宏加载库，FreeLibrary 宏释放库，GetProcAddress 函数查找库函数 需要的头文件 #include \u0026lt;windows.h\u0026gt;\n基类功能 在C++中可以通过定义一个抽象类来作为所有库的基类，所有的库文件都实现这个基类，然后重写基类的纯虚函数。可以在加载到所有库后，都可以把库里的类作为抽象类的派生类。\n先定义一个基类 base.h\n1#ifndef DLOAD_BASE_H 2#define DLOAD_BASE_H 3 4/** 5 * 必须实现 moduleName_create 函数,来初始化对象 6 * extern \u0026#34;C\u0026#34; Base *module1_create() { 7 * return new Module; 8 * } 9 * 10 * //必须实现 moduleName_destroy 函数,来回收对象 11 * extern \u0026#34;C\u0026#34; void module1_destroy(Base *obj) { 12 * delete obj; 13 * } 14 */ 15 16 17class Base { 18 public: 19 virtual std::string readLine(const std::string \u0026amp;) = 0; 20 21 virtual ~Base() = default; 22}; 23 24#endif //DLOAD_BASE_H 这个基类的功能很简单，只有一个纯虚函数readLine 这个函数会传入一个字符串，然后返回一个字符串\n注释中的哪两个函数，后面会有详细的介绍\n实现一个模块 可以把一个库看做是一个模块，现在实现一个模块\n1//简单的模块 例子 2//转大写 3 4#include \u0026lt;algorithm\u0026gt; 5#include \u0026lt;string\u0026gt; 6#include \u0026#34;../base.h\u0026#34; 7 8class Module1 : public Base { 9 std::string readLine(const std::string \u0026amp;str) override { 10 std::string str2(str); 11 std::transform(str.begin(), str.end(), str2.begin(), ::toupper); 12 return str2; 13 } 14}; 15 16//必须实现 moduleName_create 函数,来初始化对象 17extern \u0026#34;C\u0026#34; Base *module1_create() { 18 return new Module1; 19} 20 21//必须实现 moduleName_destroy 函数,来回收对象 22extern \u0026#34;C\u0026#34; void module1_destroy(Base *obj) { 23 delete obj; 24} 这个功能非常简单，把传入的字符串转成大写，然后返回\n为什么需要 Base *module1_create() 和 void module1_destroy(Base *obj) 这两个函数 因为在把库加载完成后，需要使用库里的函数，但是不能直接查找C++的类，然后再初始化对象，只能在库里完成C++对象的初始化，然后返回对象的指针。\n所以需要在库里有对应的函数来初始化对象和回收对象，所以就有了这两个函数。\n为什么要 extern \u0026quot;C\u0026quot; 因为C++有函数重载的功能，所以编译器在编译代码的时候，会对函数重命名。但是对函数重命名的规则，没有统一的标准，不同编译器有不同的规则。像 module1_create 这个函数可能就被重命名成 _Z14module1_create这样的字符串。这样后面使用 dlsym 或者 GetProcAddress 函数查找库里的函数时，就没法找到对应的函数了。所以使用extern \u0026quot;C\u0026quot; 让编译器使用C的规则来编译这段函数\n至于这两个函数的名字 module1_create 和 module1_destroy 没有强制的要求，但是要有一定的规范。否则在加载到库后，没法根据函数名查找到对应的函数。这里用到的规则是 模块名_create 和 模块名_destroy\n加载库 下面开始加载库，因为在同的系统下，加载库调用的函数不同，所以使用 宏来完成不用系统下的条件编译，最终完成加载库\n1//声明创建对象的函数 2typedef Base *(*create)(); 3 4//声明回收对象的函数 5typedef void (*destroy)(Base *); 6 7//调用系统函数,加载动态库 8 9#ifdef _WIN32 10 11HINSTANCE loadLib(Base **base, const char *path, const char *funName) { 12 auto handle = LoadLibrary(path); 13 if (!handle) { 14 return nullptr; 15 } 16 auto cr = (create) GetProcAddress(handle, funName); 17 if (cr) { 18 *base = cr(); 19 } 20 return handle; 21} 22 23//调用系统函数,卸载动态库 24void freeLib(HINSTANCE handle, Base *obj, const char *funName) { 25 auto free = (destroy) GetProcAddress(handle, funName); 26 if (free) { 27 free(obj); 28 } 29 FreeLibrary(handle); 30} 31 32#else 33 34void *loadLib(Base **base, const char *path, const char *funName) { 35 auto handle = dlopen(path, RTLD_LAZY); 36 if (!handle) { 37 return nullptr; 38 } 39 auto cr = (create) dlsym(handle, funName); 40 if (cr) { 41 *base = cr(); 42 } 43 return handle; 44} 45 46//调用系统函数,卸载动态库 47void freeLib(void *handle, Base *obj, const char *funName) { 48 auto free = (destroy) dlsym(handle, funName); 49 if (free) { 50 free(obj); 51 } 52 dlclose(handle); 53} 54 55#endif 在代码最开始的位置，通过 typedef 声明了两个函数的指针，在查找到函数后，把函数强转成对应的类型，才能在后面使用\n使用库 1 2int main() { 3 std::string libPath; 4#ifdef _WIN32 5 libPath = std::string(\u0026#34;./module/libmodule1\u0026#34; + \u0026#34;.dll\u0026#34;); 6#else 7 libPath = std::string(\u0026#34;./module/libmodule1\u0026#34; + \u0026#34;.so\u0026#34;); 8#endif 9 Base *module = nullptr; 10 auto handle = loadLib(\u0026amp;module, libPath.c_str(), std::string(\u0026#34;module1_create\u0026#34;).c_str()); 11 12 if (!module) { 13 std::cout \u0026lt;\u0026lt; \u0026#34;load lib module1\u0026#34; \u0026lt;\u0026lt; \u0026#34; fail\u0026#34; \u0026lt;\u0026lt; std::endl; 14 return 1; 15 } 16 std::cout \u0026lt;\u0026lt; module-\u0026gt;readLine(\u0026#34;abc\u0026#34;) \u0026lt;\u0026lt; std::endl; 17 18 return 0; 19} 现在基本就完成了一个动态库的动态加载过程。如果想要拓展，只要再按照这个规则，写一个新的模块然后加载上来就可以了。\n最后放一个相对完整的动态加载的demo，github\n","date":"2023-07-22T21:56:18Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/7e0d79d47f0173b9b7a0c351c5d719303aa0f0e8.png","permalink":"https://lqxhub.github.io/posts/b810e905/","title":"C++中动态加载共享库，使用.so/dll文件。详细讲解编译时链接与运行时动态加载的区别"},{"content":"Redis 在6.0 中加入了ACL（Access Control List) 的支持，在此前的版本中,Redis是没有用户的概念的，没有办法很好的控制权限，在6.0中加入了用户的概念，可以给每个用户分配不同的权限来控制权限。\nACL作用 ACL的作用就是对不同用户的权限做限制，限制不同用户的权限。比如限制某些用户使用删除命令，限制某些用户只能使用读命令等等。在 6.0 之前，redis没有用户的概念，是不能做具体用户的限制的，如果有的用户执行了 FLUSHALL 命令，那么整个库的数据都没有了，这样是有风险的。 ACL命令 redis还是使用原来的 AUTH 命令来进行认证，这个命令做了对低版本的兼容\n6.0 及以后版本 AUTH \u0026lt;username\u0026gt; \u0026lt;password\u0026gt; 6.0 之前版本 AUTH \u0026lt;password\u0026gt; 在使用 AUTH \u0026lt;password\u0026gt; 这个命令时，使用的是redis的默认用户，redis ACL 中初始化了一个默认用户default 这样就实现了对低版本的兼容。在 6.0 以后的版本中使用 AUTH \u0026lt;password\u0026gt; 这个命令时，实际上是对default用户做了认证。\nACL是使用 DSL（domain specific language）定义的，该 DSL 描述了给定用户能够执行的操作。此类规则始终从左到右从第一个到最后一个实施，因为有时规则的顺序对于理解用户的实际能力很重要。\nACL 简单的语法\n看一下当前用户\n1127.0.0.1:6379\u0026gt; acl list 21) \u0026#34;user default on nopass ~* \u0026amp;* +@all\u0026#34; default 用户名 on 表示用户是激活的，如果是 off那么这个用户无法通过 AUTH 命令 nopass 表示这个用户没有密码 ~* 表示可以访问的Key（正则匹配） \u0026amp;* 6.2 加入的，表示channel的权限 +@ 表示用户的权限，“+”表示授权权限，有权限操作或访问，“-”表示还是没有权限； @为权限分类，可以通过 ACL CAT 查询支持的分类。+@all 表示所有权限，nocommands 表示不给与任何命令的操作权限 用户权限分类\n1 \u0026#34;keyspace\u0026#34; 2 \u0026#34;read\u0026#34; 3 \u0026#34;write\u0026#34; 4 \u0026#34;set\u0026#34; 5 \u0026#34;sortedset\u0026#34; 6 \u0026#34;list\u0026#34; 7 \u0026#34;hash\u0026#34; 8 \u0026#34;string\u0026#34; 9 \u0026#34;bitmap\u0026#34; 10 \u0026#34;hyperloglog\u0026#34; 11 \u0026#34;geo\u0026#34; 12 \u0026#34;stream\u0026#34; 13 \u0026#34;pubsub\u0026#34; 14 \u0026#34;admin\u0026#34; 15 \u0026#34;fast\u0026#34; 16 \u0026#34;slow\u0026#34; 17 \u0026#34;blocking\u0026#34; 18 \u0026#34;dangerous\u0026#34; 19 \u0026#34;connection\u0026#34; 20 \u0026#34;transaction\u0026#34; 21 \u0026#34;scripting\u0026#34; 至于怎么操作，不是这次的重点，直接去看官方文档就好了 redis acl\nACL源码 开始上源码了，本次源码基于redis的 7.0.11版本，不同的版本之间可能有差异。\nACL相关的数据结构 ACL鉴权对应的是一个User，先看一下User和相关的selector的定义\n1typedef struct { 2 //用户名 3 sds name; /* The username as an SDS string. */ 4 5 //用户的flag,用来做各种比对 6 uint32_t flags; /* See USER_FLAG_* */ 7 8 //这个用户的密码，一个用户可以有多个密码，所以是用链表保存的 9 //这个链表的node是一个明文密码经过 `SHA256` 计算过后的 字符串 10 list *passwords; /* A list of SDS valid passwords for this user. */ 11 12 //验证用户权限的选择器，该用户的权限保存在这个链表中 13 list *selectors; /* A list of selectors this user validates commands 14 against. This list will always contain at least 15 one selector for backwards compatibility. */ 16 //缓存ACL命令的字符串 17 robj *acl_string; /* cached string represent of ACLs */ 18} user; 19 20 21//user中 `selectors` 链表中的结构 22typedef struct { 23 //这个 selectors 的flag 24 uint32_t flags; /* See SELECTOR_FLAG_* */ 25 26 /* The bit in allowed_commands is set if this user has the right to 27 * execute this command. 28 * If the bit for a given command is NOT set and the command has 29 * allowed first-args, Redis will also check allowed_firstargs in order to 30 * understand if the command can be executed. */ 31 32 //使用 bit 记录允许的命令 33 uint64_t allowed_commands[USER_COMMAND_BITS_COUNT/64]; 34 35 /* allowed_firstargs is used by ACL rules to block access to a command unless a 36 * specific argv[1] is given. 37 * 38 * For each command ID (corresponding to the command bit set in allowed_commands), 39 * This array points to an array of SDS strings, terminated by a NULL pointer, 40 * with all the first-args that are allowed for this command. When no first-arg 41 * matching is used, the field is just set to NULL to avoid allocating 42 * USER_COMMAND_BITS_COUNT pointers. */ 43 44 sds **allowed_firstargs; 45 46 //redis key 匹配规则的字符串链表 47 list *patterns; /* A list of allowed key patterns. If this field is NULL 48 the user cannot mention any key in a command, unless 49 the flag ALLKEYS is set in the user. */ 50 51 //redis channels 规则的字符串 链表 52 list *channels; /* A list of allowed Pub/Sub channel patterns. If this 53 field is NULL the user cannot mention any channel in a 54 `PUBLISH` or [P][UNSUBSCRIBE] command, unless the flag 55 ALLCHANNELS is set in the user. */ 56} aclSelector; 57 58 59/* Structure used for handling key patterns with different key 60 * based permissions. */ 61//`aclSelector` 中 patterns 链表中的结构 62typedef struct { 63 int flags; /* The CMD_KEYS_* flags for this key pattern */ 64 sds pattern; /* The pattern to match keys against */ 65} keyPattern; user源码\naclSelector源码\naclSelector 结构先有个大概的了解即可，后面在权限校验的那部分会有详细的分析\nACL的初始化 ACL的初始化在ACLInit函数中完成\n1void ACLInit(void) { 2 Users = raxNew(); 3 UsersToLoad = listCreate(); 4 listSetMatchMethod(UsersToLoad, ACLListMatchLoadedUser); 5 ACLLog = listCreate(); 6 DefaultUser = ACLCreateDefaultUser(); 7} ACLInit\nACLInit这个函数在 main 函数中被调用，也就是在redis启动的时候，就会初始化ACL的数据结构\n所有的用户都存在Users这个全局变量中，这个变量是rax类型的\nUsersToLoad 记录了从配置文件中加载的用户\nACLLog ACL操作相关的log\nDefaultUser 特殊的用户，default用户\n会使用 ACLCreateDefaultUser 这个函数初始化default这个用户\n1user *ACLCreateDefaultUser(void) { 2 user *new = ACLCreateUser(\u0026#34;default\u0026#34;,7); 3 ACLSetUser(new,\u0026#34;+@all\u0026#34;,-1); 4 ACLSetUser(new,\u0026#34;~*\u0026#34;,-1); 5 ACLSetUser(new,\u0026#34;\u0026amp;*\u0026#34;,-1); 6 ACLSetUser(new,\u0026#34;on\u0026#34;,-1); 7 ACLSetUser(new,\u0026#34;nopass\u0026#34;,-1); 8 return new; 9} ACLCreateDefaultUser\n创建一个用户是在ACLCreateUser 这个函数中完成的\n1user *ACLCreateUser(const char *name, size_t namelen) { 2 //先判断一下这个鱼护是否存在,如果存在了直接return 3 if (raxFind(Users,(unsigned char*)name,namelen) != raxNotFound) return NULL; 4 user *u = zmalloc(sizeof(*u)); 5 u-\u0026gt;name = sdsnewlen(name,namelen); 6 //新创建的用户默认都是不能使用的 7 u-\u0026gt;flags = USER_FLAG_DISABLED; 8 u-\u0026gt;passwords = listCreate(); 9 u-\u0026gt;acl_string = NULL; 10 listSetMatchMethod(u-\u0026gt;passwords,ACLListMatchSds); 11 listSetFreeMethod(u-\u0026gt;passwords,ACLListFreeSds); 12 listSetDupMethod(u-\u0026gt;passwords,ACLListDupSds); 13 14 u-\u0026gt;selectors = listCreate(); 15 listSetFreeMethod(u-\u0026gt;selectors,ACLListFreeSelector); 16 listSetDupMethod(u-\u0026gt;selectors,ACLListDuplicateSelector); 17 18 /* Add the initial root selector */ 19 aclSelector *s = ACLCreateSelector(SELECTOR_FLAG_ROOT); 20 listAddNodeHead(u-\u0026gt;selectors, s); 21 22 raxInsert(Users,(unsigned char*)name,namelen,u,NULL); 23 return u; 24} ACLCreateUser\n到这，default 用户的初始化就完成了\n后面会从配置文件中加载其他用户的数据，完成其他用户的初始化\n在main 函数中调用 ACLLoadUsersAtStartup 完成从配置文件中加载用户\n在此之前会先使用ACLAppendUserForLoading 函数完成从 redis.conf 中加载用户。因为redis中的用户既可以配置在redis.conf中，也可以配置在一个单独的ACL文件中（两者只能选择其中一个，不能同时启用）。这个函数是从redis.conf中加载用户\n最终把从配置文件中加载的用户都放到UsersToLoad 这个链表中\nACLAppendUserForLoading\n完成加载后，会调用ACLLoadUsersAtStartup 完成用户信息的初始化\n1void ACLLoadUsersAtStartup(void) { 2 //先判断一下,如果配置了ACL文件的同时，又在redis.conf 中配置了用户，那么redis启动会失败 3 //ACL的配置只能在一个里面配置 4 if (server.acl_filename[0] != \u0026#39;\\0\u0026#39; \u0026amp;\u0026amp; listLength(UsersToLoad) != 0) { 5 serverLog(LL_WARNING, 6 \u0026#34;Configuring Redis with users defined in redis.conf and at \u0026#34; 7 \u0026#34;the same setting an ACL file path is invalid. This setup \u0026#34; 8 \u0026#34;is very likely to lead to configuration errors and security \u0026#34; 9 \u0026#34;holes, please define either an ACL file or declare users \u0026#34; 10 \u0026#34;directly in your redis.conf, but not both.\u0026#34;); 11 exit(1); 12 } 13 14 //处理从redis配置文件中加载的用户 15 if (ACLLoadConfiguredUsers() == C_ERR) { 16 serverLog(LL_WARNING, 17 \u0026#34;Critical error while loading ACLs. Exiting.\u0026#34;); 18 exit(1); 19 } 20 21 //处理从acl文件中加载的用户 22 if (server.acl_filename[0] != \u0026#39;\\0\u0026#39;) { 23 sds errors = ACLLoadFromFile(server.acl_filename); 24 if (errors) { 25 serverLog(LL_WARNING, 26 \u0026#34;Aborting Redis startup because of ACL errors: %s\u0026#34;, errors); 27 sdsfree(errors); 28 exit(1); 29 } 30 } 31} ACLLoadUsersAtStartup\n从配置文件中加载的逻辑，需要完成用户加载和用户信息的初始化（用户的密码，flag，selectors规则等）\n1int ACLLoadConfiguredUsers(void) { 2 listIter li; 3 listNode *ln; 4 listRewind(UsersToLoad,\u0026amp;li); 5 //遍历UsersToLoad这个链表 完成信息初始化 6 while ((ln = listNext(\u0026amp;li)) != NULL) { 7 sds *aclrules = listNodeValue(ln); 8 sds username = aclrules[0]; 9 10 if (ACLStringHasSpaces(aclrules[0],sdslen(aclrules[0]))) { 11 serverLog(LL_WARNING,\u0026#34;Spaces not allowed in ACL usernames\u0026#34;); 12 return C_ERR; 13 } 14 15 user *u = ACLCreateUser(username,sdslen(username)); 16 //做用户去重，一个用户只允许有一个 17 if (!u) { 18 /* Only valid duplicate user is the default one. */ 19 serverAssert(!strcmp(username, \u0026#34;default\u0026#34;)); 20 u = ACLGetUserByName(\u0026#34;default\u0026#34;,7); 21 ACLSetUser(u,\u0026#34;reset\u0026#34;,-1); 22 } 23 24 /* Load every rule defined for this user. */ 25 26 //遍历得到的规则，把这些规则赋给user，完成user信息的初始化 27 for (int j = 1; aclrules[j]; j++) { 28 if (ACLSetUser(u,aclrules[j],sdslen(aclrules[j])) != C_OK) { 29 const char *errmsg = ACLSetUserStringError(); 30 serverLog(LL_WARNING,\u0026#34;Error loading ACL rule \u0026#39;%s\u0026#39; for \u0026#34; 31 \u0026#34;the user named \u0026#39;%s\u0026#39;: %s\u0026#34;, 32 aclrules[j],aclrules[0],errmsg); 33 return C_ERR; 34 } 35 } 36 37 /* Having a disabled user in the configuration may be an error, 38 * warn about it without returning any error to the caller. */ 39 //完成信息初始后,判断一下这个用户是不是还是不可用的 40 if (u-\u0026gt;flags \u0026amp; USER_FLAG_DISABLED) { 41 serverLog(LL_NOTICE, \u0026#34;The user \u0026#39;%s\u0026#39; is disabled (there is no \u0026#34; 42 \u0026#34;\u0026#39;on\u0026#39; modifier in the user description). Make \u0026#34; 43 \u0026#34;sure this is not a configuration error.\u0026#34;, 44 aclrules[0]); 45 } 46 } 47 return C_OK; 48} ACLLoadConfiguredUsers\n从ACL文件中加载user代码比较多，下面会把一些不重要的（比如文件加载等等）删掉\n1sds ACLLoadFromFile(const char *filename) { 2 //这里会先把全局的 Users 保存到 old_users指针, 3 //然后重新 初始化一个 User,后面加载如果出错了,可以回滚 4 rax *old_users = Users; 5 Users = raxNew(); 6 7 //遍历文件中所有的行,开始加载user 8 for (int i = 0; i \u0026lt; totlines; i++) 9 ............ 省略读文件部分............... 10 //创建一个User 11 user *u = ACLCreateUser(argv[1],sdslen(argv[1])); 12 13 //如果用户已经存在了,跳过 14 if (!u) { 15 errors = sdscatprintf(errors,\u0026#34;WARNING: Duplicate user \u0026#39;%s\u0026#39; found on line %d. \u0026#34;, argv[1], linenum); 16 sdsfreesplitres(argv,argc); 17 continue; 18 } 19 20 /* Finally process the options and validate they can 21 * be cleanly applied to the user. If any option fails 22 * to apply, the other values won\u0026#39;t be applied since 23 * all the pending changes will get dropped. */ 24 int merged_argc; 25 26 //这个函数的作用是把读到的字符串,提取成具体的user属性的数组 27 sds *acl_args = ACLMergeSelectorArguments(argv + 2, argc - 2, \u0026amp;merged_argc, NULL); 28 if (!acl_args) { 29 errors = sdscatprintf(errors, 30 \u0026#34;%s:%d: Unmatched parenthesis in selector definition.\u0026#34;, 31 server.acl_filename, linenum); 32 } 33 34 int syntax_error = 0; 35 for (int j = 0; j \u0026lt; merged_argc; j++) { 36 acl_args[j] = sdstrim(acl_args[j],\u0026#34;\\t\\r\\n\u0026#34;); 37 //遍历上面得到的手势,给创建的user设置属性 38 if (ACLSetUser(u,acl_args[j],sdslen(acl_args[j])) != C_OK) { 39 const char *errmsg = ACLSetUserStringError(); 40 if (errno == ENOENT) { 41 /* For missing commands, we print out more information since 42 * it shouldn\u0026#39;t contain any sensitive information. */ 43 errors = sdscatprintf(errors, 44 \u0026#34;%s:%d: Error in applying operation \u0026#39;%s\u0026#39;: %s. \u0026#34;, 45 server.acl_filename, linenum, acl_args[j], errmsg); 46 } else if (syntax_error == 0) { 47 /* For all other errors, only print out the first error encountered 48 * since it might affect future operations. */ 49 errors = sdscatprintf(errors, 50 \u0026#34;%s:%d: %s. \u0026#34;, 51 server.acl_filename, linenum, errmsg); 52 syntax_error = 1; 53 } 54 } 55 } 56 57 for (int i = 0; i \u0026lt; merged_argc; i++) sdsfree(acl_args[i]); 58 zfree(acl_args); 59 60 /* Apply the rule to the new users set only if so far there 61 * are no errors, otherwise it\u0026#39;s useless since we are going 62 * to discard the new users set anyway. */ 63 if (sdslen(errors) != 0) { 64 sdsfreesplitres(argv,argc); 65 continue; 66 } 67 68 sdsfreesplitres(argv,argc); 69 } 70 71 sdsfreesplitres(lines,totlines); 72 73 /* Check if we found errors and react accordingly. */ 74 if (sdslen(errors) == 0) { 75 //判断一下,是否加载了新的`default` user,如果有的话把旧的default user释放掉,用新加载的 76 user *new_default = ACLGetUserByName(\u0026#34;default\u0026#34;,7); 77 if (!new_default) { 78 new_default = ACLCreateDefaultUser(); 79 } 80 81 ACLCopyUser(DefaultUser,new_default); 82 ACLFreeUser(new_default); 83 raxInsert(Users,(unsigned char*)\u0026#34;default\u0026#34;,7,DefaultUser,NULL); 84 raxRemove(old_users,(unsigned char*)\u0026#34;default\u0026#34;,7,NULL); 85 ACLFreeUsersSet(old_users); 86 sdsfree(errors); 87 return NULL; 88 } else { 89 //如果出错了,数据回滚 90 ACLFreeUsersSet(Users); 91 Users = old_users; 92 errors = sdscat(errors,\u0026#34;WARNING: ACL errors detected, no change to the previously active ACL rules was performed\u0026#34;); 93 return errors; 94 } 95} ACLLoadFromFile\n不管是从 配置文件中加载用户还是从ACL文件中加载用户，最终都会调用ACLSetUser 这个函数来完成 user 属性的初始化。使用redis的 ACL 命令来管理用户时也是通过这个函数来处理的。\n1int ACLSetUser(user *u, const char *op, ssize_t oplen) { 2 //第一步,先把以前的属性字符串删掉 3 if (u-\u0026gt;acl_string) { 4 decrRefCount(u-\u0026gt;acl_string); 5 u-\u0026gt;acl_string = NULL; 6 } 7 8 if (oplen == -1) oplen = strlen(op); 9 if (oplen == 0) return C_OK; /* Empty string is a no-operation. */ 10 if (!strcasecmp(op,\u0026#34;on\u0026#34;)) { 11 //设置 user 是 开启的 12 u-\u0026gt;flags |= USER_FLAG_ENABLED; 13 u-\u0026gt;flags \u0026amp;= ~USER_FLAG_DISABLED; 14 } else if (!strcasecmp(op,\u0026#34;off\u0026#34;)) { 15 //设置 user 是关闭的 16 u-\u0026gt;flags |= USER_FLAG_DISABLED; 17 u-\u0026gt;flags \u0026amp;= ~USER_FLAG_ENABLED; 18 } else if (!strcasecmp(op,\u0026#34;skip-sanitize-payload\u0026#34;)) { 19 u-\u0026gt;flags |= USER_FLAG_SANITIZE_PAYLOAD_SKIP; 20 u-\u0026gt;flags \u0026amp;= ~USER_FLAG_SANITIZE_PAYLOAD; 21 } else if (!strcasecmp(op,\u0026#34;sanitize-payload\u0026#34;)) { 22 u-\u0026gt;flags \u0026amp;= ~USER_FLAG_SANITIZE_PAYLOAD_SKIP; 23 u-\u0026gt;flags |= USER_FLAG_SANITIZE_PAYLOAD; 24 } else if (!strcasecmp(op,\u0026#34;nopass\u0026#34;)) { 25 u-\u0026gt;flags |= USER_FLAG_NOPASS; 26 listEmpty(u-\u0026gt;passwords); 27 } else if (!strcasecmp(op,\u0026#34;resetpass\u0026#34;)) { 28 u-\u0026gt;flags \u0026amp;= ~USER_FLAG_NOPASS; 29 listEmpty(u-\u0026gt;passwords); 30 } else if (op[0] == \u0026#39;\u0026gt;\u0026#39; || op[0] == \u0026#39;#\u0026#39;) { 31 //设置密码 32 sds newpass; 33 if (op[0] == \u0026#39;\u0026gt;\u0026#39;) { 34 //如果是明文,先转成sha256字符串 35 newpass = ACLHashPassword((unsigned char*)op+1,oplen-1); 36 } else { 37 //判断一下输入的值是不是有效的hash值 38 if (ACLCheckPasswordHash((unsigned char*)op+1,oplen-1) == C_ERR) { 39 errno = EBADMSG; 40 return C_ERR; 41 } 42 newpass = sdsnewlen(op+1,oplen-1); 43 } 44 45 listNode *ln = listSearchKey(u-\u0026gt;passwords,newpass); 46 //如果之前有这个密码,不用添加了,避免同一个密码添加多次 47 if (ln == NULL) 48 listAddNodeTail(u-\u0026gt;passwords,newpass); 49 else 50 sdsfree(newpass); 51 u-\u0026gt;flags \u0026amp;= ~USER_FLAG_NOPASS; 52 } else if (op[0] == \u0026#39;\u0026lt;\u0026#39; || op[0] == \u0026#39;!\u0026#39;) { 53 //删除密码,同样的,如果是明文,先转成sha256字符串 54 sds delpass; 55 if (op[0] == \u0026#39;\u0026lt;\u0026#39;) { 56 delpass = ACLHashPassword((unsigned char*)op+1,oplen-1); 57 } else { 58 //同样,判断这个字符串是不是有效的hash值 59 if (ACLCheckPasswordHash((unsigned char*)op+1,oplen-1) == C_ERR) { 60 errno = EBADMSG; 61 return C_ERR; 62 } 63 delpass = sdsnewlen(op+1,oplen-1); 64 } 65 listNode *ln = listSearchKey(u-\u0026gt;passwords,delpass); 66 sdsfree(delpass); 67 if (ln) { 68 listDelNode(u-\u0026gt;passwords,ln); 69 } else { 70 errno = ENODEV; 71 return C_ERR; 72 } 73 } else if (op[0] == \u0026#39;(\u0026#39; \u0026amp;\u0026amp; op[oplen - 1] == \u0026#39;)\u0026#39;) { 74 //处理 `()` 内的 selector 75 aclSelector *selector = aclCreateSelectorFromOpSet(op, oplen); 76 if (!selector) { 77 /* No errorno set, propagate it from interior error. */ 78 return C_ERR; 79 } 80 listAddNodeTail(u-\u0026gt;selectors, selector); 81 return C_OK; 82 } else if (!strcasecmp(op,\u0026#34;clearselectors\u0026#34;)) { 83 //清理掉所有的 selector 84 listIter li; 85 listNode *ln; 86 listRewind(u-\u0026gt;selectors,\u0026amp;li); 87 /* There has to be a root selector */ 88 serverAssert(listNext(\u0026amp;li)); 89 while((ln = listNext(\u0026amp;li))) { 90 listDelNode(u-\u0026gt;selectors, ln); 91 } 92 return C_OK; 93 } else if (!strcasecmp(op,\u0026#34;reset\u0026#34;)) { 94 //重置这个用户 95 serverAssert(ACLSetUser(u,\u0026#34;resetpass\u0026#34;,-1) == C_OK); 96 serverAssert(ACLSetUser(u,\u0026#34;resetkeys\u0026#34;,-1) == C_OK); 97 serverAssert(ACLSetUser(u,\u0026#34;resetchannels\u0026#34;,-1) == C_OK); 98 if (server.acl_pubsub_default \u0026amp; SELECTOR_FLAG_ALLCHANNELS) 99 serverAssert(ACLSetUser(u,\u0026#34;allchannels\u0026#34;,-1) == C_OK); 100 serverAssert(ACLSetUser(u,\u0026#34;off\u0026#34;,-1) == C_OK); 101 serverAssert(ACLSetUser(u,\u0026#34;sanitize-payload\u0026#34;,-1) == C_OK); 102 serverAssert(ACLSetUser(u,\u0026#34;clearselectors\u0026#34;,-1) == C_OK); 103 serverAssert(ACLSetUser(u,\u0026#34;-@all\u0026#34;,-1) == C_OK); 104 } else { 105 //处理用户的 selector 设置, 比如 `+@, -@, \u0026amp;, ~*` 等等命令 106 aclSelector *selector = ACLUserGetRootSelector(u); 107 if (ACLSetSelector(selector, op, oplen) == C_ERR) { 108 return C_ERR; 109 } 110 } 111 return C_OK; 112} aclCreateSelectorFromOpSet 这个函数最终会调用 ACLSetSelector 来把字符串转换成具体的规则\nACLSetSelector\n1int ACLSetSelector(aclSelector *selector, const char* op, size_t oplen) { 2 if (!strcasecmp(op,\u0026#34;allkeys\u0026#34;) || !strcasecmp(op,\u0026#34;~*\u0026#34;)) { 3 //允许所有key 4 selector-\u0026gt;flags |= SELECTOR_FLAG_ALLKEYS; 5 listEmpty(selector-\u0026gt;patterns); 6 } else if (!strcasecmp(op,\u0026#34;resetkeys\u0026#34;)) { 7 //去掉所有key权限 8 selector-\u0026gt;flags \u0026amp;= ~SELECTOR_FLAG_ALLKEYS; 9 listEmpty(selector-\u0026gt;patterns); 10 } else if (!strcasecmp(op,\u0026#34;allchannels\u0026#34;) || !strcasecmp(op,\u0026#34;\u0026amp;*\u0026#34;)) { 11 //channel 和key一样,允许所有和去掉所有 12 selector-\u0026gt;flags |= SELECTOR_FLAG_ALLCHANNELS; 13 listEmpty(selector-\u0026gt;channels); 14 } else if (!strcasecmp(op,\u0026#34;resetchannels\u0026#34;)) { 15 selector-\u0026gt;flags \u0026amp;= ~SELECTOR_FLAG_ALLCHANNELS; 16 listEmpty(selector-\u0026gt;channels); 17 } else if (!strcasecmp(op,\u0026#34;allcommands\u0026#34;) || !strcasecmp(op,\u0026#34;+@all\u0026#34;)) { 18 //允许所有的权限, 下面是去掉所有权限 19 memset(selector-\u0026gt;allowed_commands,255,sizeof(selector-\u0026gt;allowed_commands)); 20 selector-\u0026gt;flags |= SELECTOR_FLAG_ALLCOMMANDS; 21 ACLResetFirstArgs(selector); 22 } else if (!strcasecmp(op,\u0026#34;nocommands\u0026#34;) || !strcasecmp(op,\u0026#34;-@all\u0026#34;)) { 23 memset(selector-\u0026gt;allowed_commands,0,sizeof(selector-\u0026gt;allowed_commands)); 24 selector-\u0026gt;flags \u0026amp;= ~SELECTOR_FLAG_ALLCOMMANDS; 25 ACLResetFirstArgs(selector); 26 } else if (op[0] == \u0026#39;~\u0026#39; || op[0] == \u0026#39;%\u0026#39;) { 27 if (selector-\u0026gt;flags \u0026amp; SELECTOR_FLAG_ALLKEYS) { 28 //如果是允许所有key了, 再加限制key的命令,会返回错误 29 errno = EEXIST; 30 return C_ERR; 31 } 32 int flags = 0; 33 size_t offset = 1; 34 if (op[0] == \u0026#39;%\u0026#39;) { 35 //如果是%开头,需要判断是读还是写 36 for (; offset \u0026lt; oplen; offset++) { 37 if (toupper(op[offset]) == \u0026#39;R\u0026#39; \u0026amp;\u0026amp; !(flags \u0026amp; ACL_READ_PERMISSION)) { 38 flags |= ACL_READ_PERMISSION; 39 } else if (toupper(op[offset]) == \u0026#39;W\u0026#39; \u0026amp;\u0026amp; !(flags \u0026amp; ACL_WRITE_PERMISSION)) { 40 flags |= ACL_WRITE_PERMISSION; 41 } else if (op[offset] == \u0026#39;~\u0026#39;) { 42 offset++; 43 break; 44 } else { 45 errno = EINVAL; 46 return C_ERR; 47 } 48 } 49 } else { 50 flags = ACL_ALL_PERMISSION; 51 } 52 53 if (ACLStringHasSpaces(op+offset,oplen-offset)) { 54 errno = EINVAL; 55 return C_ERR; 56 } 57 keyPattern *newpat = ACLKeyPatternCreate(sdsnewlen(op+offset,oplen-offset), flags); 58 listNode *ln = listSearchKey(selector-\u0026gt;patterns,newpat); 59 //避免重复 60 if (ln == NULL) { 61 listAddNodeTail(selector-\u0026gt;patterns,newpat); 62 } else { 63 //如果有重复的. 合并两个pattern的flag 64 ((keyPattern *)listNodeValue(ln))-\u0026gt;flags |= flags; 65 ACLKeyPatternFree(newpat); 66 } 67 selector-\u0026gt;flags \u0026amp;= ~SELECTOR_FLAG_ALLKEYS; 68 } else if (op[0] == \u0026#39;\u0026amp;\u0026#39;) { 69 if (selector-\u0026gt;flags \u0026amp; SELECTOR_FLAG_ALLCHANNELS) { 70 //同样,如果已经允许所有channel了,再去限制channel,也会报错 71 errno = EISDIR; 72 return C_ERR; 73 } 74 if (ACLStringHasSpaces(op+1,oplen-1)) { 75 errno = EINVAL; 76 return C_ERR; 77 } 78 sds newpat = sdsnewlen(op+1,oplen-1); 79 listNode *ln = listSearchKey(selector-\u0026gt;channels,newpat); 80 //同样,也会对channel pattern 去重 81 if (ln == NULL) 82 listAddNodeTail(selector-\u0026gt;channels,newpat); 83 else 84 sdsfree(newpat); 85 selector-\u0026gt;flags \u0026amp;= ~SELECTOR_FLAG_ALLCHANNELS; 86 } else if (op[0] == \u0026#39;+\u0026#39; \u0026amp;\u0026amp; op[1] != \u0026#39;@\u0026#39;) { 87 //加命令权限 (没有在 ACL CAT分类里的) 88 //如果一个命令没有在分类里,可以通过前缀来做匹配,比如 89 //DB提供执行SELECT的能力，但可能仍然希望能够运行SELECT 0。 90 //ACL SETUSER myuser -select +select|0 91 if (strrchr(op,\u0026#39;|\u0026#39;) == NULL) { 92 //如果op字符串中没有 `|` 不需要处理前缀, 直接处理即可 93 //需要先处理一下重命名的命令 94 struct redisCommand *cmd = ACLLookupCommand(op+1); 95 if (cmd == NULL) { 96 errno = ENOENT; 97 return C_ERR; 98 } 99 //处理禁用和允许的命令,包括子命令 100 ACLChangeSelectorPerm(selector,cmd,1); 101 } else { 102 //分割字符串,得到子命令 103 char *copy = zstrdup(op+1); 104 char *sub = strrchr(copy,\u0026#39;|\u0026#39;); 105 sub[0] = \u0026#39;\\0\u0026#39;; 106 sub++; 107 108 struct redisCommand *cmd = ACLLookupCommand(copy); 109 110 /* Check if the command exists. We can\u0026#39;t check the 111 * first-arg to see if it is valid. */ 112 if (cmd == NULL) { 113 zfree(copy); 114 errno = ENOENT; 115 return C_ERR; 116 } 117 118 //不能直接作用于子命令 119 if (cmd-\u0026gt;parent) { 120 zfree(copy); 121 errno = ECHILD; 122 return C_ERR; 123 } 124 125 //子命令不能是空的,比如 `HASH|` 这种是不合法的 126 if (strlen(sub) == 0) { 127 zfree(copy); 128 errno = EINVAL; 129 return C_ERR; 130 } 131 132 if (cmd-\u0026gt;subcommands_dict) { 133 //这个命令有子命令,处理子命令 134 cmd = ACLLookupCommand(op+1); 135 if (cmd == NULL) { 136 zfree(copy); 137 errno = ENOENT; 138 return C_ERR; 139 } 140 ACLChangeSelectorPerm(selector,cmd,1); 141 } else { 142 /* If user is trying to use the ACL mech to block SELECT except SELECT 0 or 143 * block DEBUG except DEBUG OBJECT (DEBUG subcommands are not considered 144 * subcommands for now) we use the allowed_firstargs mechanism. */ 145 146 /* Add the first-arg to the list of valid ones. */ 147 serverLog(LL_WARNING, \u0026#34;Deprecation warning: Allowing a first arg of an otherwise \u0026#34; 148 \u0026#34;blocked command is a misuse of ACL and may get disabled \u0026#34; 149 \u0026#34;in the future (offender: +%s)\u0026#34;, op+1); 150 ACLAddAllowedFirstArg(selector,cmd-\u0026gt;id,sub); 151 } 152 153 zfree(copy); 154 } 155 } else if (op[0] == \u0026#39;-\u0026#39; \u0026amp;\u0026amp; op[1] != \u0026#39;@\u0026#39;) { 156 //去掉 命令权限 (没有在 ACL CAT分类里的) 157 struct redisCommand *cmd = ACLLookupCommand(op+1); 158 if (cmd == NULL) { 159 errno = ENOENT; 160 return C_ERR; 161 } 162 ACLChangeSelectorPerm(selector,cmd,0); 163 } else if ((op[0] == \u0026#39;+\u0026#39; || op[0] == \u0026#39;-\u0026#39;) \u0026amp;\u0026amp; op[1] == \u0026#39;@\u0026#39;) { 164 //加或者减权限 (只处理在ACL CAT分类里的) 165 int bitval = op[0] == \u0026#39;+\u0026#39; ? 1 : 0; 166 if (ACLSetSelectorCommandBitsForCategory(selector,op+2,bitval) == C_ERR) { 167 errno = ENOENT; 168 return C_ERR; 169 } 170 } else { 171 errno = EINVAL; 172 return C_ERR; 173 } 174 return C_OK; 175} 权限设置相关的差不多就是这些了，基本都是得到字符串后，处理字符串，然后处理对应的权限。代码量不小，其中一些细节没有详细展开分析，逻辑都不太复杂，后面有时间会考虑把这里的坑填上。\nACL规则存储 使用 ACL SETUSER 命令设置的规则，默认只会存在内存中，如果没有调用ACL SAVE命令进行存储，redis重启后会丢失所有 用户信息\n使用ACL SAVE 命令的前提是 redis 配置了 ACL 文件，如果没有配置 ACL 文件，那么 使用 ACL SAVE命令会报错\n使用 ACL SAVE 和 ACL LIST最终都会调用这个函数来生成 ACL 规则的字符串\nACLDescribeUser\n1robj *ACLDescribeUser(user *u) { 2 if (u-\u0026gt;acl_string) { 3 incrRefCount(u-\u0026gt;acl_string); 4 return u-\u0026gt;acl_string; 5 } 6 7 sds res = sdsempty(); 8 9 先处理flag 10 for (int j = 0; ACLUserFlags[j].flag; j++) { 11 if (u-\u0026gt;flags \u0026amp; ACLUserFlags[j].flag) { 12 res = sdscat(res,ACLUserFlags[j].name); 13 res = sdscatlen(res,\u0026#34; \u0026#34;,1); 14 } 15 } 16 17 //处理密码 18 listIter li; 19 listNode *ln; 20 listRewind(u-\u0026gt;passwords,\u0026amp;li); 21 while((ln = listNext(\u0026amp;li))) { 22 sds thispass = listNodeValue(ln); 23 res = sdscatlen(res,\u0026#34;#\u0026#34;,1); 24 res = sdscatsds(res,thispass); 25 res = sdscatlen(res,\u0026#34; \u0026#34;,1); 26 } 27 28 //生成 selector的规则字符串 29 listRewind(u-\u0026gt;selectors,\u0026amp;li); 30 while((ln = listNext(\u0026amp;li))) { 31 aclSelector *selector = (aclSelector *) listNodeValue(ln); 32 //通过 ACLDescribeSelector 生成 selector的规则字符串 33 //这里面的处理如果详细来拆分的话,还是有点多的,就不展开了 34 sds default_perm = ACLDescribeSelector(selector); 35 //这里需要注意一下, 如果是非root selector, 规则需要用 () 包裹 36 if (selector-\u0026gt;flags \u0026amp; SELECTOR_FLAG_ROOT) { 37 res = sdscatfmt(res, \u0026#34;%s\u0026#34;, default_perm); 38 } else { 39 res = sdscatfmt(res, \u0026#34; (%s)\u0026#34;, default_perm); 40 } 41 sdsfree(default_perm); 42 } 43 44 u-\u0026gt;acl_string = createObject(OBJ_STRING, res); 45 /* because we are returning it, have to increase count */ 46 incrRefCount(u-\u0026gt;acl_string); 47 48 return u-\u0026gt;acl_string; 49} ACL鉴权 下面开始分析 鉴权相关的代码。\n上面的基本是和权限设置相关的，有了权限后，要执行命令时，需要判断是否可以执行，这部分就是鉴权了。\n先来最基本的 AUTH 命令\nauthCommand\nAUTH 命令兼容以前的命令参数，会根据参数的个数判断命名的版本，如果参数长度是2，会使用以前的模式来处理。\n如果参数长度是3，会按照ACL的模式来处理\n1void authCommand(client *c) { 2 //如果参数\u0026gt;3了这个命令是错误的,直接返回 3 if (c-\u0026gt;argc \u0026gt; 3) { 4 addReplyErrorObject(c,shared.syntaxerr); 5 return; 6 } 7 redactClientCommandArgument(c, 1); 8 9 /* Handle the two different forms here. The form with two arguments 10 * will just use \u0026#34;default\u0026#34; as username. */ 11 robj *username, *password; 12 if (c-\u0026gt;argc == 2) { 13 //处理两种参数的情况,如果默认用户是没有密码的, 返回错谁 14 if (DefaultUser-\u0026gt;flags \u0026amp; USER_FLAG_NOPASS) { 15 addReplyError(c,\u0026#34;AUTH \u0026lt;password\u0026gt; called without any password \u0026#34; 16 \u0026#34;configured for the default user. Are you sure \u0026#34; 17 \u0026#34;your configuration is correct?\u0026#34;); 18 return; 19 } 20 21 username = shared.default_username; 22 password = c-\u0026gt;argv[1]; 23 } else { 24 //处理三种参数的情况 25 username = c-\u0026gt;argv[1]; 26 password = c-\u0026gt;argv[2]; 27 redactClientCommandArgument(c, 2); 28 } 29 //校验用户名和密码是否匹配 30 if (ACLAuthenticateUser(c,username,password) == C_OK) { 31 addReply(c,shared.ok); 32 } else { 33 addReplyError(c,\u0026#34;-WRONGPASS invalid username-password pair or user is disabled.\u0026#34;); 34 } 35} AUTH 命令处理还是挺简单的，下面开始ACL对具体命令的判断\n当一个命令进来后，redis要先判断命令是否能执行，从 server.c:3769 开始，调用ACLCheckAllPerm函数。\n最终会调用到 ACLCheckAllUserCommandPerm 函数去做具体的校验逻辑\n会遍历user的 Selectors 这个链表来做鉴权\n1 listRewind(u-\u0026gt;selectors,\u0026amp;li); 2 while((ln = listNext(\u0026amp;li))) { 3 aclSelector *s = (aclSelector *) listNodeValue(ln); 4 int acl_retval = ACLSelectorCheckCmd(s, cmd, argv, argc, \u0026amp;local_idxptr, \u0026amp;cache); 5 if (acl_retval == ACL_OK) { 6 //如果通过校验了,可以结束循环,然后返回正确 7 cleanupACLKeyResultCache(\u0026amp;cache); 8 return ACL_OK; 9 } 10 if (acl_retval \u0026gt; relevant_error || 11 (acl_retval == relevant_error \u0026amp;\u0026amp; local_idxptr \u0026gt; last_idx)) 12 { 13 relevant_error = acl_retval; 14 last_idx = local_idxptr; 15 } 16 } 做鉴权判断的是这个函数ACLSelectorCheckCmd\nACLSelectorCheckCmd\n鉴权的优先级\n判断命令类型，比如GET,SET,HGET 等等,判断是否有这个类型命令的权限 判断key名，通过对比key的名字，判断这个key是否有权限 判断是否是channel命令，然后判断权限 1static int ACLSelectorCheckCmd(aclSelector *selector, struct redisCommand *cmd, robj **argv, int argc, int *keyidxptr, aclKeyResultCache *cache) { 2 uint64_t id = cmd-\u0026gt;id; 3 int ret; 4 //如果 flags 不是全部 ALLCOMMANDS 并且 这个命令不是不需要验证的命令(这个命令需要auth后才能使用) 5 //CMD_NO_AUTH命令包括 `auth`,`hello`,`quit`,`reset` 6 if (!(selector-\u0026gt;flags \u0026amp; SELECTOR_FLAG_ALLCOMMANDS) \u0026amp;\u0026amp; !(cmd-\u0026gt;flags \u0026amp; CMD_NO_AUTH)) { 7 //如果命令bit里没有找到,需要再去匹配一下前缀,防止漏判 8 if (ACLGetSelectorCommandBit(selector,id) == 0) { 9 /* Check if the first argument matches. */ 10 if (argc \u0026lt; 2 || 11 selector-\u0026gt;allowed_firstargs == NULL || 12 selector-\u0026gt;allowed_firstargs[id] == NULL) 13 { 14 return ACL_DENIED_CMD; 15 } 16 17 long subid = 0; 18 //遍历,比较前缀 19 while (1) { 20 if (selector-\u0026gt;allowed_firstargs[id][subid] == NULL) 21 return ACL_DENIED_CMD; 22 int idx = cmd-\u0026gt;parent ? 2 : 1; 23 if (!strcasecmp(argv[idx]-\u0026gt;ptr,selector-\u0026gt;allowed_firstargs[id][subid])) 24 break; /* First argument match found. Stop here. */ 25 subid++; 26 } 27 } 28 } 29 30 //如果不是允许所有的key 并且这个命令里 包含了key 31 //排除类似 select 0 等等没有key操作的命令 32 if (!(selector-\u0026gt;flags \u0026amp; SELECTOR_FLAG_ALLKEYS) \u0026amp;\u0026amp; doesCommandHaveKeys(cmd)) { 33 //这里有一个从函数外传进来的,用来缓存key 的结构, 如果没有初始化过,需要初始化一下 34 if (!(cache-\u0026gt;keys_init)) { 35 cache-\u0026gt;keys = (getKeysResult) GETKEYS_RESULT_INIT; 36 //获取到这条命令中所有的key 37 getKeysFromCommandWithSpecs(cmd, argv, argc, GET_KEYSPEC_DEFAULT, \u0026amp;(cache-\u0026gt;keys)); 38 cache-\u0026gt;keys_init = 1; 39 } 40 getKeysResult *result = \u0026amp;(cache-\u0026gt;keys); 41 keyReference *resultidx = result-\u0026gt;keys; 42 for (int j = 0; j \u0026lt; result-\u0026gt;numkeys; j++) { 43 int idx = resultidx[j].pos; 44 //通过遍历所有的key,判断是否符合规则 45 ret = ACLSelectorCheckKey(selector, argv[idx]-\u0026gt;ptr, sdslen(argv[idx]-\u0026gt;ptr), resultidx[j].flags); 46 //遇到一个不符合的,直接就可以退出,并返回错误 47 if (ret != ACL_OK) { 48 if (keyidxptr) *keyidxptr = resultidx[j].pos; 49 return ret; 50 } 51 } 52 } 53 54 //检查channel的权限,只需要检查 pub 和 sub这两个权限即可 55 const int channel_flags = CMD_CHANNEL_PUBLISH | CMD_CHANNEL_SUBSCRIBE; 56 if (!(selector-\u0026gt;flags \u0026amp; SELECTOR_FLAG_ALLCHANNELS) \u0026amp;\u0026amp; doesCommandHaveChannelsWithFlags(cmd, channel_flags)) { 57 getKeysResult channels = (getKeysResult) GETKEYS_RESULT_INIT; 58 getChannelsFromCommand(cmd, argv, argc, \u0026amp;channels); 59 keyReference *channelref = channels.keys; 60 for (int j = 0; j \u0026lt; channels.numkeys; j++) { 61 int idx = channelref[j].pos; 62 if (!(channelref[j].flags \u0026amp; channel_flags)) continue; 63 int is_pattern = channelref[j].flags \u0026amp; CMD_CHANNEL_PATTERN; 64 //和匹配key类似,也是遍历匹配,遇到不符合的就结束并返回错误 65 int ret = ACLCheckChannelAgainstList(selector-\u0026gt;channels, argv[idx]-\u0026gt;ptr, sdslen(argv[idx]-\u0026gt;ptr), is_pattern); 66 if (ret != ACL_OK) { 67 if (keyidxptr) *keyidxptr = channelref[j].pos; 68 getKeysFreeResult(\u0026amp;channels); 69 return ret; 70 } 71 } 72 getKeysFreeResult(\u0026amp;channels); 73 } 74 return ACL_OK; 75} ACL鉴权的基本就是这些了\nACL相关的一些知识 ACL 相关的一些定义\n1//命令分类的定义 2struct ACLCategoryItem { 3 const char *name; 4 uint64_t flag; 5} ACLCommandCategories[] = { /* See redis.conf for details on each category. */ 6 {\u0026#34;keyspace\u0026#34;, ACL_CATEGORY_KEYSPACE}, 7 {\u0026#34;read\u0026#34;, ACL_CATEGORY_READ}, 8 {\u0026#34;write\u0026#34;, ACL_CATEGORY_WRITE}, 9 {\u0026#34;set\u0026#34;, ACL_CATEGORY_SET}, 10 {\u0026#34;sortedset\u0026#34;, ACL_CATEGORY_SORTEDSET}, 11 {\u0026#34;list\u0026#34;, ACL_CATEGORY_LIST}, 12 {\u0026#34;hash\u0026#34;, ACL_CATEGORY_HASH}, 13 {\u0026#34;string\u0026#34;, ACL_CATEGORY_STRING}, 14 {\u0026#34;bitmap\u0026#34;, ACL_CATEGORY_BITMAP}, 15 {\u0026#34;hyperloglog\u0026#34;, ACL_CATEGORY_HYPERLOGLOG}, 16 {\u0026#34;geo\u0026#34;, ACL_CATEGORY_GEO}, 17 {\u0026#34;stream\u0026#34;, ACL_CATEGORY_STREAM}, 18 {\u0026#34;pubsub\u0026#34;, ACL_CATEGORY_PUBSUB}, 19 {\u0026#34;admin\u0026#34;, ACL_CATEGORY_ADMIN}, 20 {\u0026#34;fast\u0026#34;, ACL_CATEGORY_FAST}, 21 {\u0026#34;slow\u0026#34;, ACL_CATEGORY_SLOW}, 22 {\u0026#34;blocking\u0026#34;, ACL_CATEGORY_BLOCKING}, 23 {\u0026#34;dangerous\u0026#34;, ACL_CATEGORY_DANGEROUS}, 24 {\u0026#34;connection\u0026#34;, ACL_CATEGORY_CONNECTION}, 25 {\u0026#34;transaction\u0026#34;, ACL_CATEGORY_TRANSACTION}, 26 {\u0026#34;scripting\u0026#34;, ACL_CATEGORY_SCRIPTING}, 27 {NULL,0} /* Terminator. */ 28}; 29 30//userflag的定义 31struct ACLUserFlag { 32 const char *name; 33 uint64_t flag; 34} ACLUserFlags[] = { 35 /* Note: the order here dictates the emitted order at ACLDescribeUser */ 36 {\u0026#34;on\u0026#34;, USER_FLAG_ENABLED}, 37 {\u0026#34;off\u0026#34;, USER_FLAG_DISABLED}, 38 {\u0026#34;nopass\u0026#34;, USER_FLAG_NOPASS}, 39 {\u0026#34;skip-sanitize-payload\u0026#34;, USER_FLAG_SANITIZE_PAYLOAD_SKIP}, 40 {\u0026#34;sanitize-payload\u0026#34;, USER_FLAG_SANITIZE_PAYLOAD}, 41 {NULL,0} /* Terminator. */ 42}; 还有一个在权限校验中用到的东西 cmd-\u0026gt;id 这个是每个redis命令的id，具体是通过这个函数得到的\nACLGetCommandID\n1//获取一个命令的id 2unsigned long ACLGetCommandID(sds cmdname) { 3 sds lowername = sdsdup(cmdname); 4 sdstolower(lowername); 5 if (commandId == NULL) commandId = raxNew(); 6 void *id = raxFind(commandId,(unsigned char*)lowername,sdslen(lowername)); 7 if (id != raxNotFound) { 8 sdsfree(lowername); 9 //如果找到了,直接return id就可以了 10 return (unsigned long)id; 11 } 12 13 //如果没有找到, 把这个命令插入的rax表中,并得到id 14 raxInsert(commandId,(unsigned char*)lowername,strlen(lowername), 15 (void*)nextid,NULL); 16 sdsfree(lowername); 17 unsigned long thisid = nextid; 18 //id自增, nextid是在acl中定义的 19 nextid++; 20 21 //如果id==1023了, 再自增一次,防止id是1024 22 //因为这个值要给aclSelector中的allowed_commands做索引, 23 //allowed_commands 是一个长度为16的数组,至于为什么不能是1024这个值,后面会看到 24 if (nextid == USER_COMMAND_BITS_COUNT-1) nextid++; 25 return thisid; 26} 27 28//nextid的定义 29static unsigned long nextid = 0; /* Next command id that has not been assigned */ 30 31//aclSelector 中的 allowed_commands定义 32uint64_t allowed_commands[USER_COMMAND_BITS_COUNT/64]; ACLSetSelectorCommandBit\n根据 cmd.id 设置 selector\n1void ACLSetSelectorCommandBit(aclSelector *selector, unsigned long id, int value) { 2 uint64_t word, bit; 3 //调用 ACLGetCommandBitCoordinates 计算得到 word 和bit 4 if (ACLGetCommandBitCoordinates(id,\u0026amp;word,\u0026amp;bit) == C_ERR) return; 5 if (value) { 6 //如果是允许的话,设置这个bit 7 selector-\u0026gt;allowed_commands[word] |= bit; 8 } else { 9 //如果是不予许, 取消这个位, 再把flag设置一下 10 selector-\u0026gt;allowed_commands[word] \u0026amp;= ~bit; 11 selector-\u0026gt;flags \u0026amp;= ~SELECTOR_FLAG_ALLCOMMANDS; 12 } 13} 14 15int ACLGetCommandBitCoordinates(uint64_t id, uint64_t *word, uint64_t *bit) { 16 //如果id \u0026gt;= 1024了,return 错误 17 if (id \u0026gt;= USER_COMMAND_BITS_COUNT) return C_ERR; 18 //sizeof(uint64_t) 计算得到8 19 //word 得到但是 数组的索引 20 //到这应该就明白为什么 在 `ACLGetCommandID` id 不能是1024了吧 21 *word = id / sizeof(uint64_t) / 8; 22 //bit 是通过位运算得到的, 是id%64 得到的一个[0,63]的值,然后再左移得到 bit的值 23 *bit = 1ULL \u0026lt;\u0026lt; (id % (sizeof(uint64_t) * 8)); 24 return C_OK; 25} 这样一番操作下来，selector.allowed_commands 得到一个长度是64的 uint64_t 的数组，数组内的每一个整数的每一个位，记录了一个命令开启或者关闭（对应位的0或1）\n这里有个非常巧妙的计算过程。\n一般我们在使用位运算记录的时候，都是1，2，4，8 等等这些2的倍数来做，因为要保证不会出现位冲突。比如2的二进制是 10, 3的二进制是 11 在同时使用 10 和 11 进行 与或运算的时候，2 和 3 第一位的 1 会相互影响，使结果不准确。\n但是如果直接用id的值左移来计算，uint64_t bit = 1ULL \u0026lt;\u0026lt; id 假设有100个cmd,id的值就是100，那就需要一个整数是100位的长度。但是现在C语言的最大整数是64位长度。显然是不够用的。所以这里在计算的时候，会把命令先分组，让命令落在[0,63]这个范围内，然后再对组内的数字进行左移计算。这样，使用长度是64的 uint64_t 的数组就能完成 1024个命令的bit记录了。\n命令初始化 在ACL中，有 命令分类 (acl_categories) 和 子命令(subcommands) 这两个概念，这个东西需要在命令初始化时就赋值。\nacl_categories 是一个 uint64_t 类型的，对应的值是 ACL_CATEGORY_ 的宏定义，在 这里 被定义\nsubcommands 是一个 redisCommand类型的指针，其实就是 redisCommand 类型的数组\ncommands初始化\n在这里，redis的所有命令都会被初始化\n就拿 ACL 这个命令来说吧 ACL命令初始化\nACL命令的 acl_categories 被设置为了0, subcommands 被设置为了 ACL_Subcommands\n其中 ACL_Subcommands 是一个命令的数组，在这里被初始化\n有子命令的会把对应的子命令赋值对 subcommands 中，没有子命令的就直接是空指针了\n暂时能想到的就是这些了，后面有新的再补充\n","date":"2023-07-03T21:07:02Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/174339-62bacd4b7f65d.png","permalink":"https://lqxhub.github.io/posts/eeb1e692/","title":"redis源码学习|ACL，细探讨了Redis ACL的作用、命令和权限设置，以及如何在源码层面实现ACL的初始化、加载和鉴权。"},{"content":"最近想深入学习一下redis，那阅读源码是最好的学习方式了，正好最近pika社区在讨论 事务 的实现，实现事务的基础就是数据的一致性 虽然redis的事务没有像 关系型数据库那样，支持数据回滚。但是redis的事务也可以保证数据的一致性，如何保证数据 一致性，就是靠 watch 这个功能来实现的。说白了，redis的watch功能就是一个乐观锁\n乐观锁 我的理解是，所谓的乐观锁，对数据加锁不会阻止别的人修改数据，但是别人修改过的数据，加锁的人能知道这个数据被修改过\nredis 实现 本文中的源码基于redis 7.0.11，不同的版本实现可能会不同\n先放一张watch的数据结构图\n在redis的 db 结构中，有一个map，用来记录所有被watch的key，所有watch这个key的client都使用链表串联在一起\n源码\n1/* Redis database representation. There are multiple databases identified 2 * by integers from 0 (the default database) up to the max configured 3 * database. The database number is the \u0026#39;id\u0026#39; field in the structure. */ 4typedef struct redisDb { 5 dict *dict; /* The keyspace for this DB */ 6 dict *expires; /* Timeout of keys with a timeout set */ 7 dict *blocking_keys; /* Keys with clients waiting for data (BLPOP)*/ 8 dict *ready_keys; /* Blocked keys that received a PUSH */ 9 dict *watched_keys; /* WATCHED keys for MULTI/EXEC CAS 这个map就是记录被watch的key*/ 10 int id; /* Database ID */ 11 long long avg_ttl; /* Average TTL, just for stats */ 12 unsigned long expires_cursor; /* Cursor of the active expire cycle. */ 13 list *defrag_later; /* List of key names to attempt to defrag one by one, gradually. */ 14 clusterSlotToKeyMapping *slots_to_keys; /* Array of slots to keys. Only used in cluster mode (db 0). */ 15} redisDb; 在redis的 client中也有一个链表，记录了当前client watch的所有key\n还有一个flag记录当前client的状态，这个flag可以记录很多状态，在watch功能里，可以记录这个当前client watch的key，是否被别的client修改过\n源码\n1typedef struct client { 2 uint64_t flags; /* Client flags: CLIENT_* macros. */ 3 list *watched_keys; /* Keys WATCHED for MULTI/EXEC CAS */ 4}; 因为redis不同的db是互相隔离的，所以在db层面做watch就可以了\nwatch key 现在来看一下如何watch一个key\n源码\n1void watchForKey(client *c, robj *key) { 2 list *clients = NULL; 3 listIter li; 4 listNode *ln; 5 watchedKey *wk; 6 7 /* Check if we are already watching for this key */ 8 listRewind(c-\u0026gt;watched_keys,\u0026amp;li); 9 //遍历当前client已经watch的key中,是否包含当前要watch的key 10 while((ln = listNext(\u0026amp;li))) { 11 wk = listNodeValue(ln); 12 //因为redis不同的db中,数据是隔离的,所以要判断一下,db是否相同 13 //比如db0和db1都有key1这个key 14 if (wk-\u0026gt;db == c-\u0026gt;db \u0026amp;\u0026amp; equalStringObjects(key,wk-\u0026gt;key)) 15 //如果这个key已经被watch了,直接rerun就好了 16 return; /* Key already watched */ 17 } 18 /* This key is not already watched in this DB. Let\u0026#39;s add it */ 19 //去db 的 `watched_keys`这个map中,找到watch这个key的所有client 20 clients = dictFetchValue(c-\u0026gt;db-\u0026gt;watched_keys,key); 21 if (!clients) { 22 //如果没有client watch 这个key,返回的链表是空指针,这时候初始化一个链表 23 clients = listCreate(); 24 //把链表赋值给map 25 dictAdd(c-\u0026gt;db-\u0026gt;watched_keys,key,clients); 26 incrRefCount(key); 27 } 28 /* Add the new key to the list of keys watched by this client */ 29 wk = zmalloc(sizeof(*wk)); 30 wk-\u0026gt;key = key; 31 wk-\u0026gt;client = c; 32 wk-\u0026gt;db = c-\u0026gt;db; 33 //记录一下,在watch时,这个key是否过期了,如果在watch前就已经过期了,在执行事务的时候,就忽略这个key 34 wk-\u0026gt;expired = keyIsExpired(c-\u0026gt;db, key); 35 incrRefCount(key); 36 //把当前的client加到链表中 37 listAddNodeTail(c-\u0026gt;watched_keys,wk); 38 //把watch的key 加入的client watch链表中 39 listAddNodeTail(clients,wk); 40} watch一个key前，会检查一下这个key是否已经被watch了，避免重复watch\n找到watch这个key的所有client，并使用尾插法把当前client加入链表，并且记录一下watch这个key之前，这个key是否过期了\n到这里，watch的过程就完成了，通过源码可以发现，watch的过程还是挺好理解的，就是在记录一下\n执行事务 当redis的client在执行 EXEC命令时，会把当前事务所有的命令一起执行，在执行命令前，会先检查一下watch的key是否被修改了，如果被修改了， 就会放弃执行命令，返回失败\n源码\n1void execCommand(client *c) { 2 int j; 3 robj **orig_argv; 4 int orig_argc, orig_argv_len; 5 struct redisCommand *orig_cmd; 6 7 //先检查一下,如果client在此之前没有执行过`MULTI`命令,就执行`EXEC`,返回错误 8 if (!(c-\u0026gt;flags \u0026amp; CLIENT_MULTI)) { 9 addReplyError(c,\u0026#34;EXEC without MULTI\u0026#34;); 10 return; 11 } 12 13 /* EXEC with expired watched key is disallowed*/ 14 //检查一下被watch的key是否过期了,如果过期了,事务也会失败 15 //如果这个key在watch之前就过期了,那么这个key会被忽略 16 if (isWatchedKeyExpired(c)) { 17 c-\u0026gt;flags |= (CLIENT_DIRTY_CAS); 18 } 19 20 /* Check if we need to abort the EXEC because: 21 * 1) Some WATCHed key was touched. 22 * 2) There was a previous error while queueing commands. 23 * A failed EXEC in the first case returns a multi bulk nil object 24 * (technically it is not an error but a special behavior), while 25 * in the second an EXECABORT error is returned. */ 26 //这里就是判断这个key是否被其他client改动了,如果key被别的client改动了,或者事务出错了,那么本次事务都会失败 27 if (c-\u0026gt;flags \u0026amp; (CLIENT_DIRTY_CAS | CLIENT_DIRTY_EXEC)) { 28 if (c-\u0026gt;flags \u0026amp; CLIENT_DIRTY_EXEC) { 29 addReplyErrorObject(c, shared.execaborterr); 30 } else { 31 addReply(c, shared.nullarray[c-\u0026gt;resp]); 32 } 33 34 discardTransaction(c); 35 return; 36 } 37 uint64_t old_flags = c-\u0026gt;flags; 38 39 /* we do not want to allow blocking commands inside multi */ 40 c-\u0026gt;flags |= CLIENT_DENY_BLOCKING; 41 42 /* Exec all the queued commands */ 43 //取消watch的所有key 44 unwatchAllKeys(c); /* Unwatch ASAP otherwise we\u0026#39;ll waste CPU cycles */ 45 ..................................................... 46 省略 47} 在执行事务前，会检查一下当前client是否开启了事务（是否执行了 MULTI 命令），没有开启事务，这次事务会失败\n再检查这个client watch的key是否被修改了。如果这个key被其他的client修改了，则这个事务会执行失败\nwatch检查没有问题后，会清除当前client watch的所有key\n到这，事务执行前的检查就完成了，后面就是事务相关的判断和操作了\n修改watch的key 如果一个被watch的key被修改了，那么所有watch这个key的client都会知道，具体实现如下\n源码\n所有修改命令(比如set,hset等等)在执行后,都会调用这个函数，把watch的key标记为修改状态\n1void touchWatchedKey(redisDb *db, robj *key) { 2 list *clients; 3 listIter li; 4 listNode *ln; 5 6 //如果记录key的map为空或者client链表是空,直接return 7 if (dictSize(db-\u0026gt;watched_keys) == 0) return; 8 clients = dictFetchValue(db-\u0026gt;watched_keys, key); 9 if (!clients) return; 10 11 /* Mark all the clients watching this key as CLIENT_DIRTY_CAS */ 12 /* Check if we are already watching for this key */ 13 listRewind(clients,\u0026amp;li); 14 //遍历watch这个key的client链表,把所有client的flag修改为 `CLIENT_DIRTY_CAS` 状态 15 while((ln = listNext(\u0026amp;li))) { 16 watchedKey *wk = listNodeValue(ln); 17 client *c = wk-\u0026gt;client; 18 19 if (wk-\u0026gt;expired) { 20 /* The key was already expired when WATCH was called. */ 21 if (db == wk-\u0026gt;db \u0026amp;\u0026amp; 22 equalStringObjects(key, wk-\u0026gt;key) \u0026amp;\u0026amp; 23 dictFind(db-\u0026gt;dict, key-\u0026gt;ptr) == NULL) 24 { 25 //如果在这个client在watch前,这个key就已经过期了 \u0026amp;\u0026amp; 是这个db的 \u0026amp;\u0026amp; key是同一个 \u0026amp;\u0026amp; 内存里没有这个key了 26 //就清除 watch就过期的 flag 27 /* Already expired key is deleted, so logically no change. Clear 28 * the flag. Deleted keys are not flagged as expired. */ 29 wk-\u0026gt;expired = 0; 30 goto skip_client; 31 } 32 //否则就结束 33 break; 34 } 35 36 //把这个client的flag修改为 被其他client修改了 37 c-\u0026gt;flags |= CLIENT_DIRTY_CAS; 38 /* As the client is marked as dirty, there is no point in getting here 39 * again in case that key (or others) are modified again (or keep the 40 * memory overhead till EXEC). */ 41 //如果这个client watch的key被标记为以修改,那么就把这个client watch的key都删掉 42 unwatchAllKeys(c); 43 44 skip_client: 45 continue; 46 } 47} 48 49//删除client watch的key 50void unwatchAllKeys(client *c) { 51 listIter li; 52 listNode *ln; 53 54 if (listLength(c-\u0026gt;watched_keys) == 0) return; 55 listRewind(c-\u0026gt;watched_keys,\u0026amp;li); 56 //变量当前client watch的key 把这些key在对应的db的`watched_keys`中删除 57 while((ln = listNext(\u0026amp;li))) { 58 list *clients; 59 watchedKey *wk; 60 61 /* Lookup the watched key -\u0026gt; clients list and remove the client\u0026#39;s wk 62 * from the list */ 63 wk = listNodeValue(ln); 64 clients = dictFetchValue(wk-\u0026gt;db-\u0026gt;watched_keys, wk-\u0026gt;key); 65 serverAssertWithInfo(c,NULL,clients != NULL); 66 listDelNode(clients,listSearchKey(clients,wk)); 67 /* Kill the entry at all if this was the only client */ 68 if (listLength(clients) == 0) 69 dictDelete(wk-\u0026gt;db-\u0026gt;watched_keys, wk-\u0026gt;key); 70 /* Remove this watched key from the client-\u0026gt;watched list */ 71 listDelNode(c-\u0026gt;watched_keys,ln); 72 decrRefCount(wk-\u0026gt;key); 73 zfree(wk); 74 } 75} 任意client在修改key后,都会调用 touchWatchedKey 把watch这个key的client的flag标记为被修改状态，watch这个key的client，会遍历自己的watch 的链表，把所有的key都删掉。后续在执行事务时会失败\n在执行 UNWATCH 命令时，最终调用的也是 unwatchAllKeys 这个函数\n总结 redis通过 watch 命令实现乐观锁，保证了事务中数据的一致性。\nredis的乐观锁在集群模式下并不适用，在集群模式下，还是要使用 SETEX KEY_NAME TIMEOUT VALUE 这种方式加锁来保证数据一致\n刚开始学习redis源码，对一些概念理解还不是很深，如果有错误的地方，还请批评指正\n","date":"2023-05-27T15:20:19Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/2293d1c588ec113daecfde68815267b8.png","permalink":"https://lqxhub.github.io/posts/aadf9734/","title":"redis 乐观锁，事务中如何确保数据一致性,watch命令源码,watch的实现原理，数据结构、如何监控和管理key的变化"},{"content":"根据debian官方发布的公告，debian12的发布日期是2023年6月10日。 我原本以为要等到那天才能更新呢，去网站看了一下，现在就可以更新了，那还用说了，直接冲。\n其实更新方式也非常简单，只需要把 apt 的源换成 debian12的，然后执行 apt full-upgrade 就可以了\n在国内，不建议使用官方的源，网速慢，国内有很多镜像，找一下替换一下就行。\n我用的是清华大学的镜像，\n地址\n选择对应的debian版本，如图中\n回到linux中，在升级12前，建议把关键数据做一次备份，出问题了还有回头路。 我使用的虚拟机，在升级前创建了一个快照\n在升级前 先把11的所有包都更新到最新\nsudo apt update sudo apt upgrade 将 /etc/apt/sources.list 所有的配置删掉，把debian12 的复制进去\n然后执行\nsudo apt update sudo apt full-upgrade 等待下载完成后会自动安装。如果你有更改过一些包的配置，在重新安装的时候会询问你使用默认的配置还是修改后的配置\n一般情况下选择自己修改后的配置就可以了。\n等全部完成后 重启进入系统，整个升级就完成了\n系统升级后，如果使用的是gnome桌面，因为gnome从3升级到了4，所以原来的一些插件就不能用了，这时候只需要把旧的插件卸载 换成新的就可以\n如果这个插件没有兼容gnome4的，那就没法了 0.0\n我升级后只有一个插件不能用了，换成最新版的就可以，原来软件都能正常使用，已经用了两天了，完全没有问题\n","date":"2023-05-14T14:12:12Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/debian-12-banner.jpg","permalink":"https://lqxhub.github.io/posts/39fad342/","title":"debian11 升级到 debian12"},{"content":"go的 math 包只提供了简单的小数操作，像常用的四舍五入，保留几位小数这些常用的操作，却没有提供，那只好自己造轮子了。\n四舍五入取整 1func Rounding(v float64) int { 2 return int(v + 0.5) 3} 四舍五入取整还是很简单的，直接 +0.5 然后取整就可以了。\n保留指定小数位数 1func FloatRetainBit(v float64, bit int) float64 { 2 if bit == 0 { 3 return math.Floor(v) 4 } 5 pow10 := math.Pow10(bit) 6 return math.Floor(v*pow10) / pow10 7} 这个多了一点数学运算，其实就是 * 10 的 多少次方，然后向下取整，再 ÷ 10 的 多少次方就可以了\n其中的数学知识：\n* 10 的 多少次方 就是小数点 右 移多少位\n÷ 10 的 多少次方 就是小数点 左 移多少位\n保留指定小数位数取整 1func FloatRoundingRetainBit(v float64, bit int) float64 { 2 if bit == 0 { 3 return math.Floor(v + 0.5) 4 } 5 pow10 := math.Pow10(bit) 6 return math.Floor(v*pow10+0.5) / pow10 7} 这个也没啥复杂的，就是在保留位数的基础上再加一个四舍五入就好了\n测试一下 1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;math\u0026#34; 6 \u0026#34;math/rand\u0026#34; 7) 8 9func main() { 10 f := rand.Float64() 11 fmt.Println(f) 12 fmt.Println(Rounding(f)) 13 fmt.Println(FloatRetainBit(f, 4)) 14 fmt.Println(FloatRoundingRetainBit(f, 4)) 15} 16 17func Rounding(v float64) int { 18 return int(v + 0.5) 19} 20 21func FloatRetainBit(v float64, bit int) float64 { 22 if bit == 0 { 23 return math.Floor(v) 24 } 25 pow10 := math.Pow10(bit) 26 return math.Floor(v*pow10) / pow10 27} 28 29func FloatRoundingRetainBit(v float64, bit int) float64 { 30 if bit == 0 { 31 return math.Floor(v + 0.5) 32 } 33 pow10 := math.Pow10(bit) 34 return math.Floor(v*pow10+0.5) / pow10 35} 看一下运行结果\n10.6046602879796196 21 30.6046 40.6047 是符合逻辑的\nbenchmark 保留指定位数的小数，出了用这种数学计算的方式外，还可以用 fmt 包的函数来做\n比如：\n1sprintf := fmt.Sprintf(\u0026#34;%.4f\u0026#34;, f) 2float, = strconv.ParseFloat(sprintf, 64) 通过占位符 %.4f 来确定小数点后面保留几位\n这个方式在性能上比数学计算的要差好多，用benchmark 测试一下\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;math/rand\u0026#34; 6 \u0026#34;strconv\u0026#34; 7 \u0026#34;testing\u0026#34; 8) 9 10func BenchmarkFloatRetainBit(b *testing.B) { 11 f := rand.Float64() 12 for i := 0; i \u0026lt; b.N; i++ { 13 FloatRetainBit(f, 5) 14 } 15} 16 17func BenchmarkFloatRetainFmt(b *testing.B) { 18 f := rand.Float64() 19 for i := 0; i \u0026lt; b.N; i++ { 20 sprintf := fmt.Sprintf(\u0026#34;%.4f\u0026#34;, f) 21 _, _ = strconv.ParseFloat(sprintf, 64) 22 } 23} 执行：\n1go test -bench . -benchmem 结果：\n1goos: windows 2goarch: amd64 3pkg: test2 4cpu: AMD Ryzen 5 3500X 6-Core Processor 5BenchmarkFloatRetainBit-6 310487731 3.865 ns/op 0 B/op 0 allocs/op 6BenchmarkFloatRetainFmt-6 3773605 322.6 ns/op 16 B/op 2 allocs/op 7PASS 8ok test2 3.179s 可以看到，无论是速度还是内存使用上，都是数学计算更好\n","date":"2023-04-17T19:08:17Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/OIP-C.5vDPz8YnSqT_cxT-CicKkwHaEK","permalink":"https://lqxhub.github.io/posts/9a5e1240/","title":"go小数四舍五入取整"},{"content":"好久没有写东西了，上次写还是在去年10月，都快半年了。这期间，除了工作比较忙外，也开始参与一些开源项目，比如 pika 刚好今年pika做了一些改动，比如编译方式从MakeFile 改成了 cmake。我有幸参与了一些工作，正好趁此机会，又深入学习了一下cmake 的知识，这周末有时间，来记录一下\n以前我也写过两篇和cmake相关的文章，这次又有了新的收获，就想着再写一篇记录一下\n我那就从pika中用到的cmake的一些知识，记录一下吧。我没有找到好的中文cmake文档，遇到问题最好还是去官网查，文中的相关知识,很多都是从官网学到的。cmake官网 传送门\nfind_program 主要功能是检查当前系统上是否有对应的程序\n比如在pika中，用来检查系统中是否有autoconf这个程序\n这个函数的第一参数是一个变量，用来接收检查结果\n第二个参数是要检查的程序的名字\n后面是一些可选参数，在cmake中，可选参数要加上参数的名比如在这里，要给出检查的路径，参数名是PATHS\n1find_program(AUTOCONF 2 autoconf 3 PATHS /usr/bin /usr/local/bin) 4 5if (${AUTOCONF} MATCHES AUTOCONF-NOTFOUND) 6 message(FATAL_ERROR \u0026#34;not find autoconf on localhost\u0026#34;) 7endif() 后面通过比较 AUTOCONF 是不是 AUTOCONF-NOTFOUND来确定系统中是否存在 autoconf这个程序\n这知识最基本的用法，find_program 还有很多参数，可以实现更多的功能，可以去官网直接学习传送门\nexecute_process 主要功能是执行一个命令，一般常用于执行一个本机的程序或者脚本\n这个函数常用的有下面这些参数\nCOMMAND 要执行的命令，后面可以加参数，可以支持执行多个命令\nWORKING_DIRECTORY 这个命令执行时的工作目录\nTIMEOUT 执行这个命令的超时时间\nRESULT_VARIABLE 这是一个变量，保存命令执行的结果\nOUTPUT_VARIABLE 调用结果的返回值\nERROR_VARIABLE 如果出错了，error的返回值\n在pika中的应用\n1execute_process(COMMAND sh ${CMAKE_UTILS_DIR}/Get_OS_Version.sh 2 OUTPUT_VARIABLE OS_VERSION) 这段命令的作用是执行一个shell脚本，得到这个脚本的返回值\n需要注意的是，execute_process不是使用shell去执行命令，所以要指定执行的程序。\n比如这里，要执行shell脚本，必须指定用sh程序去执行这个脚本。\ncmake_host_system_information 获取本机的一些信息\n这个函数使用比较简单，只有两个参数，\nRESULT 获取的结果\nQUERY 要获取的信息\nQUERY 常用的值，这些值在不同版本的cmake上支持程度也是不一样的，使用前还是去官网看一下，传送门\nNUMBER_OF_LOGICAL_CORES：逻辑核心数量。 NUMBER_OF_PHYSICAL_CORES：物理核心数量。 HOSTNAME：主机名称。 TOTAL_VIRTUAL_MEMORY：总虚拟内存，单位是M。 AVAILABLE_VIRTUAL_MEMORY：可用虚拟内存，单位是M。 TOTAL_PHYSICAL_MEMORY：总物理内存，单位是M。 AVAILABLE_PHYSICAL_MEMORY：可用物理内存，单位是M。 IS_64BIT：如果处理器是64位，查询结果为1。 HAS_FPU：如果处理器拥有浮点处理单元，查询结果为1。 HAS_MMX：如果处理器支持MMX指令集，查询结果为1。 HAS_MMX_PLUS：如果处理器支持Ext. MMX指令集，查询结果为1。 HAS_SSE：如果处理器支持SSE指令集，查询结果为1。 HAS_SSE2：如果处理器支持SSE2指令集，查询结果为1。 HAS_SSE_FP：如果处理器支持SSE FP指令集，查询结果为1。 HAS_SSE_MMX：如果处理器支持SSE MMX指令集，查询结果为1。 HAS_AMD_3DNOW：如果处理器支持3DNow指令集，查询结果为1。 HAS_AMD_3DNOW_PLUS：如果处理器支持3DNow+指令集，查询结果为1。 HAS_IA64：如果IA64处理器可以模拟X86，查询结果为1。 HAS_SERIAL_NUMBER：如果处理器有序列号，查询结果为1。 PROCESSOR_SERIAL_NUMBER：处理器序列号。 PROCESSOR_NAME：可读的处理器全称。 OS_NAME：操作系统名称，也就是uname -s的输出，三大操作系统对应的名称是Linux、Windows和Darwin（masOS），也可以通过CMAKE_HOST_SYSTEM_NAME变量获取。 OS_RELEASE：操作系统子类型，例如Windows Professional。 OS_VERSION：操作系统构建ID。 OS_PLATFORM：处理器架构，Windows下可以通过PROCESSOR_ARCHITECTURE变量获取，Unix/Linux/macOS等平台可以通过uname -m或uname -p获取。也可以通过CMAKE_HOST_SYSTEM_PROCESSOR变量获取。 示例：\n1cmake_host_system_information(RESULT CPU_CORE QUERY NUMBER_OF_LOGICAL_CORES) 2message(STATUS \u0026#34;Cpu core ${CPU_CORE}\u0026#34;) 获取当前电脑的逻辑核数\nExternalProject_Add 这个就比较复杂了，主要功能是引入一个外部项目。比如在一些项目中，需要别的库，可以使用这个函数来实现。只需要一些简单的配置就能完成依赖的编译和安装，极大的简化了C++的依赖管理。\n使用这个函数前，需要先导入\n1include(ExternalProject) 这个函数的常用参数有\nDirectory Options: 这部分是目录相关的配置\nPREFIX：外部项目的根目录\nTMP_DIR：外部项目的临时目录\nLOG_DIR ：外部项目在执行时，产生的log目录\nSTAMP_DIR：外部项目在执行时，每一步的时间戳都会记录在这里，如果没有设置LOG_DIR log文件默认也会在这里\nDOWNLOAD_DIR： 外部项目下载文件的存放目录\nSOURCE_DIR： 外部项目的源码存放目录\nBINARY_DIR： 外部项目编译产生的二进制文件的存放目录\nINSTALL_DIR： 外部项目编译产生的动态库和静态库的存放目录\n如果设置了PREFIX 属性，那么默认的目录结构是这样的\n1TMP_DIR = \u0026lt;prefix\u0026gt;/tmp 2STAMP_DIR = \u0026lt;prefix\u0026gt;/src/\u0026lt;name\u0026gt;-stamp 3DOWNLOAD_DIR = \u0026lt;prefix\u0026gt;/src 4SOURCE_DIR = \u0026lt;prefix\u0026gt;/src/\u0026lt;name\u0026gt; 5BINARY_DIR = \u0026lt;prefix\u0026gt;/src/\u0026lt;name\u0026gt;-build 6INSTALL_DIR = \u0026lt;prefix\u0026gt; 7LOG_DIR = \u0026lt;STAMP_DIR\u0026gt; 如果设置了EP_BASE，目录结构是这样的\n1TMP_DIR = \u0026lt;base\u0026gt;/tmp/\u0026lt;name\u0026gt; 2STAMP_DIR = \u0026lt;base\u0026gt;/Stamp/\u0026lt;name\u0026gt; 3DOWNLOAD_DIR = \u0026lt;base\u0026gt;/Download/\u0026lt;name\u0026gt; 4SOURCE_DIR = \u0026lt;base\u0026gt;/Source/\u0026lt;name\u0026gt; 5BINARY_DIR = \u0026lt;base\u0026gt;/Build/\u0026lt;name\u0026gt; 6INSTALL_DIR = \u0026lt;base\u0026gt;/Install/\u0026lt;name\u0026gt; 7LOG_DIR = \u0026lt;STAMP_DIR\u0026gt; 在pika中，是这样设置的\n1set(EP_BASE_SUFFIX \u0026#34;buildtrees\u0026#34;) 2set_property(DIRECTORY PROPERTY EP_BASE ${CMAKE_CURRENT_SOURCE_DIR}/${EP_BASE_SUFFIX}) 最后的目录结构是这样的\n1buildtrees/ 2├── Build 3├── Download 4├── Install 5├── Source 6├── Stamp 7└── tmp Download Step Options: 这部分是依赖下载相关的，下载又可以分url下载，git、svn、等等版本管理工具的下载\nURL：没什么好说的，就是下载依赖包我网址\nURL_HASH：对下载的文件做校验，必须要指定校验的算法，比如 SHA1=0cf3c3d176a2134dec9702c64abb13da593aea0c\nURL_MD5：使用md5对文件校验\nDOWNLOAD_NAME：下载的文件名\nTIMEOUT：下载的超时时间\nGIT_REPOSITORY：拉取代码的git仓库的url地址\nGIT_TAG：拉取代码的tag\n还有一些就不一一列举了\nConfigure Step Options: 编译前的准备步骤，比如生成MakeFile\nCONFIGURE_COMMAND： 通过autoconf生成MakeFile文件\nCMAKE_COMMAND：使用CMakeList.txt生成MakeFile文件\nCMAKE_ARGS：cmake的参数\nBuild Step Options: 编译相关的参数\nBUILD_COMMAND：编译命令\nBUILD_IN_SOURCE：是否在源代码目录进行编译，一般来说这个不用指定即可\nBUILD_ALWAYS：启用此选项将强制始终运行构建步骤。这可能是最简单的方法，可以可靠地确保评估外部项目自己的构建依赖关系，而不是依赖于默认的基于成功时间戳的方法。一般也不用设置\n后面的一些不太常用，就不列举了。有需要还是看官方文档\n在pika中的使用 1ExternalProject_Add(gflags 2 URL 3 https://github.com/gflags/gflags/archive/refs/tags/v2.2.2.tar.gz 4 URL_HASH 5 MD5=1a865b93bacfa963201af3f75b7bd64c 6 DOWNLOAD_NO_PROGRESS 7 1 8 UPDATE_COMMAND 9 \u0026#34;\u0026#34; 10 LOG_CONFIGURE 11 1 12 LOG_BUILD 13 1 14 LOG_INSTALL 15 1 16 BUILD_ALWAYS 17 1 18 CMAKE_ARGS 19 -DCMAKE_INSTALL_PREFIX=${STAGED_INSTALL_PREFIX} 20 -DCMAKE_BUILD_TYPE=${LIB_BUILD_TYPE} 21 -DGFLAGS_NAMESPACE=gflags 22 -DBUILD_STATIC_LIBS=ON 23 -DBUILD_SHARED_LIBS=OFF 24 BUILD_COMMAND 25 make -j${CPU_CORE} 26) 就是一些很常规的使用\n总结 cmake功能还是非常强大，但是同样的，使用也是想对复杂的，而且也没有相对好的中文文档，要用好还是有一定学习门槛的。但是用好cmake 可以很大程度上减轻一些工作量的。\npika在改用cmake的过程中我也提交过几个简单的PR，也是一次很好的学习过程，先记录这些吧，后面想起来再补充。\n","date":"2023-04-16T12:53:34Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/bdbfc42c62bafe98a218d05d53402cb4ecb80454.jpg","permalink":"https://lqxhub.github.io/posts/d026638f/","title":"cmake笔记3。CMake中几个常用函数和命令的应用场景和代码示例，find_program、execute_process、cmake_host_system_information以及ExternalProject_Add"},{"content":"访问本机网络的方式 访问同一台电脑上的网络，一般用的地址是 localhost 或者 127.0.0.1这两种方式，比如本机有一个Nginx服务器，想要访问本机Nginx，在浏览器中输入localhost 或者 127.0.0.1就能访问到Nginx的首页。如果要连接到本机的mysql， 在连接的时候，把地址填127.0.0.1就好了\ntcp 本地回环 为什么使用localhost或者1270.0.1就能访问本机的网络或者程序呢，是因为在每台电脑上都有一个特殊的网络，这个网络就是本地回环（local loopback）。localhost可以看做是 127.0.0.1 的域名。一般在hosts文件中都会有一条配置，使 localhost 映射到1270.0.0.1\n在linux系统(debin 11)中, 使用 ip a命令可以查看本机的网络\n可以看到，第一个网络就是本地回环（loopback），他的 ip 地址就是就是 127.0.0.1\n本地回环也是网络，是一个特殊的虚拟网卡。使用本地回环网络时，数据也会经过网络栈的封包和解包。\n可以看到，tcp属于运输层（传输层）协议，所以在本机发送数据时，也会经过\n1传输层-\u0026gt;网络层-\u0026gt;lookback-\u0026gt;网络层-\u0026gt;传输层 这样一个过程。\nunix domain 上面说了什么是 tcp 本地回环，那什么是 unix domain 呢。unix domain 严格来说不是网络，是unix 和 linux系统提供的一个进程间通信的方式，有点类似管道。看名字也知道，unix domain 只支持unix类的系统中，windows系统是不支持的。unix 的使用方式和 tcp很像，但是底层的工作原理差别却很大。\nunix domain 中的数据传输 就不需要网络栈了，可以看做是操作系统做了一次内存中的一个数据复制。\n使用 unix domain 如何使用tcp 相信都很熟了，就不上demo了。只上 unix domain 的代码吧。因为 unix domain 不支持 windows系统，所以要在linux或者unix系统中测试，下面会使用go在debin中测试一下\nunix domain 和tcp 一样 也是分 服务器 和 客户端 的\nunix domain 服务器 1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;io\u0026#34; 6\t\u0026#34;net\u0026#34; 7) 8 9func main() { 10\tlisten, err := GetUnixListen(\u0026#34;/tmp/test_server.sock\u0026#34;) 11\tif err != nil { 12\tpanic(err) 13\t} 14 15\tdefer listen.Close() 16\tfor { 17\tconn, err := listen.Accept() 18\tif err != nil { 19\tpanic(err) 20\t} 21 22\tbuf := make([]byte, 1024) 23\t//读数据 24\tn, err := conn.Read(buf) 25\tif err != nil \u0026amp;\u0026amp; err != io.EOF { 26\tpanic(err) 27\t} 28\tfmt.Printf(\u0026#34;%s\\n\u0026#34;, buf[:n]) 29 30\t//写数据 31\t_, err = conn.Write([]byte(\u0026#34;hello\u0026#34;)) 32\tpanic(err) 33\t} 34} 35 36func GetUnixListen(addr string) (net.Listener, error) { 37\tlisten, err := net.Listen(\u0026#34;unix\u0026#34;, addr) 38\tif err != nil { 39\treturn nil, err 40\t} 41\treturn listen, nil 42} unix domain 客户端\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;io\u0026#34; 6\t\u0026#34;net\u0026#34; 7) 8 9func main() { 10\tconn, err := GetUnixConn(\u0026#34;/tmp/test_server.sock\u0026#34;) 11\tif err != nil { 12\tpanic(err) 13\t} 14 15\tbuff := make([]byte, 1024) 16\tn, err := conn.Read(buff) 17\tif err != nil { 18\tif err != io.EOF { 19\tpanic(err) 20\t} 21\t} 22\tfmt.Printf(\u0026#34;%s\\n\u0026#34;, buff[:n]) 23 24\tconn.Write([]byte(\u0026#34;ok\u0026#34;)) 25} 26 27func GetUnixConn(addr string) (net.Conn, error) { 28\tconn, err := net.Dial(\u0026#34;unix\u0026#34;, addr) 29\tif err != nil { 30\treturn nil, err 31\t} 32\treturn conn, nil 33} 可以看到，在go中使用 unix domain的api 和tcp基本没有区别。有区别的地方是在监听和连接的地方。\ntcp 通过 IP+端口的方式来确定地址的，而unix domain 同时一个文件符 来确定地址。\n当unix domain开启监听后，会在目录中创建一个文件。在上面的例子中，就会在 /tmp 目录中创建一个test_server.sock 文件。 这是一个特殊的文件通过 file命令可以看到\n1file test_server.sock 2test_server.sock: socket 如果在同一个目录下有一个同名的文件，unix domain 的监听就会失败。就像一个端口默认只能被监听一次一样。\nunix domain 和 tcp loopback 性能对比 我没有过严格的性能测试，只是写了一些简单的测试看了一下，在发送小的数据包时，unix domain 的性能会好于 tcp。当发送大的数据包时，两者的性能差距可以忽略不计了。\n这个也是符合预期的，小的数据包时，tcp会经过网络协议栈，当数据量变大时，网络协议栈的影响可以忽略不计了。\n总结 tcp look back 可以在多个平台使用，通过本机的虚拟网卡完成数据传输，需要经过网络协议栈，性能开销相对大一些。\nunix domain 只能在unix类系统中使用，是操作系统提供的一种进程间通信方式。不需要经过网络协议栈，性能相对高一些。\n","date":"2022-10-23T17:35:05Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/8025.jpg_wh860.jpg","permalink":"https://lqxhub.github.io/posts/afb2aaad/","title":"tcp loopbcak与unix domain区别与性能对比，在Linux系统中如何使用这两种网络通信方式，展示Unix套接字的使用方法"},{"content":"什么是内存逃逸分析 内存逃逸分析是go的编译器在编译期间，根据变量的类型和作用域，确定变量是堆上还是栈上\n简单说就是编译器在编译期间，对代码进行分析，确定变量分配内存的位置。如果变量需要分配在堆上，则称作内存逃逸了。\n为什么需要逃逸分析 因为go语言是自动自动内存管理的，也就是有GC的。开发者在写代码的时候不需要关心考虑内存释放的问题，这样编译器和go运行时（runtime）就需要准确分配和管理内存，所以编译器在编译期间要确定变量是放在堆空间和栈空间。\n如果变量放错了位置会怎样 我们知道，栈空间和生命周期是和函数生命周期相关的，如果一个函数的局部变量离开了函数的范围，比如函数结束时，局部变量就会失效。所以要把这样的变量放到堆空间上。\n既然如此，那把所有在变量都放在堆上不就行了，这样一来，是没啥问题了，但是堆内存的使用成本比占内存要高好多。使用堆内存，要向操作系统申请和归还，而占内存是程序运行时就确定好了，如何使用完全由程序自己确定。在栈上分配和回收内存成本很低，只需要 2 个 CPU 指令：PUSH 和 POP，push 将数据放到到栈空间完成分配，pop 则是释放空间。\n比如 C++ 经典错误，return 一个 函数内部变量的指针\n1#include\u0026lt;iostream\u0026gt; 2 3int* one(){ 4 int i = 10; 5 return \u0026amp;i; 6} 7 8int main(){ 9 std::cout \u0026lt;\u0026lt; *one(); 10} 这段代码在编译的时候会如下警告:\n1one.cpp: 在函数‘int* one()’中: 2one.cpp:4:6: 警告：返回了局部变量的‘i’的地址 [-Wreturn-local-addr] 3 int i = 10; 4 ^ 虽然程序的运行结果大多数时候都和我们预期的一样，但是这样的代码还是有风险的。\n这样的代码在go里就完全没有问题了，因为go的编译器会根据变量的作用范围确定变量是放在栈上和堆上。\n内存逃逸场景 go的编译器提供了逃逸分析的工具，只需要在编译的时候加上 -gcflags=-m 就可以看到逃逸分析的结果了\n常见的有4种场景下会出现内存逃逸\nreturn 局部变量的指针 1package main 2 3func main() { 4 5} 6 7func One() *int { 8 i := 10 9 return \u0026amp;i 10} 执行 go build -gcflags=-m main.go\n1# command-line-arguments 2.\\main.go:3:6: can inline main 3.\\main.go:7:6: can inline One 4.\\main.go:8:2: moved to heap: i 可以看到变量 i 已经被分配到堆上了\ninterface{} 动态类型 当函数传递的变量类型是 interface{} 类型的时候，因为编译器无法推断运行时变量的实际类型，所以也会发生逃逸\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6 i := 10 7 fmt.Println(i) 8} 执行 go build -gcflags=-m .\\main.go\n1.\\main.go:11:13: inlining call to fmt.Println 2.\\main.go:11:13: i escapes to heap 3.\\main.go:11:13: []interface {} literal does not escape 4\u0026lt;autogenerated\u0026gt;:1: .this does not escape 5\u0026lt;autogenerated\u0026gt;:1: .this does not escape 可看到，i 也被分配到堆上了\n栈空间不足 因为栈的空间是有限的，所以在分配大块内存时，会考虑栈空间内否存下，如果栈空间存不下，会分配到堆上。\n1package main 2 3func main() { 4 Make10() 5 Make100() 6 Make10000() 7 MakeN(5) 8} 9 10func Make10() { 11 arr10 := make([]int, 10) 12 _ = arr10 13} 14 15func Make100() { 16 arr100 := make([]int, 100) 17 _ = arr100 18} 19 20func Make10000() { 21 arr10000 := make([]int, 10000) 22 _ = arr10000 23} 24 25func MakeN(n int) { 26 arrN := make([]int, n) 27 _ = arrN 28} 执行 go build -gcflags=-m main.go\n1# command-line-arguments 2.\\main.go:10:6: can inline Make10 3.\\main.go:15:6: can inline Make100 4.\\main.go:20:6: can inline Make10000 5.\\main.go:25:6: can inline MakeN 6.\\main.go:3:6: can inline main 7.\\main.go:4:8: inlining call to Make10 8.\\main.go:5:9: inlining call to Make100 9.\\main.go:6:11: inlining call to Make10000 10.\\main.go:7:7: inlining call to MakeN 11.\\main.go:4:8: make([]int, 10) does not escape 12.\\main.go:5:9: make([]int, 100) does not escape 13.\\main.go:6:11: make([]int, 10000) escapes to heap 14.\\main.go:7:7: make([]int, n) escapes to heap 15.\\main.go:11:15: make([]int, 10) does not escape 16.\\main.go:16:16: make([]int, 100) does not escape 17.\\main.go:21:18: make([]int, 10000) escapes to heap 18.\\main.go:26:14: make([]int, n) escapes to heap 可以看到当需要分配长度为10，100的int类型的slice时，不需要逃逸到堆上，在栈上就可以，如果slice长度达到1000时，就需要分配到堆上了。\n还有一种情况，当在编译期间长度不确定时，也需要分配到堆上。\n闭包 1package main 2 3func main() { 4 One() 5} 6 7func One() func() { 8 n := 10 9 return func() { 10 n++ 11 } 12} 在函数One中return了一个匿名函数，形成了一个闭包，看一下逃逸分析\n1# command-line-arguments 2.\\main.go:3:6: can inline main 3.\\main.go:9:9: can inline One.func1 4.\\main.go:8:2: moved to heap: n 5.\\main.go:9:9: func literal escapes to heap 可以看到 变量 n 也分配到堆上了\n还有一种情况，new 出来的变量不一定分配到堆上\n1package main 2 3func main() { 4 i := new(int) 5 _ = i 6} 像java C++等语言，new 出来的变量正常都会分配到堆上，但是在go里，new出来的变量不一定分配到堆上，至于分配到哪里，还是看编译器的逃逸分析来确定\n编译一下看看 go build -gcflags=-m main.go\n1# command-line-arguments 2.\\main.go:3:6: can inline main 3.\\main.go:4:10: new(int) does not escape 可以看到 new出来的变量，并没有逃逸，还是在栈上。\n常见的内存逃逸场景差不多就是这些了，再说一下内存逃逸带来的影响吧\n性能 那肯定就是性能问题了，因为操作栈空间比堆空间要快多了，而且使用堆空间还会有GC问题，频繁的创建和释放堆空间，会增加GC的压力\n一个简单的例子测试一下，一般来说，函数返回结构体的指针比直接返回结构体性能要好\n1package main 2 3import \u0026#34;testing\u0026#34; 4 5type MyStruct struct { 6 A int 7} 8 9func BenchmarkOne(b *testing.B) { 10 for i := 0; i \u0026lt; b.N; i++ { 11 One() 12 } 13} 14 15//go:noinline 16func One() MyStruct { 17 return MyStruct{ 18 A: 10, 19 } 20} 21 22func BenchmarkTwo(b *testing.B) { 23 for i := 0; i \u0026lt; b.N; i++ { 24 Two() 25 } 26} 27 28//go:noinline 29func Two() *MyStruct { 30 return \u0026amp;MyStruct{ 31 A: 10, 32 } 33} 注意 被调用的函数一定要加上 //go:noinline 来禁止编译器内联优化\n然后执行\ngo test -bench . -benchmem\n1goos: windows 2goarch: amd64 3pkg: escape 4BenchmarkOne-6 951519297 1.26 ns/op 0 B/op 0 allocs/op 5BenchmarkTwo-6 74933496 15.4 ns/op 8 B/op 1 allocs/op 6PASS 7ok escape 2.698s 可以明显看到 函数 One返回结构体 比 函数Two 返回 结构体指针 的性能更好，而且还不会有内存分配，不会增加GC压力\n抛开结构体的大小谈性能都是耍流氓，如果结构体比较复杂了还是指针性能更高，还有一些场景必须使用指针，所以实际工作中还是要分场景合理使用\n最后 常见的go 逃逸分析差不多就是这些了，虽然go会自动管理内存，减小了写代码的负担，但是想要写出高效可靠的代码还是有一些细节有注意的。\n","date":"2022-10-15T20:13:45Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/51143d2916746e4930adcb7433814f52eb693f29.jpg","permalink":"https://lqxhub.github.io/posts/e0a249f3/","title":"聊一聊go的内存逃逸分析"},{"content":"什么是内存对齐呢 简单说就是程序运行过程中，程序中的变量在内存中的分布情况，为什么要有对齐这个问题呢，是因为不同类型的变量占用内存的大小是不一样的， 但是cpu每次读取的内存长度是固定的，为了cpu能高效的读写数据（cpu读取数据不是一个字节一个字节读取的，一次读取的一块内存）， 所以编译器在编译的时候会通过填充空数据(数据不是连续的)，让一个变量，使cpu能一次操作就能完成读写。还有跨平台的问题，有的平台不支持访问任意地址上的任意数据，必须按照顺序依次按块读取。\n一个简单的例子看一下:\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;unsafe\u0026#34; 6) 7 8type One struct { 9 a bool 10 b int8 11 c int32 12} 13 14type Two struct { 15 a bool 16 c int32 17 b int8 18} 19 20func main() { 21 fmt.Println(unsafe.Sizeof(One{})) 22 fmt.Println(unsafe.Sizeof(Two{})) 23} 这两个结构体在运行时，占用的内存大小，看起来应该来说是一样大的，毕竟内部的变量是一样的，只是顺序不同而已。\n但实际上，占用的内存是不一样的，看一下运行结果：\n1go run main.go 24 312 为什么会这样呢，画一下内存的示意图就清楚了\nOne的内存 Two的内存\n图中灰色的块是为了对齐而填充的无用区域，可见 One 的 内存利用率比 Two 要高好多，因为cpu一次读取的内存大小是4个字节，也就是32位。为了能让cpu一次就读取完这个变量，所以编译器就做了一些调整，使内存利用率低了，但是却提高了效率。\n这里又带来一个问题，cpu一次读取数据的长度是如何确定的，这个叫对齐系数。\ngo中有一个函数，可以计算出对齐系数，一段代码看一下\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;unsafe\u0026#34; 6) 7 8type One struct { 9 a bool 10 b int8 11} 12 13type Two struct { 14 a bool 15 c int32 16 b int8 17} 18 19type Three struct { 20 a bool 21 b int8 22 c int64 23} 24 25func main() { 26 fmt.Println(unsafe.Alignof(One{})) 27 fmt.Println(unsafe.Alignof(Two{})) 28 fmt.Println(unsafe.Alignof(Three{})) 29} 运行结果如下\n1go run main.go 21 34 48 可以得到，cpu一次读取的数据长度和这结构体中的最大的数据有关。\nOne 中最大的数据长度是1个字节, Two 中最大的数据长度是4个字节, Three 中最大的数据长度是8个字节\n如果我换成 32位操作系统 呢\n1$env:GOARCH=\u0026#34;386\u0026#34; 2go run main.go 31 44 54 此时的对齐系数变成了4，因为32位的系统一次能处理的数据长度就是 4个字节，说明对齐系数还和操作系统有关。\n所以：对齐系数和结构体中最大的的数据有关，同时和操作系统也有关。取这两个条件中的小值\n内存对齐的利弊 利\n高效. 数据只需要一次就能完成读写，效率肯定比多次读写要高效 数据原子性. 还是数据一次就能完成读写，保证了原子性 弊\n那就是内存的利用率变低了，这个可以通过优化来解决一部分\n看一下如果没有内存对齐的情况吧，如果在32位的系统上，变量C要经过两次才能读到\n不同类型的对齐系数 在64位操作系统中\n类型 系数 bool, byte, uint8, int8 1 uint16, int16 2 uint32, int32 4 float32, complex64 4 int, uint, int64, uint64,string,uintptr,float64 8 有个特殊的类型 struct{} 空结构体，这个结构体的空间大小是0，但是计算出的对齐系数是1。\n而且 struct{}的位置不同，占用的空间也不相同\n1package main 2 3import ( 4 \u0026#34;fmt\u0026#34; 5 \u0026#34;unsafe\u0026#34; 6) 7 8type One struct { 9 s struct{} 10 x int 11} 12type Two struct { 13 x int 14 s struct{} 15} 16 17func main() { 18 fmt.Println(unsafe.Sizeof(One{})) 19 fmt.Println(unsafe.Sizeof(Two{})) 20} 运行结果如下:\n1go run main.go 28 316 One 和 Two 中，只是 struct{}的位置不同，就会导致内存占用不同\n之所以这样是因为，当struct{} 作为结构体最后一个字段时，如果struct{}不做填充，就会导致指向 struct{} 的地址指向了 结构体之外了，所以为了出错，就会填充一个数据位置，也就是一个 int的大小。\n如何优化内存布局 首先，go的编译器不会做内存对齐的优化，也就是在编译期间，编译器不会调整结构体中字段的顺序。至于为啥不做，我还没想通，有知道的欢迎评论区探讨。\n所以内存对齐的优化需要我们自己做。\n我自己总结的两点，欢迎补充\n尽量把相同类型的变量放到一起 把小的数据放到前面，大的数据放到后面 好了，常见的go内存对齐的问题 差不多就是这些了。\n说实话，我在工作中不是特别注意内存对齐的问题，只有在想到的时候才会做一下。这个东西带来的收益不是特别大，在内存动不动16G起步的时代，这点优化可以忽略不计的，当做知识了解一下就好了。\n","date":"2022-09-24T18:56:10Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/13daf0aa276c1739c5ae961efd41eeacac540a19.jpg","permalink":"https://lqxhub.github.io/posts/4992c058/","title":"聊一聊go的内存对齐"},{"content":"给Github上的开源项目贡献代码，就少不了 pull request 也会简称为 PR 或者 MR\n为啥我不能直接给开源项目提交代码，非要通过 PR 贡献呢。 主要有两个方面吧\n开源项目的作者要甄别提交的代码的质量，不能什么烂代码都可以提交到这个项目里，只有作者觉得合适的代码才可以加到项目里 防止别人搞破坏，要是谁都能随便提交代码，万一你给我来个删库跑路，作者想问候他全家 基于这两个方面的考虑吧，gitbub只能修改自己的项目的代码，然后向原项目提交 PR， 原项目作者可以选择性的合并到项目中。\n所以，Github贡献代码基本流程如下：\nfork 这个没什么好说的，找到你想要贡献代码的项目，然后点右上角的 fork 就好了\n然后回到自己的 repositories 中就能看到刚才fork 的项目了，其实fork就是复制了当前项目的镜像，这个复制后的镜像就是你自己的了，你拥有最高的权限。\npull pull 就是把fork 后的项目拉到本地，然后修改代码。这个没啥说的，就是常规操作。\ncommit commit 也没啥，和正常的提交代码一样，写好提交信息就好了。\npush push 就是把这次的commit提交到自己的github上去。注意，这次push是push到自己fork后的仓库中，别搞混了。\npull request 现在就到最重要的一步了，创建 pull request了。 到自己的github中，能看到自己刚才的commit了，这时候github 就会提示我们去创建pull request了\n或者按照下图中的顺序，一样可以到创建 PR的页面\n通过下图标注的地方，选择要Merge的分支，一般默认都是正确的。\n因为我已经把这个PR提交了，所以显示的是 View pull request，正常的显示的是 create pull request 然后根据提示创建这个PR就好了。\n到这里，一次完整的PR流程基本就完成了，剩下的就等着原项目作者Merge就行了。\n但是事情没有结束\n如果原项目作者同意合并了，提交的代码就会合并到主项目中，或者有别人也提交PR了，这是你想再次提交PR的话，就要先同步仓库了，就是把自己fork的仓库和源项目的仓库保持同步。 如果直接在github上点 sync fork，github会自动帮你Merge两个仓库，也就是会把之前你的commit信息一起Merge过来， 当你下次再要提交PR的时候，就会出现之前的commit信息。因为在 sync fork 的时候是Merge的，所以会带上之前的提交信息。\n先说已经sync fork后，在创建 PR时才发现的解决办法： 回到自己电脑上\n把本地的代码回退到重复之前的那个版本 通过 git log 找到重复前的那个版本。 然后回退到那个版本\n1git reset 对应版本的id 这时候本地修改的代码就会回到未提交的状态，这时候先把改的代码复制一份出来，避免操作失误找不到了就尴尬了。 再通过\n1git checkout . 把放弃本地修改。\n然后重点来了，给项目加一个上游地址。 先看一下当前的分支\n1git remote -v 2 3origin\tgit@github.com:lqxhub/pika.git (fetch) 4origin\tgit@github.com:lqxhub/pika.git (push) 此时只有自己fork后的仓库。 现在要给fork后的仓库，加一个上游地址，也就是指定这个仓库是从哪里fork来的\n1git remote add upstream https://github.com/OpenAtomFoundation/pika.git upstream 后面跟上源仓库地址 现在来看看分支器情况\n1git remote -v 2origin\tgit@github.com:lqxhub/pika.git (fetch) 3origin\tgit@github.com:lqxhub/pika.git (push) 4 5upstream\thttps://github.com/OpenAtomFoundation/pika.git (fetch) 6upstream\thttps://github.com/OpenAtomFoundation/pika.git (push) 到这上游仓库已经加好了\n然后执行\n1git fetch upstream 同步上游仓库到本地\n等代码同步完成\n1git branch -a 看一下当前的分支情况\n1* master 2 remotes/origin/HEAD -\u0026gt; origin/master 3 remotes/origin/master 4 remotes/upstream/2.3 5 remotes/upstream/3.0 6 remotes/upstream/3.0.16 7 remotes/upstream/3.2.9_beta_rocksdb5.18.3 8 remotes/upstream/develop 9 remotes/upstream/master 10 remotes/upstream/pika_codis 这时候就能看到很多分支了，然后把自己本地的代码rebase到想要的分支，一般就是remote/upstream/master\n执行\n1git rebase remotes/upstream/master 到这，本地的代码就已经和原仓库保持同步了。注意一定是 bebase 不要 merge\n核心思想就是让本地代码落后于上游仓库，然后再把本地的rebase到最新的\n然后就正常的修改代码 commit push\n注意 这里push的时候要强制 push git push -f 要不然会失败\n最后去github上 提交 PR就好了。\n上面说的是出错了怎么补救，再说一下应该怎么正确操作\n正确的操作 正确的操作是，每次修改代码都新建一个分支，在分支上修改代码，这样就不会带上之前的信息了。\n或者一开始就在本地加上上游仓库地址，每次都是git fetch upstream 然后基于remote/upstream/master分支，在本地新建一个分支(假设新分支是 newDev)开始开发。\n1git checkout -b newDev remote/upstream/master 新版本的git可以用\n1git switch -c newDev remote/upstream/master 好了，问题解决了，又可以愉快的参与开源项目了。\n","date":"2022-08-20T17:44:17Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/1573462520_5dc921f8018f2.jpeg","permalink":"https://lqxhub.github.io/posts/639c962/","title":"github提交pull request流程和commit重复解决办法"},{"content":"在C/C++中可以通过宏定义实现条件编译，比如在不同平台的机器上，调用不同的函数，或者通过编译是传递参数，调用不同的函数，比如下面的例子\nC++条件编译 1#include \u0026lt;iostream\u0026gt; 2 3#ifdef DEBUG 4 5void fun1() { 6 std::cout \u0026lt;\u0026lt; \u0026#34;I am debug\u0026#34; \u0026lt;\u0026lt; std::endl; 7} 8 9#else 10 11void fun1() { 12 std::cout \u0026lt;\u0026lt; \u0026#34;I am release\u0026#34; \u0026lt;\u0026lt; std::endl; 13} 14 15#endif 16 17int main() { 18 fun1(); 19 return 0; 20} 现在就可以使用不同的编译参数，控制程序调用不同的函数\n不添加参数，直接编译 g++ -o test main.cpp 程序中没有定义 DEBUG这个宏，所以程序最终会调用 I am release这个函数 执行程序验证一下 和我们预期的一样\n在编译的时候添加参数，让程序调用debug函数 g++ -DDEBUG -o test main.cpp 也没有问题，程序最终调用的是 I am debug 这个函数\ngo条件编译 go虽然不支持宏定义，但是go可以通过 build tags 实现类似的功能。 go的条件编译没有C++那么强大，可以在代码任意位置添加宏，实现条件编译，go的tags的作用范围是文件，也就是说go的编译器通过不同的tag去选择不同的文件。 先创建file.go file_debug.go main.go这三个文件\nfile.go\n1// +build !debug 2 3package main 4 5import \u0026#34;fmt\u0026#34; 6 7func Fun1() { 8\tfmt.Println(\u0026#34;I am release\u0026#34;) 9} file_debug.go\n1// +build debug 2 3package main 4 5import \u0026#34;fmt\u0026#34; 6 7func Fun1() { 8\tfmt.Println(\u0026#34;I am debug\u0026#34;) 9} main.go\n1package main 2 3func main() { 4\tFun1() 5} go的tags有几个注意的点\n// +build debug 必须在文件的最开始位置，一般在第一行 // 和 +之间必须有一个空格 // +build debug 下面必须有一个空行 只有满足这些条件后，这个tag才能正确的被编译器识别\n先正常编译 go build -o release.exe 执行程序，最终程序调用的是I am release 这个函数 在编译的时候，加参数使用debug版本的函数 go build -tags debug -o debug.exe go1.17改变 在go1.17之前，go的build tags 格式是 // +build 条件\n从go1.17开始，开始支持 //go:build 条件 这种格式了\n//go:build 条件 这种格式有什么好处呢，最明显的就是关系运算更符合编程语法了\n在之前，想要表示 windows 64位系统 或者 是 linux 系统需要下面的语法\n// +build windows,amd64 linux\n原来的build tags , 是 and 空格 是 or ，不符合常见编程语言的语法\n从go1.17开始，同样的条件可以这样写了\n//go:build (windows \u0026amp;\u0026amp; amd64) || linux\n这个表达式就比之前的明显多了\n开始测试一下 先创建file.go file_x64.go main.go三个文件\nfile.go\n1//go:build windows \u0026amp;\u0026amp; 386 2 3package main 4 5import \u0026#34;fmt\u0026#34; 6 7func Fun1() { 8\tfmt.Println(\u0026#34;I am windows 386\u0026#34;) 9} file_x64\n1//go:build windows \u0026amp;\u0026amp; amd64 2 3package main 4 5import \u0026#34;fmt\u0026#34; 6 7func Fun1() { 8\tfmt.Println(\u0026#34;I am windows amd64\u0026#34;) 9} main.go\n1package main 2 3func main() { 4\tFun1() 5} 编译 32位程序 编译64位程序 全都符合预期\n实际应用 说了这么多，tags在实际开发中有什么用处呢。 最主要的就是功能就是可以通过编译参数控制使用那些代码编译得到程序。比如在不同的平台可以有不同的函数实现。不同的版本有不同的实现。\n举个栗子 一般log都会有不同的级别，必须开发中可以通过多打印一些数据，方便调试。但是程序上线后，为了性能考虑会关闭一些低级别的log，只保留 error 和 waning 级别的log。\n虽然现在大多数log库都有log级别，但是如果不需要打印的log，但是还是调用了函数，其实还是会有一部分性能开销的，比如函数调用开销，参数传递开销等。为了进一步压榨性能，可以通过tags 在编译程序的时候，把低等级的log直接不编译到程序中。\n回到第一个示例中，修改一下代码\nfile.go\n1// +build !debug 2 3package main 4 5import \u0026#34;fmt\u0026#34; 6 7func LogDebug(info string) { 8\tfmt.Println(info) 9} file_debug.go\n1// +build debug 2 3package main 4 5func LogDebug(info string) { 6} main.go\n1package main 2 3func main() { 4\tLogDebug(\u0026#34;aaaaaaaaaaaa\u0026#34;) 5} 可以看到，在非debug版本中，模拟正常打印log，在debug版本中，log函数只有一个空的函数，没有实现。 先编译两个程序，然后通过反编译看看两次函数调用的区别\n执行如下命令\n1go build -tags debug -o debug.exe 2go build -o release.exe 3go tool objdump -s \u0026#34;main.main\u0026#34; ./debug.exe \u0026gt; ./debug.s 4go tool objdump -s \u0026#34;main.main\u0026#34; ./release.exe \u0026gt; ./release.s 分别得到debug版本和release版本的汇编代码\ndebug.s\n1TEXT main.main(SB) D:/goProject/src/build_tag/main.go 2 main.go:3\t0x49e750\t65488b0c2528000000\tMOVQ GS:0x28, CX\t3 main.go:3\t0x49e759\t488b8900000000\tMOVQ 0(CX), CX\t4 main.go:3\t0x49e760\t483b6110\tCMPQ 0x10(CX), SP\t5 main.go:3\t0x49e764\t0f8687000000\tJBE 0x49e7f1\t6 main.go:3\t0x49e76a\t4883ec58\tSUBQ $0x58, SP\t7 main.go:3\t0x49e76e\t48896c2450\tMOVQ BP, 0x50(SP)\t8 main.go:3\t0x49e773\t488d6c2450\tLEAQ 0x50(SP), BP\t9 main.go:4\t0x49e778\t488d0542fd0200\tLEAQ go.string.*+5001(SB), AX\t10 file.go:8\t0x49e77f\t48890424\tMOVQ AX, 0(SP)\t11 file.go:8\t0x49e783\t48c74424080c000000\tMOVQ $0xc, 0x8(SP)\t12 file.go:8\t0x49e78c\te87fb1f6ff\tCALL runtime.convTstring(SB)\t13 file.go:8\t0x49e791\t488b442410\tMOVQ 0x10(SP), AX\t14 file.go:8\t0x49e796\t0f57c0\tXORPS X0, X0\t15 file.go:8\t0x49e799\t0f11442440\tMOVUPS X0, 0x40(SP)\t16 file.go:8\t0x49e79e\t488d0d3be70000\tLEAQ runtime.types+57056(SB), CX\t17 file.go:8\t0x49e7a5\t48894c2440\tMOVQ CX, 0x40(SP)\t18 file.go:8\t0x49e7aa\t4889442448\tMOVQ AX, 0x48(SP)\t19 print.go:274\t0x49e7af\t488b0592a50d00\tMOVQ os.Stdout(SB), AX\t20 print.go:274\t0x49e7b6\t488d0da3c40400\tLEAQ go.itab.*os.File,io.Writer(SB), CX\t21 print.go:274\t0x49e7bd\t48890c24\tMOVQ CX, 0(SP)\t22 print.go:274\t0x49e7c1\t4889442408\tMOVQ AX, 0x8(SP)\t23 print.go:274\t0x49e7c6\t488d442440\tLEAQ 0x40(SP), AX\t24 print.go:274\t0x49e7cb\t4889442410\tMOVQ AX, 0x10(SP)\t25 print.go:274\t0x49e7d0\t48c744241801000000\tMOVQ $0x1, 0x18(SP)\t26 print.go:274\t0x49e7d9\t48c744242001000000\tMOVQ $0x1, 0x20(SP)\t27 print.go:274\t0x49e7e2\te8e998ffff\tCALL fmt.Fprintln(SB)\t28 file.go:8\t0x49e7e7\t488b6c2450\tMOVQ 0x50(SP), BP\t29 file.go:8\t0x49e7ec\t4883c458\tADDQ $0x58, SP\t30 file.go:8\t0x49e7f0\tc3\tRET\t31 main.go:3\t0x49e7f1\te87acffbff\tCALL runtime.morestack_noctxt(SB)\t32 main.go:3\t0x49e7f6\te955ffffff\tJMP main.main(SB)\t可以看到在debug版本中，LogDebug 函数已经被编译器内联处理了。最终程序是调用了fmt.Println函数。\nrelease.s\n1TEXT main.main(SB) D:/goProject/src/build_tag/main.go 2 main.go:4\t0x45b630\tc3\tRET\t3 :0\t0x45b631\tcc\tINT $0x3\t4 :0\t0x45b632\tcc\tINT $0x3\t5 :0\t0x45b633\tcc\tINT $0x3\t6 :0\t0x45b634\tcc\tINT $0x3\t7 :0\t0x45b635\tcc\tINT $0x3\t8 :0\t0x45b636\tcc\tINT $0x3\t9 :0\t0x45b637\tcc\tINT $0x3\t10 :0\t0x45b638\tcc\tINT $0x3\t11 :0\t0x45b639\tcc\tINT $0x3\t12 :0\t0x45b63a\tcc\tINT $0x3\t13 :0\t0x45b63b\tcc\tINT $0x3\t14 :0\t0x45b63c\tcc\tINT $0x3\t15 :0\t0x45b63d\tcc\tINT $0x3\t16 :0\t0x45b63e\tcc\tINT $0x3\t17 :0\t0x45b63f\tcc\tINT $0x3\t相比之下，release版本的汇编代码就简单多了，因为编译器会进行内联处理，但是发现LogDebug这个函数是一个空函数，所以就直接跳过编译了。\n总结 go也可以实现条件编译，但是不能像C++那样灵活，只能以文件为单位 在go1.17之前使用// +build 条件，从1.17开始可以使用//go:build 条件 go预设了很多tags，也可以自定义tags 在编译时，使用 -tags 个自定义的tags赋值 ","date":"2022-07-31T17:11:07Z","permalink":"https://lqxhub.github.io/posts/84a29eaf/","title":"go使用build tags实现条件编译，Go中的条件编译，Go中的build tags的使用方法及其实现原理 - QX's blog"},{"content":"一直以来算法题刷的比较少，算法这块算是我的弱项。前几天，看到一个挺有意思的链表题\n原题 原题是这样的，给一个链表 [1,2,3,4,5] 然后转换成 [5,3,1,2,4] 这种格式 找一下规律，其实就是第一个先拿第一个元素，然后把第二个元素放在新的链表后面，第三个元素放在新的链表前面，然后第四个放在新链表的后面，第五个放在新链表前面，以此类推。\n其实就是一个链表头插和尾插的结合嘛\n直接上代码\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5) 6 7type Node struct { 8\tNext *Node 9\tVal int 10} 11 12//通过数组生成链表 13func Make(nums []int) *Node { 14\thead := \u0026amp;Node{} 15\tmove := head 16\tfor _, num := range nums { 17\tt := \u0026amp;Node{ 18\tVal: num, 19\t} 20\tmove.Next = t 21\tmove = move.Next 22\t} 23\treturn head.Next 24} 25 26//打印链表 27func Print(list *Node) { 28\tfor h := list; h != nil; h = h.Next { 29\tfmt.Printf(\u0026#34;%d \u0026#34;, h.Val) 30\t} 31\tfmt.Println() 32} 33 34func main() { 35\tnums := make([]int, 5) 36\tfor i := 1; i \u0026lt;= 5; i++ { 37\tnums[i-1] = i 38\t} 39\tnodes := Make(nums) 40\tPrint(nodes) 41\tnodes = TurnList(nodes) 42\tPrint(nodes) 43} 44 45//转换链表 46func TurnList(list *Node) *Node { 47\ti := 0 48\th := list 49\tt := list 50\tlist = list.Next 51\tfor list != nil { 52\tif i%2 == 0 { 53\tt.Next = list 54\tlist = list.Next 55\tt = t.Next 56\tt.Next = nil 57\t} else { 58\tx := list.Next 59\tlist.Next = h 60\th = list 61\tlist = x 62\t} 63\ti++ 64\t} 65\treturn h 66} 初始链表如图： 变换过程： 就是样根据奇偶分别头插和尾插就能完成 这么简单当时就是没写出来。 淦\n只写这一个也抬不过瘾了，再来一个链表排序的 leetcode 148\n链表排序 排序的方法有好多，但是我感觉适合用于链表的是 插入排序 和 归并排序 尤其是归并排序，简直就是为链表定做的。\n先来一个简单的，插入排序吧 插入排序的思想就是选择一个基准，然后把整个序列中的比自己小的放到基准的前面，用数组的形式还是很好理解和操作的。但是链表不能随机访问，所以不能用数组那样的插入排序了，需要做一下变换，看起来有点像是选择排序和插入排序的结合。 不废话了，直接上代码，插入排序：\n1func InsertSort(list *Node) *Node { 2\thead := \u0026amp;Node{ 3\tNext: list, 4\t} 5\th := head 6\tfor h.Next != nil { 7\tt := h 8\tfor t.Next != nil { 9\tif t.Next.Val \u0026lt; h.Next.Val { 10\tx := t.Next 11\tt.Next = t.Next.Next 12\tx.Next = h.Next 13\th.Next = x 14\t} else { 15\tt = t.Next 16\t} 17\t} 18\th = h.Next 19\t} 20\treturn head.Next 21} 无序的链表\n排序过程 图中有个迷惑的地方，就是蓝色的线是 next 指针的指向，就是一开始的时候，head h t 的next指针指向 3 也就是 h t自身是指向 head的，head是一开始的时候，新建的一个临时结点，因为单向链表无法向前查找，只能向后查找，所以要用 next 指针。 同样，在使用 t 和 h 指针的时候，也都是使用 next 用来判断。 比较逻辑 t.Next.Val \u0026lt; h.Next.Val 当 t的 next 是 3，h的 next 是 2 时,满足条件，所以交换 2 和 3 如此往复，当 t 走完一趟后，链表中的第一个结点就是最小的了。 当 t 走完一趟后，h指针要后移一个。以此类推，直到 h 和 t 都走完后，就完成了排序。\n这个排序方法用的是插入排序的思想加上一些选择排序的方法完成的，时间复杂度还是O(n²)。是稳定的排序。\n归并排序 相比插入排序和选择排序，归并排序就要复杂一些了\n归并排序的思想是分治法，把整个序列拆分，当拆分到不能再拆分时，子序列就是有序的了。也就是当序列长度是1的时候，序列就是有序的。然后在把子序列有序的合并起来。\n归并排序简直就是为了链表排序而生的。如果用数组排序，拆分和重组还是比较复杂的，链表就简单多了。说实话，数组的归并排序我都不会写。\n线上代码，归并排序\n1func MergerSort(list *Node) *Node { 2\tif list == nil || list.Next == nil { 3\treturn list 4\t} 5 6\tfast := list.Next 7\tslow := list 8\tfor fast != nil \u0026amp;\u0026amp; fast.Next != nil { 9\tfast = fast.Next.Next 10\tslow = slow.Next 11\t} 12 13\th1 := MergerSort(slow.Next) 14\tslow.Next = nil 15\th2 := MergerSort(list) 16 17\treturn Merge(h1, h2) 18} 19 20func Merge(list1, list2 *Node) *Node { 21\thead := \u0026amp;Node{} 22\th := head 23\tfor list1 != nil \u0026amp;\u0026amp; list2 != nil { 24\tif list1.Val \u0026lt; list2.Val { 25\th.Next = list1 26\tlist1 = list1.Next 27\t} else { 28\th.Next = list2 29\tlist2 = list2.Next 30\t} 31\th = h.Next 32\t} 33\tif list1 != nil { 34\th.Next = list1 35\t} else { 36\th.Next = list2 37\t} 38\treturn head.Next 39} 归并排序有两个部分，一个是拆分，另一个是合并。\n拆分 拆分是二分法，也就是每次从中间分开。链表中找到中间位置，最方便的就是快慢指针了，就是一个指针每次移动一个位置，指针每次移动两个位置。当快的指针移动到最后的时候，慢的指针正好移动到链表的中间位置。递归拆分，直到链表长度是1的时候，就完成了拆分。\n合并 合并的过程其实就是合并两个有序链表。leetcode 21 很简单没什么需要解释的。\n简单的把排序过程花了出来。\n整个归并排序，不好理解的地方就是递归拆分的过程，其实也不难理解，就是能拆的情况下就一直拆，直到不能拆了为止。\n1 fast := list.Next 2 slow := list 3 for fast != nil \u0026amp;\u0026amp; fast.Next != nil { 4 fast = fast.Next.Next 5 slow = slow.Next 6 } 当一次拆分完成时，slow 指针指向的就是链表的中间位置，所以 slow 的 next 就是链表的后半部分了，list 指针就是链表的前半部分。\n拆分的过程中有个地方需要注意，就是断链，slow.Next = nil 因为在用快慢指针找到链表的中间位置时,并没有把链表切分开，需要手动把链表断开，要不然从头开始遍历，还是能遍历整个链表的。\n总结 链表的问题其实没有没有特别难的算法，基本都是一些基础的操作。链表难的地方是因为内存地址不连续，不像数组那样可以随机访问，只能通过指针操作，理解起来没有那么直观所以会觉难。遇到链表问题就画图，基本上图画出来了，问题也基本能解决了。\n","date":"2022-05-21T16:56:04Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images/blog/02F73302CA875C38.jpg","permalink":"https://lqxhub.github.io/posts/f8e89faa/","title":"链表排序，LeetCode链表排序，golang链表归并排序 - QX's blog"},{"content":"五一假期在家没事逛论坛的时候，发现了一个宝藏网站，传送门 这个网站可以在线生成多种语言的汇编代码，有这个好东西，那必须拿go实验一番。\n很久之前我写过一篇go通过go汇编看多返回值实现的文章传送门。当时写的时候比较早，后来 go 1.17 对函数调用时，传递参数做了修改，简单说就是go1.17之前，函数参数是通过栈空间来传递的，在go1.17时做出了改变，在一些平台上（AMD64）可以像C,C++那样使用寄存器传递参数和函数返回值了。为什么做出这个改变呢，原因就是寄存器更快。虽然内存已经很快了，但是还是没法和寄存器相比。之前为啥不用寄存器，用栈空间，原因是实现简单，不用考虑不同平台，不用架构的区别。\n简单总结一下两种方式\n栈空间： 优点：实现简单，不用区分不同的平台，通用性强 缺点：效率低 寄存器： 优点：速度快 缺点：通用性差，不同的平台需要单独处理 当然，这里说的通用性差是对于编译器来说的 go汇编基础知识 再来总结一次go汇编的基础知识吧，现在回头看之前总结的还是不全面的 go使用的 plan9 汇编，这个和 AT\u0026amp;T 的汇编差别还是有点大的，我个人感觉plan9汇编比较重要的就是四个寄存器，只要理解了这四个寄存器，汇编就理解了一半了\n汇编中个几个术语:\n栈：进程、线程、goroutine 都有自己的调用栈，先进后出（FILO） 栈帧：可以理解是函数调用时，在栈上为函数所分配的内存区域 调用者：caller，比如：A 函数调用了 B 函数，那么 A 就是调用者 被调者：callee，比如：A 函数调用了 B 函数，那么 B 就是被调者 寄存器 说明 SB(Static base pointer) global symbols 全局静态指针 FP(Frame pointer) arguments and locals 指向栈帧的开始 SP(Stack pointer) top of stack 指向栈顶 PC(Program counter) jumps and branches 简单说程序计数器 简单展开说一下几个寄存器吧\nSB：全局静态指针，即程序地址空间的开始地址。一般用在声明函数、全局变量中。 FP：指向的是 caller 调用 callee 时传递的第一个参数的位置，可以看作是指向两个函数栈的分割位置；但是FP指向的位置不在 callee 的 stack frame 之内。而是在 caller 的 stack frame 上，指向调用 add 函数时传递的第一个参数的位置；可以在 callee 中用 symbol+offset(FP) 来获取入参的参数值，比如 a+8(FP)。虽然 symbol 没有什么具体意义，但是不加编译器会报错。 SP：这个是最常用的寄存器了，同样也是最复杂的寄存器了。不同的引用方式，代表不同的位置。SP寄存器 分为伪 SP 寄存器和硬件 SP 寄存器。symbol+offset(SP) 形式，则表示伪寄存器 SP （这个也简称为 BP）。如果是 offset(SP) 则表示硬件寄存器 SP。伪 SP 寄存器指向当前栈帧第一个局部变量的结束位置；硬件SP指向的是整个函数栈结束的位置。**有个比较坑的地方：**对于编译输出(go tool compile -S / go tool objdump)的代码来讲，所有的 SP 都是硬件 SP 寄存器，无论是否带 symbol（这一点非常具有迷惑性，需要慢慢理解。往往在分析编译输出的汇编时，看到的就是硬件 SP 寄存器）。 PC：这个就是计算机常见的 pc 寄存器，在 x86 平台下对应 ip 寄存器，amd64 上则是 rip。这个很少有用到。 通过一个栈帧的图来理解一下这几个寄存器\n大体的栈帧就是图中的这样，图中标注的寄存器都是以 callee 函数为基准的\n通过图中可知，如果callee函数中没有局部变量的话，SP硬寄存器和SP伪寄存器指向的是同一个地方\n伪 FP 寄存器对应的是 caller 函数的帧指针，一般用来访问 callee 函数的入参参数和返回值。伪 SP 栈指针对应的是当前 callee 函数栈帧的底部（不包括参数和返回值部分），一般用于定位局部变量。硬件 SP 是一个比较特殊的寄存器，因为还存在一个同名的 SP 真寄存器，硬件 SP 寄存器对应的是栈的顶部。\n在编写 Go 汇编时，当需要区分伪寄存器和真寄存器的时候只需要记住一点：伪寄存器一般需要一个标识符和偏移量为前缀，如果没有标识符前缀则是真寄存器。比如(SP)、+8(SP)没有标识符前缀为真 SP 寄存器，而 a(SP)、b+8(SP)有标识符为前缀表示伪寄存器。\n还有一点\n如果callee的栈空间大小是0的话， caller BP 是不会被压入栈中的，此时的SP硬件寄存器和伪FP寄存器指向的是同一个位置。\n在汇编中，函数的定义\n1TEXT \u0026#34;\u0026#34;.add(SB), NOSPLIT|ABIInternal, $0-24 TEXT 是一个特殊的指令，定义一个函数\n.add 是函数的名\nNOSPLIT 向编译器表明不应该插入 stack-split 的用来检查栈需要扩张的前导指令\n$0-24 这两个参数，0是声明这个函数需要的栈空间的大小，一般来说就是局部变量需要的空间，单位是位。 24是声明函数传入参数和返回值需要的栈空间的大小，单位也是位。\n生成汇编 了解了这些基本概念后，上一段代码，通过汇编看一下不同版本go是如何处理函数传递参数的\n先通过一段简单的代码看一下区别\n1package main 2 3func main(){ 4 add(10,20) 5} 6 7//go:noinline 8func add(a,b int) int{ 9 return a+b 10} //go:noinline 这个是告诉编译器不要对这个函数内联，这个东西叫go的编译指令，go还有你很多别的指令，这里就不展开了。 想想go也挺有意思的，C++是通过 inline 显式的指定要内联，go是告诉编译器不要内联。\n先看一下在1.16下的汇编代码\n1main_pc0: 2 .file 1 \u0026#34;\u0026lt;source\u0026gt;\u0026#34; 3 .loc 1 5 0 4 TEXT \u0026#34;\u0026#34;.main(SB), ABIInternal, $32-0 5 MOVQ (TLS), CX 6 CMPQ SP, 16(CX) 7 PCDATA $0, $-2 8 JLS main_pc64 9 PCDATA $0, $-1 10 SUBQ $32, SP 11 MOVQ BP, 24(SP) 12 LEAQ 24(SP), BP 13 FUNCDATA $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 14 FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 15 .loc 1 11 0 16 MOVQ $10, (SP) 17 MOVQ $20, 8(SP) 18 PCDATA $1, $0 19 CALL \u0026#34;\u0026#34;.add(SB) 20 .loc 1 12 0 21 MOVQ 24(SP), BP 22 ADDQ $32, SP 23 RET 24 NOP 25 .loc 1 5 0 26 PCDATA $1, $-1 27 PCDATA $0, $-2 28 NOP 29main_pc64: 30 CALL runtime.morestack_noctxt(SB) 31 PCDATA $0, $-1 32 JMP main_pc0 33 .loc 1 21 0 34 TEXT \u0026#34;\u0026#34;.add(SB), NOSPLIT|ABIInternal, $0-24 35 FUNCDATA $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 36 FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 37 .loc 1 22 0 38 MOVQ \u0026#34;\u0026#34;.b+16(SP), AX 39 MOVQ \u0026#34;\u0026#34;.a+8(SP), CX 40 ADDQ CX, AX 41 MOVQ AX, \u0026#34;\u0026#34;.~r2+24(SP) 42 RET 代码有很多，只关注下面图中标注的\n通 MOVQ \u0026quot;\u0026quot;.b+16(SP), AX 和 MOVQ \u0026quot;\u0026quot;.a+8(SP), CX 可以得知，函数是通过SP寄存器偏移完成传递参数的。 这里要注意，.b+16(SP) 这种写法看着像是使用的是伪SP寄存器，实际上用的是硬件SP寄存器\n同样的，在函数调用之前，也会把数值放到栈的指定位置\nMOVQ $10, (SP) , MOVQ $20, 8(SP)\n把编译器换成最新的 1.18看一下\n1main_pc0: 2 .file 1 \u0026#34;\u0026lt;source\u0026gt;\u0026#34; 3 .loc 1 5 0 4 TEXT \u0026#34;\u0026#34;.main(SB), ABIInternal, $24-0 5 CMPQ SP, 16(R14) 6 PCDATA $0, $-2 7 JLS main_pc47 8 PCDATA $0, $-1 9 SUBQ $24, SP 10 MOVQ BP, 16(SP) 11 LEAQ 16(SP), BP 12 FUNCDATA $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 13 FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 14 .loc 1 11 0 15 MOVL $10, AX 16 MOVL $20, BX 17 PCDATA $1, $0 18 NOP 19 CALL \u0026#34;\u0026#34;.add(SB) 20 .loc 1 12 0 21 MOVQ 16(SP), BP 22 ADDQ $24, SP 23 RET 24main_pc47: 25 NOP 26 .loc 1 5 0 27 PCDATA $1, $-1 28 PCDATA $0, $-2 29 CALL runtime.morestack_noctxt(SB) 30 PCDATA $0, $-1 31 JMP main_pc0 32 .loc 1 21 0 33 TEXT \u0026#34;\u0026#34;.add(SB), NOSPLIT|ABIInternal, $0-16 34 FUNCDATA $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 35 FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 36 FUNCDATA $5, \u0026#34;\u0026#34;.add.arginfo1(SB) 37 FUNCDATA $6, \u0026#34;\u0026#34;.add.argliveinfo(SB) 38 PCDATA $3, $1 39 .loc 1 22 0 40 ADDQ BX, AX 41 RET 在1.18的汇编代码中就没有通过栈空间来传递参数了，而是直接通过寄存器完成操作， ADDQ BX, AX，并且返回值直接放到寄存器中。\n寄存器数量是有上限的，如果传递的参数个数超过了寄存器的上限，又会怎样处理呢\n1package main 2 3func main(){ 4 add(1,2,3,4,5,6,7,8,9,10,11,12) 5} 6 7//go:noinline 8func add(a,b,c,d,e,f,g,h,i,j,k,l int) int{ 9 return a+b+c+d+e+f+g+h+i+j+k+l 10} 对应的汇编\n1main_pc0: 2 .file 1 \u0026#34;\u0026lt;source\u0026gt;\u0026#34; 3 .loc 1 5 0 4 TEXT \u0026#34;\u0026#34;.main(SB), ABIInternal, $104-0 5 CMPQ SP, 16(R14) 6 PCDATA $0, $-2 7 JLS main_pc111 8 PCDATA $0, $-1 9 SUBQ $104, SP 10 MOVQ BP, 96(SP) 11 LEAQ 96(SP), BP 12 FUNCDATA $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 13 FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 14 .loc 1 11 0 15 MOVQ $10, (SP) 16 MOVQ $11, 8(SP) 17 MOVQ $12, 16(SP) 18 MOVL $1, AX 19 MOVL $2, BX 20 MOVL $3, CX 21 MOVL $4, DI 22 MOVL $5, SI 23 MOVL $6, R8 24 MOVL $7, R9 25 MOVL $8, R10 26 MOVL $9, R11 27 PCDATA $1, $0 28 NOP 29 CALL \u0026#34;\u0026#34;.add(SB) 30 .loc 1 12 0 31 MOVQ 96(SP), BP 32 ADDQ $104, SP 33 RET 34main_pc111: 35 NOP 36 .loc 1 5 0 37 PCDATA $1, $-1 38 PCDATA $0, $-2 39 CALL runtime.morestack_noctxt(SB) 40 PCDATA $0, $-1 41 JMP main_pc0 42 .loc 1 21 0 43 TEXT \u0026#34;\u0026#34;.add(SB), NOSPLIT|ABIInternal, $0-96 44 FUNCDATA $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 45 FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 46 FUNCDATA $5, \u0026#34;\u0026#34;.add.arginfo1(SB) 47 FUNCDATA $6, \u0026#34;\u0026#34;.add.argliveinfo(SB) 48 PCDATA $3, $1 49 .loc 1 22 0 50 LEAQ (BX)(AX*1), DX 51 ADDQ DX, CX 52 ADDQ DI, CX 53 ADDQ SI, CX 54 ADDQ R8, CX 55 ADDQ R9, CX 56 ADDQ R10, CX 57 ADDQ R11, CX 58 MOVQ \u0026#34;\u0026#34;.j+8(SP), DX 59 ADDQ DX, CX 60 MOVQ \u0026#34;\u0026#34;.k+16(SP), DX 61 ADDQ DX, CX 62 MOVQ \u0026#34;\u0026#34;.l+24(SP), DX 63 LEAQ (DX)(CX*1), AX 64 RET 通过汇编可以看到，会先使用寄存器，当寄存器不够时，会使用栈空间。\n手写汇编 通过手写一段汇编代码，验证一下各个寄存器的位置，我用的go版本是 1.14.13，所以传参数用的是栈空间。 在 main.go 文件中\n1package main 2 3func add(int, int) int 4 5func main() { 6\tprint(add(10, 20)) 7} 定义一个 main 函数作为整个程序的入口，声明一个 add(int, int) int 函数，add 函数的具体实现是用汇编写的, 在 main.go 同级目录下创建一个 add_amd64.s 的文件。\n使用硬BP寄存器 1TEXT ·add(SB), $0-24 2 MOVQ 8(SP), AX 3 MOVQ 16(SP), BX 4 ADDQ BX, AX 5 MOVQ AX, 24(SP) 6 RET 使用 go run . 命令，看一下程序执行的结果。 这时候的栈帧如图所示 因为add函数栈空间是0，所以伪SP寄存器没有被压入栈中，伪SP寄存器和硬件SP寄存器指向的是同一个位置。\n使用伪SP寄存器 1TEXT ·add(SB), $16-24 2 MOVQ a+16(SP), AX 3 MOVQ b+24(SP), BX 4 ADDQ BX, AX 5 MOVQ AX, ret+32(SP) 6 RET 为了区分对比，这时候把add函数的栈空间设置为16，然后使用伪SP寄存器来获取值。 执行结果如下： 这时候的栈空间如图 使用FP寄存器 代码如下:\n1TEXT ·add(SB), $16-24 2 MOVQ a+0(FP), AX 3 MOVQ b+8(FP), BX 4 ADDQ BX, AX 5 MOVQ AX, ret+16(FP) 6 RET 执行结果:\n说明还是正确的，此时的栈空间没有变化，和上面是一样的。\n到这，应该能理解各个寄存器的相对位置了吧： 在callee栈空间不为0的时候，\n1FP = 硬件SP + framsize + 16 2SP = 硬件SP + framsize 在callee栈空间为0的时候，\n1FP = 硬件SP + 8 2SP = 硬件SP 汇编简单分析 通过上面的代码会发现，手写汇编的代码和反汇编的代码有些不同。反汇编得到的代码，在函数前面会有一段 CALL runtime.morestack_noctxt(SB) 其实这个是编译器自动插入的一段函数，这段指令会调用一次 runtime.morestack_noctxt 这个函数具体的作用是挺复杂的，主要有 检查是否需要扩张栈，go的栈空间是可以动态扩充的，所以在调用函数前会检查当前的栈空间是否需要扩充。还有一个功能就是检查当前协程需要抢占。go在1.14之前goroutine的抢占是协作式抢占模式，怎么判断一个协程是否需要抢占呢？后台协程会定时扫描当前运行中的协程，如果发现一个协程运行比较久，会将其标记为抢占状态。这个扫描的时间点就是函数调用期间完成的。\n不同类型参数传递 传结构体 1package main 2 3type One struct { 4 a int 5 b int 6} 7 8func main(){ 9 o := One { 10 a:10, 11 b.20, 12 } 13 f1(o) 14} 15 16//go:noinline 17 func f1(o One) int { 18 return o.a + o.b 19 } 只贴 关键的汇编代码吧\n1 MOVQ $10, (SP) 2 MOVQ $0, 8(SP) 3 PCDATA $1, $0 4 CALL \u0026#34;\u0026#34;.f1(SB) 5 6.......................... 7 8 TEXT \u0026#34;\u0026#34;.f1(SB), NOSPLIT|ABIInternal, $0-24 9 MOVQ \u0026#34;\u0026#34;.o+16(SP), AX 10 MOVQ \u0026#34;\u0026#34;.o+8(SP), CX 11 ADDQ CX, AX 12 MOVQ AX, \u0026#34;\u0026#34;.~r1+24(SP) 13 RET 在传结构体的时候，只把结构体的内容传进去了。\n传结构体指针 1package main 2 3type One struct { 4 a int 5 b int 6} 7 8func main(){ 9 o := \u0026amp;One{ 10 a:10, 11 b:20, 12 } 13 f1(o) 14} 15 16//go:noinline 17 func f1(o *One) int { 18 return o.a + o.b 19 } 汇编\n1 LEAQ \u0026#34;\u0026#34;..autotmp_2+16(SP), AX 2 MOVQ AX, (SP) 3 PCDATA $1, $0 4 CALL \u0026#34;\u0026#34;.f1(SB) 5 6....................... 7 8 TEXT \u0026#34;\u0026#34;.f1(SB), NOSPLIT|ABIInternal, $0-16 9 MOVQ \u0026#34;\u0026#34;.o+8(SP), AX 10 MOVQ (AX), CX 11 ADDQ 8(AX), CX 12 MOVQ CX, \u0026#34;\u0026#34;.~r1+16(SP) 13 RET 可以看到，传递指针的时候，只是把结构体第一个元素的地址传递进去了。\n如果是传一个空的结构体\n1package main 2 3type One struct { 4} 5 6func main(){ 7 o := One{} 8 f1(o,10,20) 9} 10 11//go:noinline 12 func f1(o One, a,b int) int { 13 return a + b 14 } 汇编\n1 TEXT \u0026#34;\u0026#34;.f1(SB), NOSPLIT|ABIInternal, $0-24 2 .loc 1 15 0 3 MOVQ \u0026#34;\u0026#34;.b+16(SP), AX 4 MOVQ \u0026#34;\u0026#34;.a+8(SP), CX 5 ADDQ CX, AX 6 MOVQ AX, \u0026#34;\u0026#34;.~r3+24(SP) 7 RET 可以看到，当传递一个空结构体时，相当于没有传递，因为空结构体的空间大小是0，所以编译器就给忽略了。\n最后 暂时就想到这么多，先写这些吧，后面想起别的再补充吧\n","date":"2022-05-02T19:10:56Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/3622259-778243d5661a39cd.webp","permalink":"https://lqxhub.github.io/posts/549df04c/","title":"golang汇编 深入探讨了 Go 语言中的汇编实现及参数传递的演变 - QX's blog"},{"content":"go的1.18版本在3月15这天正式发布了 release notes，虽然在bate版本就可以尝试了，毕竟那时候还没正式发布，也就没去尝试了，现在正式发布了，马上就更了尝试一下。\n总算是千呼万唤始出来，其实我对Go的泛型还是挺期待的，毕竟用 interface 能实现一些东西，但是还是不如原生支持来得好，用interface首先会因为类型转换带来一些性能损失，用interface做类型强转，有时候会因为不小心写错了，导致一些运行时错误。要是支持泛型，这些问题就会解决了，一些通用的库就会更好用了。\n当然泛型也不是完美无缺的，泛型会导致语言变得复杂，大型项目的代码可能会更难读、难理解了，这也会导致编译器实现起来更复杂。但是优势还是大于劣势的\n这里想骂一句，其他语言的泛型一般都是用 \u0026lt;\u0026gt; go 的泛型用 [] 搞不懂为啥不用 \u0026lt;\u0026gt; 非要独树一帜，打不过就加入，你说用啥就用啥吧\n先通过几个简单的例子来练习一下\n泛型函数 1func main() { 2\tfmt.Println(Max[int](1, 2)) 3\tfmt.Println(Max(1.5, 2.6)) 4\tfmt.Println(Max(\u0026#34;abc\u0026#34;, \u0026#34;efg\u0026#34;)) 5} 6 7func Max[T int | float64 | string](a, b T) T { 8\tif a \u0026gt; b { 9\treturn a 10\t} 11\treturn b 12} 通过泛型，实现了一个获取大值的函数，如果没有泛型，就要手写三个不同类型的函数。 在使用泛型函数的时候，fmt.Println(Max[int](1, 2)) 和 fmt.Println(Max(1.5, 2.6)) 两种写法都是可以的。可以指定类型，也可以不指定，让编译器自己类型推导\nMax函数的参数可不是任意类型的参数都可以传入，只能传入int float64 string 这三种类型，因为定义函数的时候，类型参数就只有这三种。泛型不是任意类型的，也是有类型的，这就是泛型的类型约束\n泛型约束 1func main() { 2\tx := uint32(10) 3\ty := uint32(20) 4\tfmt.Println(Max(x, y)) 5} 6 7func Max[T int | float64 | string](a, b T) T { 8\tif a \u0026gt; b { 9\treturn a 10\t} 11\treturn b 12} 上面这段代码是无法通过编译的，会有如下的报错 uint32 does not implement int|float64|string 因为 Max 只允许 int float64 string 这三种\n还有一种情况是无法通过编译的\n1type Myint int 2 3func main() { 4\tx := Myint (10) 5\ty := Myint (20) 6\tfmt.Println(Max(x, y)) 7} 8 9func Max[T int | float64 | string](a, b T) T { 10\tif a \u0026gt; b { 11\treturn a 12\t} 13\treturn b 14} 这个也是无法通过编译的，虽然 Myint 是 int 类型的，但是依然无法通过编译。这种情况是可以在定义时，修改一下就行了\n1type Myint int 2 3func main() { 4\tx := Myint (10) 5\ty := Myint (20) 6\tfmt.Println(Max(x, y)) 7} 8 9func Max[T ~int | ~float64 | ~string](a, b T) T { 10\tif a \u0026gt; b { 11\treturn a 12\t} 13\treturn b 14} 在定义函数时，只要在类型前加上 ~ 就可以了。\n每次在定义泛型约束时，都要写一堆类型好麻烦啊，go 官方也想到了，就是定义约束类型\n1type MyGenerics interface { 2 ~int | ~float64 | ~string 3} 4 5func Max[T MyGenerics](a, b T) T { 6\tif a \u0026gt; b { 7\treturn a 8\t} 9\treturn b 10} 这样就完成了一个泛型的约束类型的定义\n而且go的泛型约束也可以像 interface 那样相互嵌套的\n1type Int interface { 2 ~int | ~uint 3} 4 5type Float interface { 6 ~float32 | ~float64 7} 8 9type Number interface { 10\tInt | Float 11} 12 13func Max2[T Number](a, b T) T { 14\tif a \u0026gt; b { 15\treturn a 16\t} 17\treturn b 18} Go内置一个 constraints包，定义好了一些常用的泛型约束\n1type Signed interface { 2\t~int | ~int8 | ~int16 | ~int32 | ~int64 3} 4 5type Unsigned interface { 6\t~uint | ~uint8 | ~uint16 | ~uint32 | ~uint64 | ~uintptr 7} 8 9type Integer interface { 10\tSigned | Unsigned 11} 12 13type Float interface { 14\t~float32 | ~float64 15} 16 17type Complex interface { 18\t~complex64 | ~complex128 19} 20 21type Ordered interface { 22\tInteger | Float | ~string 23} go 还定义了一个 类型约束 any 看这个名字应该就知道什么意思了，就是任意类型，这个也没啥神秘的，就是给 interface 整了一个别名\n1type any interface{} go 还有一种约束类型，函数类型约束，也就是只有实现了 对应函数，才能作为泛型类型\n1type MyToString interface { 2\tToString() string 3} 4 5type Myint int 6 7func (m Myint) ToString() string { 8\treturn strconv.Itoa(int(m)) 9} 10 11func MyString[T MyToString](value T) { 12\tfmt.Println(value.ToString()) 13} 14 15func main() { 16\tvar x Myint 17\tx = 100 18\tMyString[Myint](x) 19} 在定义函数 MyString 函数的时候，MyString[T MyToString](value T) 函数的泛型约束时一个接口，函数 MyString 的类型约束就是 实现了 MyToString 接口的类型。所以传入函数的 T 类型的 value 一定会有 ToString 这个函数。\n泛型结构体 1func main() { 2\tstack := NewStack[int](10) 3 4\tfor i := 0; i \u0026lt; 10; i++ { 5\tstack.Push(i) 6\t} 7 8\tfor i := 0; i \u0026lt; 10; i++ { 9\tfmt.Printf(\u0026#34;%d \u0026#34;, stack.Pop()) 10\t} 11} 12 13func NewStack[T any](size int) *Stack[T] { 14\tstack := \u0026amp;Stack[T]{ 15\tarr: make([]T, size), 16\t} 17\tstack.size = size 18\tstack.index = -1 19\treturn stack 20} 21 22type Stack[T any] struct { 23\tarr []T 24\tsize int 25\tindex int 26} 27 28func (s *Stack[T]) Full() bool { 29\treturn s.index+1 == s.size 30} 31 32func (s *Stack[T]) Empty() bool { 33\treturn s.index \u0026lt; 0 34} 35 36func (s *Stack[T]) Push(v T) bool { 37\tif s.Full() { 38\treturn false 39\t} 40\ts.index++ 41\ts.arr[s.index] = v 42\treturn true 43} 44 45func (s *Stack[T]) Pop() T { 46\tvar v T 47\tif s.Empty() { 48\treturn v 49\t} 50\tv = s.arr[s.index] 51\ts.index-- 52\treturn v 53} 用泛型写了一个简单的栈\n1type Stack[T any] struct { 2 arr []T 3 size int 4 index int 5} 在定义结构体的同时指定了泛型类型，这样就定义了泛型的结构体\n目前结构体的泛型还是有一些限制，比如结构的 method 不能是泛型的\n1type Mystruct struct { 2} 3 4func (m Mystruct) One[T ~int | ~float64](value T) { 5\tfmt.Println(value) 6} 这段代码是编译不过的，后续可能会完善这部分吧\nend go的泛型总算是正式发布了，趁周末学习了一波。现在go泛型刚发布，工作中用上泛型可能还要等很长时间，毕竟线上的东西稳定最重要。我记得我刚入职公司的时候，那时候公司用的go版本还是 1.4， 那时候go 已经到了 1.13了。后来因为dlv调试不兼容低版本的go，就逐步升上来了。相信go的泛型肯定是一个趋势，后续很多的内置酷和第三方库都会用上泛型了。 先学到这里吧，等有空继续学习go泛型的更多知识，比如底层是怎样实现的，是java那样类型擦除还是C++那样代码展开的。\n","date":"2022-03-19T17:38:55Z","permalink":"https://lqxhub.github.io/posts/c86abacd/","title":"golang泛型初尝试"},{"content":"在go中实现一个tcp服务器还是很简单的，至少和C/C++相比还是很简单的了。\n一个简单的例子\n1\tlisten, err := net.Listen(\u0026#34;tcp\u0026#34;, \u0026#34;0.0.0.0:8088\u0026#34;) 只需要这样一行就可以监听了，就能等待客户端连接了。是不是还是很简单的\n在C/C++中，需要依次 调用socket() bind() listen() accept()函数，完成打开，绑定，监听，等待操作，才能完成等待客户端来连接。 这还没完，想要提高性能还需要自己通过 epoll等手段完成多路复用。\n其实在C/C++中是通过调用系统函数来完成的，只是go把这部分东西都给包装了，只需要简单的一行就可以完成了。\n其实在go中也可以通过系统函数自己来完成些事情。只是这些事情比较复杂，跨平台还不好弄，像使用了epoll就只能在linux系统上编译运行了。\n废话不多说了，直接上函数吧。在go中和C/C++中区别不大，同样是通过系统调用这些函数来完成。\n1func Socket(domain, typ, proto int) (fd int, err error) 2 3func Bind(fd int, sa Sockaddr) (err error) 4 5func Listen(s int, n int) (err error) 6 7func Accept(fd int) (nfd int, sa Sockaddr, err error) 在go开启tcp 服务需要用到的函数.\n1func EpollCreate(size int) (fd int, err error) 2 3func EpollCtl(epfd int, op int, fd int, event *EpollEvent) (err error) 4 5func EpollWait(epfd int, events []EpollEvent, msec int) (n int, err error) 在go中使用epoll需要的函数\n这些函数都是在syscall 包下，所以这些函数不是所有系统下都有的， 像epoll 相关的函数，就只能在linux下才能编译过。\n所以，在这里就引申出一个东西就是 条件编译 在C/C++中可以通过宏定义来实现条件编译\n1 #ifdef linux 2 cout\u0026lt;\u0026lt;\u0026#34;It is in Linux OS!\u0026#34;\u0026lt;\u0026lt;endl; 3 #endif 这段代码就只能在linux系统上才会被编译\ngo虽然没有这么强大的宏命令来判断，但是go中可以通过编译标签 和 文件后缀来判断。\n比如在文件的第一行加上\n1// +build linux 2..... 3..... 这样，这个文件就只能在linux上才会被编译（注意，// +build linux下面一定要有一个空行） 详细用法看这里 go条件编译\n下面开始具体的代码\n1//定义一个结构体存储相关的数据 2type EpollM struct { 3\tconn map[int]*ServerConn 4 5\tsocketFd int //监听socket的fd 6\tepollFd int //epoll的fd 7} 8 9//开启监听 10func (e *EpollM) Listen(ipAddr string, port int) error { 11\t//使用系统调用,打开一个socket 12\tfd, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_STREAM, syscall.IPPROTO_TCP) 13\tif err != nil { 14\treturn err 15\t} 16 17\t//ip地址转换 18\tvar addr [4]byte 19\tcopy(addr[:], net.ParseIP(ipAddr).To4()) 20\tnet.ParseIP(ipAddr).To4() 21\terr = syscall.Bind(fd, \u0026amp;syscall.SockaddrInet4{ 22\tPort: port, 23\tAddr: addr, 24\t}) 25\tif err != nil { 26\treturn err 27\t} 28 29\t//开启监听 30\terr = syscall.Listen(fd, 10) 31\tif err != nil { 32\treturn err 33\t} 34\te.socketFd = fd 35\treturn nil 36} 这样就完成了监听\n下面是 epoll 处理部分\n1 2//处理epoll 3func (e *EpollM) HandlerEpoll() error { 4\tevents := make([]syscall.EpollEvent, 100) 5\t//在死循环中处理epoll 6\tfor { 7\t//msec -1,会一直阻塞,直到有事件可以处理才会返回, n 事件个数 8\tn, err := syscall.EpollWait(e.epollFd, events, -1) 9 10\tif err != nil { 11\treturn err 12\t} 13\tfor i := 0; i \u0026lt; n; i++ { 14\t//先在map中是否有这个链接 15\tconn := e.GetConn(int(events[i].Fd)) 16\tif conn == nil { //没有这个链接,忽略 17\tcontinue 18\t} 19\tif events[i].Events\u0026amp;syscall.EPOLLHUP == syscall.EPOLLHUP || events[i].Events\u0026amp;syscall.EPOLLERR == syscall.EPOLLERR { 20\t//断开||出错 21\tif err := e.CloseConn(int(events[i].Fd)); err != nil { 22\treturn err 23\t} 24\t} else if events[i].Events == syscall.EPOLLIN { 25\t//可读事件 26\tconn.Read() 27\t} 28\t} 29\t} 30} 从连接中读写数据\n1//读取数据 2func (s *ServerConn) Read() { 3\tdata := make([]byte, 100) 4\t5\t//通过系统调用,读取数据,n是读到的长度 6\tn, err := syscall.Read(s.fd, data) 7\tif n == 0 { 8\treturn 9\t} 10\tif err != nil { 11\tfmt.Printf(\u0026#34;fd %d read error:%s\\n\u0026#34;, s.fd, err.Error()) 12\t} else { 13\tfmt.Printf(\u0026#34;%d say: %s \\n\u0026#34;, s.fd, data[:n]) 14\ts.Write([]byte(fmt.Sprintf(\u0026#34;hello %d\u0026#34;, s.fd))) 15\t} 16} 17 18//向这个链接中写数据 19func (s *ServerConn) Write(data []byte) { 20\t_, err := syscall.Write(s.fd, data) 21\tif err != nil { 22\tfmt.Printf(\u0026#34;fd %d write error:%s\\n\u0026#34;, s.fd, err.Error()) 23\t} 24} 最后在依次调用这些函数\n1package main 2 3func main() { 4\tepollM := NewEpollM() 5\t//开启监听 6\terr := epollM.Listen(\u0026#34;0.0.0.0\u0026#34;, 8088) 7\tif err != nil { 8\tpanic(err) 9\t} 10 11\t//创建epoll 12\terr = epollM.CreateEpoll() 13\tif err != nil { 14\tpanic(err) 15\t} 16 17\t//异步处理epoll 18\tgo func() { 19\terr := epollM.HandlerEpoll() 20\tepollM.Close() 21\tpanic(err) 22\t}() 23 24\t//等待client的连接 25\terr = epollM.Accept() 26\tepollM.Close() 27\tpanic(err) 28} 到这整个服务就运行起来了，代码已经上传到github了，传送门\n整个过程看下来，和C/C++实现过程还是非常相似的，都是通过系统调用完成的。也没有什么难点，就这样吧\n","date":"2022-02-13T15:17:44Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/c03de538924642947b1683e7e8f4ba121339581a.jpg","permalink":"https://lqxhub.github.io/posts/a59127c5/","title":"go 使用 epoll 实现高性能tcp服务器"},{"content":"pika 是啥懂得都懂，如果你不知道，这篇文章对你也没有任何帮助\n这篇文章已经同步到 pika 的 github中\npika issue\n编译 pika 0 准备 需要软件 centos7.x gcc4.8 g++4.8 git cmake 最好用centos7系列, 在别的系统中编译可能会报错, 人生苦短, 别和自己过不去\n使用make 编译的时候, 使用 make -jN (N=cpu核数 加快编译速度)\n1 安装工具 gcc g++ git 一般用 yum 安装\n安装cmake\ncmake 源码 https://cmake.org/download/\ncmake依赖 openssl-devel 先用yum安装 openssl-devel yum install openssl openssl-devel\n编译安装cmake\n解压cmake源码\n./bootstrap\nmake \u0026amp;\u0026amp; make install\n2 解决rocksdb依赖,安装必备的库 rocksdb 依赖库 snappy gflags zlib bzip2 stdc++ lz4 zstd lzma 这些库都要安装 为了能静态编译,这些库都要安装静态库\n编译snappy\nmkdir build \u0026amp;\u0026amp; cd build\n编译 动态库 cmake -DSNAPPY_BUILD_BENCHMARKS=OFF -DSNAPPY_BUILD_TESTS=OFF -DBUILD_SHARED_LIBS=ON ..\nmake \u0026amp;\u0026amp; make install\n编译 静态库 cmake -DSNAPPY_BUILD_BENCHMARKS=OFF -DSNAPPY_BUILD_TESTS=OFF -DBUILD_SHARED_LIBS=OFF ..\nmake \u0026amp;\u0026amp; make install\n我没有找到同时编译动态库和静态库的方法，只能分开编译了\n编译gflags\n./configure\nmake \u0026amp;\u0026amp; make install\n编译zlib\n./configure\nmake \u0026amp;\u0026amp; make install\nbzip2 一般linux都自带, 没有的用 yum 安装一个\nyum install bzip2-devel bzip2-libs\nstdc++ 这个库需要安装静态库,直接 yum 安装\nyum install libstdc++ libstdc++-devel libstdc++-static\n安装lz4\n解压,进入 源码目录\n1cd build/cmake 2 3mkdir build \u0026amp;\u0026amp; build 4 5cmake -DBUILD_STATIC_LIBS=ON -DLZ4_BUILD_CLI=OFF -DLZ4_BUILD_LEGACY_LZ4C=OFF CMAKE_BUILD_TYPE=Relase -D LZ4_POSITION_INDEPENDENT_LIB=OFF .. 6 7make \u0026amp;\u0026amp; make install 安装 zstd\n解压源码\ncd build/cmake/lib\nmake \u0026amp;\u0026amp; make install\n安装lzma\n解压源码 xz压缩包\n1./configure --disable-xz --disable-xzdec --disable-lzmadec --disable-lzmainfo --disable-lzma-links --disable-scripts --disable-doc 2make \u0026amp;\u0026amp; make install 最后, 所有的库都安装好后,把库加到 ld 目录中。因为有的库会安装到 /usr/local/lib64 目录下，但是有的系统没有把这个目录加到动态库搜索目录中,\n解决办法\n1echo \u0026#34;/usr/local/lib64\u0026#34; \u0026gt;\u0026gt; /etc/ld.so.conf.d/usr.local.conf 2echo \u0026#34;/usr/local/lib\u0026#34; \u0026gt;\u0026gt; /etc/ld.so.conf.d/usr.local.conf 执行 ldconfig\n安装 protobuf 编译 protobuf, 用cmake编译 protobuf release 地址 https://github.com/protocolbuffers/protobuf/releases 下载 protobuf-cpp-XX.XX.XX.tar.gz\nxx.XX.XX 是版本号，需要下载3.X版本的\n./configure\nmake \u0026amp;\u0026amp; make install\nprotobuf 也要安装静态库\n到这 protobuf 安装完成\n3 拉代码 拉 pika 代码 github https://github.com/OpenAtomFoundation/pika 这里最好通过代理去拉代码,要不然 速度感人\ngit 设置代理 1git config --global https.proxy http://127.0.0.1:1080 2 3git config --global https.proxy https://127.0.0.1:1080 4 5git config --global --unset http.proxy 6 7git config --global --unset https.proxy 拉取 依赖库代码 cd pika 源码目录\ngit submodule init git submodule update\n4 编译 预先编译 预先编译一次 glog 和 rocksdb, 因为这两个库直接用 pika 的 MakeFile 编译容易出问题,先预编译一下\n先特殊编译一下glog库 1cd /third/glog 2./configu 3make \u0026amp;\u0026amp; make install 编译rocksdb rocksdb编译完不需要安装，只需要复制一下静态库就好\n使用cmake构建\ncmake 需要 cmake3, cmake命令如下\n1cmake笔记3 -DWITH_BZ2=ON -DWITH_MD_LIBRARY=OFF -DWITH_SNAPPY=ON -DWITH_ZLIB=ON -DWITH_ZSTD=ON -DWITH_TOOLS=OFF -DWITH_TESTS=OFF -DCMAKE_BUILD_TYPE=Release .. 2 3make -jN 把编译后的 librocksdb.a 复制到 rocksdb 的根目录\n正常编译 按照官方给的文档编译即可,\n执行 make\n等待拉各个依赖模块的代码 然后自动编译\n前期工作做好,编译中应该不会出错\n检查编译是否正确\n后续 编译完成后,这个可执行文件有很多 .so的依赖, 可移植比较差, 通过 脚本编译一个依赖较少的.so文件\n执行 link_3_3_path-master.sh 脚本等待完成链接\n编译完成 正常编译\n到 output/bin/ 目录中, 执行 ldd pika 如果没有 notfind 的依赖库 说明编译完成了\n静态链接 output/bin/ 目录中的是正常编译的, link_3_3_path-master.sh 同级目录下的是静态链接的\n静态链接脚本 1#!/usr/bin/sh 2source_path=/root 3dependence_path=/root/pika_static 4g++ \\ 5 ${source_path}/pika/src/build_version.o \\ 6 ${source_path}/pika/src/pika_stable_log.o \\ 7 ${source_path}/pika/src/pika_consensus.o \\ 8 ${source_path}/pika/src/pika_slave_node.o \\ 9 ${source_path}/pika/src/pika_statistic.o \\ 10 ${source_path}/pika/src/pika_client_processor.o \\ 11 ${source_path}/pika/src/pika_admin.o \\ 12 ${source_path}/pika/src/pika_binlog.o \\ 13 ${source_path}/pika/src/pika_bit.o \\ 14 ${source_path}/pika/src/pika.o \\ 15 ${source_path}/pika/src/pika_proxy.o \\ 16 ${source_path}/pika/src/pika_proxy_cli.o \\ 17 ${source_path}/pika/src/pika_proxy_conn.o \\ 18 ${source_path}/pika/src/pika_client_conn.o \\ 19 ${source_path}/pika/src/pika_command.o \\ 20 ${source_path}/pika/src/pika_pubsub.o \\ 21 ${source_path}/pika/src/pika_conf.o \\ 22 ${source_path}/pika/src/pika_dispatch_thread.o \\ 23 ${source_path}/pika/src/pika_hash.o \\ 24 ${source_path}/pika/src/pika_hyperloglog.o \\ 25 ${source_path}/pika/src/pika_kv.o \\ 26 ${source_path}/pika/src/pika_list.o \\ 27 ${source_path}/pika/src/pika_monitor_thread.o \\ 28 ${source_path}/pika/src/pika_server.o \\ 29 ${source_path}/pika/src/pika_set.o \\ 30 ${source_path}/pika/src/pika_geo.o \\ 31 ${source_path}/pika/src/pika_geohash.o \\ 32 ${source_path}/pika/src/pika_geohash_helper.o \\ 33 ${source_path}/pika/src/pika_binlog_transverter.o \\ 34 ${source_path}/pika/src/pika_binlog_reader.o \\ 35 ${source_path}/pika/src/pika_partition.o \\ 36 ${source_path}/pika/src/pika_repl_bgworker.o \\ 37 ${source_path}/pika/src/pika_repl_client.o \\ 38 ${source_path}/pika/src/pika_repl_client_conn.o \\ 39 ${source_path}/pika/src/pika_repl_client_thread.o \\ 40 ${source_path}/pika/src/pika_repl_server.o \\ 41 ${source_path}/pika/src/pika_repl_server_conn.o \\ 42 ${source_path}/pika/src/pika_repl_server_thread.o \\ 43 ${source_path}/pika/src/pika_cmd_table_manager.o \\ 44 ${source_path}/pika/src/pika_auxiliary_thread.o \\ 45 ${source_path}/pika/src/pika_rm.o \\ 46 ${source_path}/pika/src/pika_table.o \\ 47 ${source_path}/pika/src/pika_rsync_service.o \\ 48 ${source_path}/pika/src/pika_inner_message.pb.o \\ 49 ${source_path}/pika/src/pika_slot.o \\ 50 ${source_path}/pika/src/pika_data_distribution.o \\ 51 ${source_path}/pika/src/pika_meta.o \\ 52 ${source_path}/pika/src/pika_cluster.o \\ 53 ${source_path}/pika/third/slash/slash/lib/libslash.a \\ 54 ${source_path}/pika/third/pink/pink/lib/libpink.a \\ 55 ${source_path}/pika/third/blackwidow/lib/libblackwidow.a \\ 56 ${source_path}/pika/third/rocksdb/librocksdb.a \\ 57 ${source_path}/pika/src/pika_zset.o -static-libstdc++ -Wl,-Bstatic -lprotobuf -llz4 -lzstd -llz4 -lglog -lgflags -llzma -lsnappy -Wl,-Bdynamic -lpthread -lrt -lz -lbz2 -Wl,--dynamic-linker=/lib64/ld-linux-x86-64.so.2 -o pika -Wl,-Bstatic 后面的是要 静态链接 的库\n-Wl,-Bdynamic 后面的是要 动态链 接的库\n","date":"2022-02-12T14:28:10Z","permalink":"https://lqxhub.github.io/posts/d9a4c4a4/","title":"pika编译笔记"},{"content":"最近在看研究公司业务的存储架构，现有的存储用redis 和 leveldb 通过自己写的中间件做数据落地。这样写业务和数据恢复有点麻烦，想着优化一下，就去研究redis和leveldb的源码。发现了跳表这个数据结构很有意思，性能不错，实现也相对简单，就想着自己用go实现一个跳表，在通过这个跳表实现一个类似redis 的 zset 功能。我会尽可能 详细的去介绍所有实现细节。\n看着篇文章，首先熟悉链表的相关知识，比如链表的插入和删除。最好会一点go，不会关系也不大，go的语法很简单，和C有一点像，有计算机基础的基本很快就能看懂go的语法。\n下面分这个几点来介绍\n跳表是什么 跳表的优缺点 跳表的结构 怎么实现一个跳表(增删改查) 跳表是什么 跳表是一个可以快速查找的有序链表, 搜索、插入、删除操作的时间均为O(logn), 关于跳表的详细定义 维基百科 百度百科 跳表虽然是非常有用的数据结构，但是很多书里都没有写这个，我在大学的数据结构课本里也没有写跳表，就导致很多人对跳表不熟悉。\n跳表本质上是一个链表，因为链表的随机查找性能太差，是O(N)，查找元素只能从头结点或者尾结点遍历。\n如图中要查找结点6，只能从结点1 一点点往右遍历。\n能不能在链表中使用二分查找呢，当然是可以的，就是给链表加索引，也就是跳表了\n上图就是一个简单的跳表了（图中的各种颜色和数字后面会有详细的介绍）。从图中可以看出，跳表是在双向链表的基础上，加了多层索引实现的。\n跳表的优缺点 作为快速查找的数据结构，跳表常用来和红黑树 做比较，列一下跳表和红黑树的优缺点吧\n跳表的优点： 跳表实现起来相对简单。红黑树的定义和左旋右旋操作，确实复杂，我资质愚钝，理解起来还是有单困难。后面我会解释跳表实现简单的原因的. 区间查找方便。在跳表中找到一个节点后，就可以通过前后指针找到相邻的元素。红黑树则需要通过父节点，子节点去寻找，相对麻烦。 红黑树的优点 内存占用小，只需要3个指针就可以（左子树，右子树，父节点） 而跳表有一个向后的指针，每一层都有一个向前的指针 红黑树的查找稳定，红黑树有着严格的定义，每次插入和删除数据都会通过左旋右旋来平衡树的结构，通过红黑树查找有着稳定的查找时间O(logn) ，为啥跳表是不稳定的，看到跳表是怎样确定层数的就明白了 跳表和普通链表相比，除了费内存，好像没啥缺点了 跳表的结构和实现 跳表的实现思路借鉴了redis的zset实现思想具体代码在github 跳表简单说可以有两种实现思路，一种是跳表内不能有重复的元素，另一种是跳表内允许有重复元素。redis中的跳表是允许有重复元素的，我这次实现的也是可以有重复元素的。\n跳表node 的结构 1type SkipListLevel struct { 2\t//指向下一个结点 3\tforward *SkipListNode 4 5\t/* 6\t* 到下一个node的距离; 7\t* 思考,为啥是记录到下一个node, 而不是记录上一个node到这的距离 8\t*/ 9\tspan int64 10} 11 12type SkipListNode struct { 13\t//指向上一个结点 14\tbackward *SkipListNode 15\t//索引用的层 16\tlevel []SkipListLevel 17\t//存储的值 18\tvalue ISkipListNode 19\t//排名用的分数 20\tscore float64 21} 在一个node中，黑色的1是 value， 黄色的方块是level，白色的数字是span，backward 和 forward 这两个指针在图中没有体现出来，只会有一个backward （向后的指针），level数组长度是多少，就会有多少个forward（向前的）指针。 span值是到下一个结点的跨度是多少，相邻的结点数值是1。这个值的作用是用来计算这个node在跳表中的排名。一开始我对span的值 不理解，以为是上个结点到这里的距离，直到在写插入和搜索结点的时候，才意识到这个是到下个结点的跨度。\n跳表结构 1type SkipList struct { 2\t//头结点和尾结点 3\t//重点,头结点是一个真实存在的,尾结点只是一个指针 4\thead, tail *SkipListNode 5 6\tsize int64 //node总数 7 8\tlevel int //当前跳表的最高level 9 10\tmaxLevel int //当前最大层数 11} head 和 tail 是两个指针指向跳表的头和尾，size 是整个跳表中node的的数量， level 是跳表中，当前的最大高度，这里会引申出一个知识点，跳表中的高度不是固定不变的，而是随着插入和删除动态变化的。maxLevel 是跳表可以达到的最大高度，这个值是一开始就固定的不变的。\n再把上面的图拿过来，分析一下整个跳表结点间的组织关系\n跳表中会有一个 head 结点，但是没有 tail 结点，tail只是一个指针，指向跳表的最后一个结点。这个在初始化函数里有体现\n1//初始化一个默认的跳表 2func NewDefaultSkipTable() *SkipList { 3\trand.Seed(time.Now().UnixNano()) 4\treturn \u0026amp;SkipList{ 5\thead: NewSkipListNode(SKIP_TABLE_DEFAULT_MAX_LEVEL, 0, nil), 6\tsize: 0, 7\tlevel: 1, 8\tmaxLevel: SKIP_TABLE_DEFAULT_MAX_LEVEL, 9\t} 10} 图中向前的指针 (forward)，也就是橙色的箭头，向后的指针 (backward)，也就是绿色的箭头。 forward指针在level中，也就是每一层都有一个向前的指针，backward只存在于node中，也就是每个节点只有一个向后的指针。想一下为啥只需要一个向后的指针呢？？？看完整个查找过程就明白为啥只需要一个向后指针就行了。\n插入node 基础知识准备的差不多了，开始进入跳表的插入逻辑，先通过一张图把逻辑展示一下\n插入元素的第一步就是先查找元素。因为是有序链表，元素都是按序排列的，插入元素前先找到元素应该在的位置。\n图中要把score为3的元素插入跳表中，带序号的箭头（指针）是搜索顺序，其中黑色的箭头是实际确定的路径，在搜索过程中，还要记录一下rank，也就是经过所有node的span之和。 先明确一下我们要搜索的结点是哪个。我们要找一个小于3的最大的数（先不考小数和虑链表中有多个3的情况），体现在图中，也就是我们要找到元素2的位置。\n搜索前先确定 当前跳表的最高level值。也可以无脑从最上层开始，但是没有意义。图中最高level是4，也就是level3（因为level数组从0开始）。然后从头结点（head）的level层（level3）开始。\n先设一个临时指针 t 指向head结点。 先通过图中 1 指针，指向的是元素4，要插入的节点是3，这个明显是大于3的，所以不符合。划重点了 当 现在的node当前层的下一个node不符合条件时，就需要开始搜索下一层 这算是一个转移条件吧。 这时候当前node还是在head，所以从head的level2开始向右搜索。此时node的下一个node是1，1小于3，所以符合条件，所以 t 指针要指向 1 node，再记录一下head的span值。\n如此往复，经过 3 4 5 指针的判断，最终来到了node 2 的level0，这时node2的下一个node是大于3的，而此时也是最后一层了，所以node 2 就是小于3 的最大值了，也就是要找的元素。\n找到合适的位置，接下来就是把node 3 插入进去了，并把span调整一下。\n在确定好要插入的位置后，还要确定node3元素的level高度，这个高度按照理想状态跳表中间的node是最高的，类似一个 山 字型，山字的左半边，再找到中间的node，这个node是次高的，以此类推。但实际上，跳表没有严格执行这种理想状态，node的高度是通过 随机 数确定的，你没看错，就是通过随机数确定。这也就是跳表相对红黑树实现起来简单的原因。\n这是随机函数\n1//跳表加一层索引的概率 2var SKIPLIST_P = 0.25 3 4//随机索引的层数 5func (list *SkipList) randLevel() int { 6\tlevel := 1 7\tfor (rand.Uint32()\u0026amp;0xFFFF) \u0026lt; uint32(0xFFFF*SKIPLIST_P) \u0026amp;\u0026amp; level \u0026lt; list.maxLevel { 8\tlevel++ 9\t} 10\treturn level 11} 1func (list *SkipList) randLevel() int { 2\tlevel := 1 3\tfor rand.Int31n(100) \u0026lt; 25 \u0026amp;\u0026amp; level \u0026lt; list.maxLevel { 4\tlevel++ 5\t} 6\treturn level 7} 上面这两段函数功能都是一样的，都是25%的概率让node 的 level 数+1。\n下面就是整个插入node的源码\n1//插入一个结点 2func (list *SkipList) InsertByScore(score float64, value ISkipListNode) *SkipListNode { 3\trank := make([]int64, list.maxLevel) 4\tupdate := make([]*SkipListNode, list.maxLevel) 5\tt := list.head 6 //搜索node 7\tfor i := list.level - 1; i \u0026gt;= 0; i-- { 8\tif i == list.level-1 { 9\trank[i] = 0 10\t} else { 11\trank[i] = rank[i+1] 12\t} 13\t//当前层的下一个结点存在 \u0026amp;\u0026amp; (下一个结点score\u0026lt;score || 当score相同时,比较这两个结点,下一个结点\u0026lt;新插入的结点) 14\tfor t.Next(i) != nil \u0026amp;\u0026amp; (t.Next(i).score \u0026lt; score || (t.Next(i).score == value.Score() \u0026amp;\u0026amp; t.Next(i).value.Compare(value) \u0026lt; 0)) { 15\trank[i] += t.level[i].span 16\tt = t.Next(i) 17\t} 18\tupdate[i] = t 19\t} 20 21\tlevel := list.randLevel() 22 23\tif level \u0026gt; list.level { 24\t//处理rand level后, level\u0026gt;当前level后的情况 25\tfor i := list.level; i \u0026lt; level; i++ { 26\trank[i] = 0 27\tupdate[i] = list.head 28\tupdate[i].SetSpan(i, list.size) 29\t} 30\tlist.level = level 31\t} 32\tnewNode := NewSkipListNode(level, score, value) 33 //插入新的node 34\tfor i := 0; i \u0026lt; level; i++ { 35\tnewNode.SetNext(i, update[i].Next(i)) 36\tupdate[i].SetNext(i, newNode) 37 38\tnewNode.SetSpan(i, update[i].Span(i)-(rank[0]-rank[i])) 39\tupdate[i].SetSpan(i, rank[0]-rank[i]+1) 40\t} 41 42\t//处理新增结点的span 43\tfor i := level; i \u0026lt; list.level; i++ { 44\tupdate[i].level[i].span++ 45\t} 46\t//处理新节点的后退指针 47\tif update[0] == list.head { 48\tnewNode.backward = nil 49\t} else { 50\tnewNode.backward = update[0] 51\t} 52 53\t//判断新插入的节点是不是最后一个节点 54\tif newNode.Next(0) != nil { 55\tnewNode.Next(0).backward = newNode 56\t} else { 57\t//如果是最后一个节点,就让tail指针指向这新插入的节点 58\tlist.tail = newNode 59\t} 60\tlist.size++ 61\treturn newNode 62} 在搜索过程中，需要一个 rank 数组和一个 update 数组 这两个辅助结构。 rank用来记录每层的排名值，用来后面调整新node 的rank 使用。 update用来记录从上而下经过的路径，也就是新node的每一层在跳表中的上一个node。\n1 //当前层的下一个结点存在 \u0026amp;\u0026amp; (下一个结点score\u0026lt;score || 当score相同时,比较这两个结点,下一个结点\u0026lt;新插入的结点) 2 for t.Next(i) != nil \u0026amp;\u0026amp; (t.Next(i).score \u0026lt; score || (t.Next(i).score == value.Score() \u0026amp;\u0026amp; t.Next(i).value.Compare(value) \u0026lt; 0)) { 3 rank[i] += t.level[i].span 4 t = t.Next(i) 5 } 上面是搜索过程中，判断是右移还是调到下一层的逻辑。这里不止需要判断node的socore，还要考虑两个node 的 score相同的情况，两个node 的 socre相同时，需要通过Compare 函数判断两个node的大小。\n1 level := list.randLevel() 2 if level \u0026gt; list.level { 3 //处理rand level后, level\u0026gt;当前level后的情况 4 for i := list.level; i \u0026lt; level; i++ { 5 rank[i] = 0 6 update[i] = list.head 7 update[i].SetSpan(i, list.size) 8 } 9 list.level = level 10 } 这段代码，是确定新node的高度后，处理一下新加层的。因为在搜索的时候，没有把现在高出层数的head放到update中，现在放到其中。\n1 //插入新的node 2 for i := 0; i \u0026lt; level; i++ { 3 newNode.SetNext(i, update[i].Next(i)) 4 update[i].SetNext(i, newNode) 5 6 newNode.SetSpan(i, update[i].Span(i)-(rank[0]-rank[i])) 7 update[i].SetSpan(i, rank[0]-rank[i]+1) 8 } 这段代码是通过调整node的前后指针，将新的node加入到跳表中。并且调整node的span值。这时候，span值是到下个node的距离而不是上个node到这的距离的好处就提现出来了，因为是到下个node的距离，只需要改当前node的span值就好了，如果存的是上个node到这个node的距离，就需要改下个node的span了，改动起了就会麻烦了。说的可能有点啰嗦，自己推导一遍就能体会出来了。\n1 //处理新增结点的span 2 for i := level; i \u0026lt; list.level; i++ { 3 update[i].level[i].span++ 4 } 这段可能是不太好理解的，这段代码的作用是，如果新node的level小于跳表中的最大level时（新node的level是2，此时跳表中最大的level是5的情况），这时候要把2上面的所有的node的span+1。\n剩下的，处理新node的后退指针（backward）和判断是否是最后一个node，的情况就很简单了。\n到现在，插入node就完成了，是不是也不难嘛，对不对。其实跳表中最复杂的就是插入过程了，剩下的删除，更新，查找就是差不多的逻辑，先找到关键node，再做处理。\n删除node 同样的，删除也是要先搜索，通过黑色箭头的路径，找到要删除的node前一个，然后修改目标node的上一个node的指针,跳过目标node,完成删除,最后调整目标node前面node的span值。\n先搜索node,并记录到update数组\n1//获取找到该结点的各层结点(路径) 2func (list *SkipList) GetUpdateList(node *SkipListNode) (update []*SkipListNode) { 3\tupdate = make([]*SkipListNode, list.maxLevel) 4\tt := list.head 5\tfor i := list.level - 1; i \u0026gt;= 0; i-- { 6\tfor t.Next(i) != nil \u0026amp;\u0026amp; (t.Next(i).score \u0026lt; node.score || (t.Next(i).score == node.score \u0026amp;\u0026amp; t.Next(i).value.Compare(node.value) \u0026lt; 0)) { 7\tt = t.Next(i) 8\t} 9\tupdate[i] = t 10\t} 11\treturn 12} 这段逻辑和插入时的搜索逻辑一样\n下面是删除的逻辑\n1//删除对应的结点 2func (list *SkipList) Delete(node *SkipListNode, update []*SkipListNode) { 3\tif node == nil { 4\treturn 5\t} 6\t//head 不能删 7\tif node == list.head { 8\treturn 9\t} 10 11\tfor i := 0; i \u0026lt; list.level; i++ { 12\tif update[i].Next(i) == node { 13\t//修改span 14\tupdate[i].SetSpan(i, update[i].Span(i)+node.Span(i)-1) 15\t//删除对应的结点 16\tupdate[i].SetNext(i, node.Next(i)) 17\t} else { 18\tupdate[i].level[i].span-- 19\t} 20\t} 21 22\t//处理node的后指针 23\tif node.Next(0) == nil { //node是最后一个,把tail指针指向node的上一个(update[0]) 24\tlist.tail = update[0] 25\t} else { //node不是最后一个,node的下一个指向node的上一个(update[0]) 26\tnode.Next(0).backward = update[0] 27\t} 28 29\t//处理删掉的是最高level的情况,当前的level要对应的-- 30\tfor list.level \u0026gt; 1 \u0026amp;\u0026amp; list.head.Next(list.level-1) == nil { 31\tlist.level-- 32\t} 33 34\tlist.size-- 35} 删除node的代码就简单多了，这里通过参数传入从最高到找到node的路径，也就是update数组。\n1 for i := 0; i \u0026lt; list.level; i++ { 2 if update[i].Next(i) == node { 3 //修改span 4 update[i].SetSpan(i, update[i].Span(i)+node.Span(i)-1) 5 //删除对应的结点 6 update[i].SetNext(i, node.Next(i)) 7 } else { 8 update[i].level[i].span-- 9 } 10 } 这个段逻辑就是删除node的，删除说白了就是让目标node的前面的node的后指针指向目标node后面的node。 剩下的就是处理node的后退指针和判断是否是最后一个node了。\n更新node 1//更新结点的score 2func (list *SkipList) UpdateScore(node *SkipListNode, score float64) { 3\tif score == node.score { 4\treturn 5\t} 6\t//更新后,分数还是 \u0026lt; next node的位置不用变 7\tif score \u0026gt; node.score { 8\tif node.Next(0) != nil \u0026amp;\u0026amp; score \u0026lt; node.Next(0).score { 9\tnode.score = score 10\treturn 11\t} 12\t} 13 14\t//更新后,分数还是 \u0026gt; per node的位置不用变 15\tif score \u0026lt; node.score { 16\tif node.Pre() != nil \u0026amp;\u0026amp; score \u0026gt; node.Pre().score { 17\tnode.score = score 18\treturn 19\t} 20\t} 21\t//删掉node,重新插入 22\tupdateList := list.GetUpdateList(node) 23\tlist.Delete(node, updateList) 24\t//重新插入 25\tlist.InsertByScore(score, node.value) 26} 更新node的score，更新node的前提是找到目标node，原理和前面的插入，删除时的搜索逻辑一样，就不赘述了。 说一下更新node score的逻辑把，最简单就是把node删了，然后再插入。当然这样的逻辑是可以优化的，比如有一种情况\n如图所示，要把node4的score更新成5，这时候修改node的score不影响node的位置，所以这种情况就只需要修改node的score就好了，不用考虑node在跳表中的位置。\n对于那种修改分数会改变位置的情况，就需要先删除node，再重新插入node了。\n查找node 看到这里，查找node应该是非常简单了吧，因为前面的插入，更新，删除都需要前查找node。但是查找分两种情况，一种是根据排名查找，另一种是根据score查找。\n先看根据排名查找\n1//根据排名 范围 查找 node 2func (list *SkipList) GetNodeByRank(left, right int64) (result []*SkipListNode) { 3\t//范围出错 4\tif list.Size() == 0 || left == 0 || right == 0 || right \u0026lt; left || left \u0026gt; list.Size() { 5\treturn 6\t} 7\ttRank := int64(0) 8\tt := list.head 9\tresult = make([]*SkipListNode, 0, right-left+1) 10\t//先找到排名最小的元素,然后向右一点点查找,直到找到排名最大的元素 11\tfor i := list.level - 1; i \u0026gt;= 0; i-- { 12\tfor t.Next(i) != nil \u0026amp;\u0026amp; tRank+t.level[i].span \u0026lt;= left { 13\ttRank += t.level[i].span 14\tt = t.Next(i) 15\t} 16\tif tRank == left { 17\tfor ; t != nil \u0026amp;\u0026amp; tRank \u0026lt;= right; t = t.Next(0) { 18\tresult = append(result, t) 19\ttRank++ 20\t} 21\treturn 22\t} 23\t} 24\treturn 25} 先排除不符合的情况，再根据之前的查找逻辑，一步步去查找。不同的是，现在的限制条件时排名。\n在看根据score查找\n1 2//判断 这个跳表 的最大值和最小值 是否包含 要查询的score范围 3func (list *SkipList) ScoreInRange(findRange *SkipListFindRange) bool { 4\tif !findRange.MaxInf \u0026amp;\u0026amp; list.head.Next(0).score \u0026gt; findRange.Max { 5\treturn false 6\t} 7\tif !findRange.MinInf \u0026amp;\u0026amp; list.tail.score \u0026lt; findRange.Min { 8\treturn false 9\t} 10\treturn true 11} 12 13//根据 score 范围 查找 node 14func (list *SkipList) GetNodeByScore(findRange *SkipListFindRange) (result []*SkipListNode) { 15\tif findRange == nil || list.Size() == 0 { 16\treturn 17\t} 18\t//查找范围不在这跳表中,直接return 19\tif !list.ScoreInRange(findRange) { 20\treturn 21\t} 22\tt := list.head 23\tif findRange.MinInf { 24\t//从头开始查找 25\tt = list.head.Next(0) 26\t} else { 27\t//不是从头,找到最小的那个元素 28\tfor i := list.level - 1; i \u0026gt;= 0; i-- { 29\tfor t.Next(i) != nil \u0026amp;\u0026amp; t.Next(i).score \u0026lt; findRange.Min { 30\tt = t.Next(i) 31\t} 32\t} 33\t} 34\tfor { 35\t//符合范围的条件 (从负无穷 || 当前的score \u0026gt;= 查找的最小值) \u0026amp;\u0026amp; (到正无穷 || 当前元素 \u0026lt;= 查找的最大值) 36\tif (findRange.MinInf || t.score \u0026gt;= findRange.Min) \u0026amp;\u0026amp; (findRange.MaxInf || t.score \u0026lt;= findRange.Max) { 37\tresult = append(result, t) 38\t} 39\tif t.Next(0) == nil || (!findRange.MaxInf \u0026amp;\u0026amp; t.Next(0).score \u0026gt; findRange.Max) { 40\t//下一个元素是空(到尾了) || (不是查找到正无穷 \u0026amp;\u0026amp; 下一个元素的 score \u0026gt; 要查找的最大值) 41\tbreak 42\t} else { 43\t//向右移动 44\tt = t.Next(0) 45\t} 46\t} 47\treturn 48} 根据score查找稍微复杂一点，因为根据score会有正无穷和负无穷这两种情况。这时候只给两个简单的范围值就不够用了，需要用一个结构体来描述范围了。\n1//根据scores查找元素的条件 2type SkipListFindRange struct { 3\tMin, Max float64 //最大值和最小值 4\tMinInf, MaxInf bool //是否是正无穷和负无穷 5} 在查找前先判断一下，给定的范围是否在跳表的范围内，如果不在就不用查找了。\n1 t := list.head 2 if findRange.MinInf { 3 //从头开始查找 4 t = list.head.Next(0) 5 } else { 6 //不是从头,找到最小的那个元素 7 for i := list.level - 1; i \u0026gt;= 0; i-- { 8 for t.Next(i) != nil \u0026amp;\u0026amp; t.Next(i).score \u0026lt; findRange.Min { 9 t = t.Next(i) 10 } 11 } 12 } 这段逻辑是确定查找的开始位置也就是找到目标node（根据范围找到最小的node），如果是从负无穷开始，就不用通过之前的方式去确定开始node了，直接从head开始就好了。 后面的逻辑就没什么特别的，找到目标弄的后，开始往后找，直到最后或者不符合范围了，就结束。\n好了查找也完成了。\n跳表的基本功能到现在已经完成，剩下的就是把跳表包装一层，去实现redis中zset的功能就好了。具体代码就不贴了，最后我会给出github的连接。\n总结 跳表可以看做一个支持二分查找的有序双向链表 跳表中最核心的就是搜索，不管是在插入，更新，删除还是查找中，都要先搜索 跳表在插入node时，通过随机数确定node中层数的 跳表的node中，有一个向后的指针，在每一层中有一个向前的指针 跳表相对于红黑树，优势是相对容易实现，和范围查找方便 最后在说一下常见的跳表的应用吧。redis 的zset就是基于跳表实现的，当然我也是通过读redis的源码，学习跳表的。还有一个是Google开发的 leveldb 也是基于跳表实现的。\n最后放上所有的源码，github gitee\n如果这个文章对你有帮助记得给我点个star 谢谢了\n","date":"2021-10-17T18:30:19Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/fcc8e8e79ed84bc3a42374e0cac652db.webp","permalink":"https://lqxhub.github.io/posts/4f40161/","title":"4000字详解跳表实现(挑战全网中文最详细)"},{"content":" 什么是惊群 简单说，惊群是因为多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），当事件发生时，就会唤醒所有等待的（休眠的）进程（线程）。但是事件只能被一个进程或线程处理，而其他进程（线程）获取失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群。维基百科-惊群\n产生惊群的条件 多个进程或者多个线程 同时等待处理一个事件 具体场景复现 测试环境 :\ndebian11 内核5.10.0-8 编译器 clang11 多线程和多进程在惊群问题上差不多，为了少些一点，下文中没有特殊说明，多线程 也包含了多进程\n在linux中，使用C/C++ 编写 tcp server时，会依次调用 socket() bind() listen() accept() 这几个函数，这几个函数会打开socket，绑定ip和端口，开始监听端口，accept函数会阻塞当前进程，等待客户端连接。\n如果在单线程中，只有一个accept函数在等待客户端连接，当客户端来连接的时候，只会有一个accept函数来处理，所以也不会存在惊群问题了。\n在多线模型中，多个线程分别accept同一个socket，当有客户端连接时，内核会通知所有的线程来处理这个请求，但是呢，请求只能被一个线程处理，其他的线程的不到这个事件，只能白白被唤醒。\n这是最简单的一种惊群，这种情况在linux2.6以后就不会产生了。因为在Linux 2.6 版本之后，通过引入一个标记位 WQ_FLAG_EXCLUSIVE，解决掉了 Accept 惊群效应。我原本还想在centos3.9（内核版本是2.5）中去复现这种情况，但是折腾了好久，也没能在centos上编译也运行C++程序，遂放弃。 不废话了，上代码，测试第一种情况\n1#include \u0026lt;netinet/in.h\u0026gt; 2#include \u0026lt;iostream\u0026gt; 3#include \u0026lt;sys/epoll.h\u0026gt; 4#include \u0026lt;iostream\u0026gt; 5#include \u0026lt;thread\u0026gt; 6#include \u0026lt;mutex\u0026gt; 7#include \u0026lt;condition_variable\u0026gt; 8 9#define WORKER_THREAD 4 10//创建socket，并返回fd 11int createSocket() { 12 int fd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); 13 if (fd \u0026lt; 0) { 14 std::cout \u0026lt;\u0026lt; \u0026#34;create socket error\u0026#34; \u0026lt;\u0026lt; std::endl; 15 return 0; 16 } 17 18 sockaddr_in sockAddr{}; 19 sockAddr.sin_port = htons(PORT); 20 sockAddr.sin_family = AF_INET; 21 sockAddr.sin_addr.s_addr = htons(INADDR_ANY); 22 23 if (bind(fd, (sockaddr *) \u0026amp;sockAddr, sizeof(sockAddr)) \u0026lt; 0) { 24 std::cout \u0026lt;\u0026lt; \u0026#34;bind socket error, port:\u0026#34; \u0026lt;\u0026lt; PORT \u0026lt;\u0026lt; std::endl; 25 return 0; 26 } 27 28 if (listen(fd, 100) \u0026lt; 0) { 29 std::cout \u0026lt;\u0026lt; \u0026#34;listen port error\u0026#34; \u0026lt;\u0026lt; std::endl; 30 return 0; 31 } 32 return fd; 33} 34 35void Worker1(int socketFd, int k) { 36 std::cout \u0026lt;\u0026lt; \u0026#34; Worker\u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#34; run \u0026#34; \u0026lt;\u0026lt; std::endl; 37 while (true) { 38 int tfd = 0; 39 sockaddr_in cli_addr{}; 40 socklen_t length = sizeof(cli_addr); 41 tfd = accept(socketFd, (sockaddr *) \u0026amp;cli_addr, \u0026amp;length); 42 std::cout \u0026lt;\u0026lt; \u0026#34;worker\u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#34; in \u0026#34; \u0026lt;\u0026lt; std::endl; 43 if (tfd \u0026lt;= 0) { 44 std::cout \u0026lt;\u0026lt; \u0026#34;accept error\u0026#34; \u0026lt;\u0026lt; std::endl; 45 return; 46 } else { 47 std::cout \u0026lt;\u0026lt; \u0026#34;worker\u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#34; accept \u0026#34; \u0026lt;\u0026lt; std::endl; 48 } 49 } 50} 51 52int main() { 53 std::mutex mutex; 54 std::unique_lock\u0026lt;std::mutex\u0026gt; lck(mutex); 55 std::condition_variable cv; 56 57 int fd = createSocket(); 58 //第一种,多个线程不使用多路复用,accept同一个socket 59 for (int i = 0; i \u0026lt; WORKER_THREAD; ++i) { 60 std::thread th(\u0026amp;Worker1, fd, i + 1); 61 th.detach(); 62 } 63 64 cv.wait(lck); 65 return 0; 66} 这代码可以用C写，但是习惯用C++了，就用C++写吧。代码也比较简单，createSocket()创建了一个socket，然后4个线程分别去accept这个socket。 下面是运行结果： 可以看到，4个线程都在运行，并且accept，但是当连接来的时候，只有个线程能得到事件。\n既然linux内核已经帮我们处理了惊群，那我们还考虑这些干啥，直接用不就完了。\n但是，我们在写代码的时候一般不会直接阻塞accept的，都是使用多路复用来帮我们处理连接阻塞的是多路复用函数。目前综合性能比较好的IO多路复用是epoll。当在多线程中使用epoll时，惊群问题就会出现了。 先代码和结果，然后再解释\n1#include \u0026lt;netinet/in.h\u0026gt; 2#include \u0026lt;iostream\u0026gt; 3#include \u0026lt;sys/epoll.h\u0026gt; 4#include \u0026lt;iostream\u0026gt; 5#include \u0026lt;thread\u0026gt; 6#include \u0026lt;mutex\u0026gt; 7#include \u0026lt;condition_variable\u0026gt; 8 9#define WORKER_THREAD 4 10//创建socket，并返回fd 11int createSocket() { 12 int fd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); 13 if (fd \u0026lt; 0) { 14 std::cout \u0026lt;\u0026lt; \u0026#34;create socket error\u0026#34; \u0026lt;\u0026lt; std::endl; 15 return 0; 16 } 17 18 sockaddr_in sockAddr{}; 19 sockAddr.sin_port = htons(PORT); 20 sockAddr.sin_family = AF_INET; 21 sockAddr.sin_addr.s_addr = htons(INADDR_ANY); 22 23 if (bind(fd, (sockaddr *) \u0026amp;sockAddr, sizeof(sockAddr)) \u0026lt; 0) { 24 std::cout \u0026lt;\u0026lt; \u0026#34;bind socket error, port:\u0026#34; \u0026lt;\u0026lt; PORT \u0026lt;\u0026lt; std::endl; 25 return 0; 26 } 27 28 if (listen(fd, 100) \u0026lt; 0) { 29 std::cout \u0026lt;\u0026lt; \u0026#34;listen port error\u0026#34; \u0026lt;\u0026lt; std::endl; 30 return 0; 31 } 32 return fd; 33} 34 35void Worker2(int socketFd, int k) { 36 std::cout \u0026lt;\u0026lt; \u0026#34; Worker\u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#34; run \u0026#34; \u0026lt;\u0026lt; std::endl; 37 38 int eFd = epoll_create(1); 39 if (eFd \u0026lt; 0) { 40 std::cout \u0026lt;\u0026lt; \u0026#34;create epoll fail\u0026#34;; 41 return; 42 } 43 epoll_event epev_{}; 44 epev_.events = EPOLLIN; 45 epev_.data.fd = socketFd; 46 epoll_ctl(eFd, EPOLL_CTL_ADD, socketFd, \u0026amp;epev_); 47 epoll_event events[EVENT_NUM]; 48 49 while (true) { 50 int eNum = epoll_wait(eFd, events, EVENT_NUM, -1); 51 if (eNum == -1) { 52 std::cout \u0026lt;\u0026lt; \u0026#34;epoll error\u0026#34;; 53 return; 54 } 55 //一定要加上这句,防止事件被瞬间处理,导致看不到结果 56 std::this_thread::sleep_for((std::chrono::seconds (1))); 57 std::cout \u0026lt;\u0026lt; \u0026#34;worker\u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#34; in \u0026#34; \u0026lt;\u0026lt; std::endl; 58 for (int i = 0; i \u0026lt; eNum; ++i) { 59 if (events[i].data.fd == socketFd) { 60 int tfd = 0; 61 sockaddr_in cli_addr{}; 62 socklen_t length = sizeof(cli_addr); 63 tfd = accept(socketFd, (sockaddr *) \u0026amp;cli_addr, \u0026amp;length); 64 if (tfd \u0026lt;= 0) { 65 std::cout \u0026lt;\u0026lt; \u0026#34;accept error\u0026#34; \u0026lt;\u0026lt; std::endl; 66 } else { 67 std::cout \u0026lt;\u0026lt; \u0026#34;worker\u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#34; accept \u0026#34; \u0026lt;\u0026lt; std::endl; 68 } 69 } else { 70 //处理正常的socket读写事件,这里可以忽略,不是这次关注的点 71 } 72 } 73 } 74} 75 76int main() { 77 std::mutex mutex; 78 std::unique_lock\u0026lt;std::mutex\u0026gt; lck(mutex); 79 std::condition_variable cv; 80 int fd = createSocket(); 81 //第二种,多个线程使用epoll多路复用,accept同一个socket 82 for (int i = 0; i \u0026lt; WORKER_THREAD; ++i) { 83 std::thread th(\u0026amp;Worker2, fd, i + 1); 84 th.detach(); 85 } 86} 结果 这里可以看到，当有客户端来连接的时候，4个线程都被唤醒了，但是只有workr2 线程成功获取了事件，其余的3个线程都白白唤醒浪费了性能\n为啥内核已经处理了第一种情景下的惊群问题，第二种情景下的惊群问题为啥就不处理了呢？\n我的猜想不一定正确，如果有错误，请指出：\naccept 只能是被一个进程调用成功（连接事件只会处理一次嘛），所以内核就直接处理了（一个accept只会唤醒一个进程）。但 epoll 不一样，epoll中管理了很多连接，不止socket这一个，除了可能后续被 accept 调用外，还有可能是其他网络 IO 事件的，而其他 IO 事件是否只能由一个进程处理，是不一定的，这是一个由用户决定的事情，例如可能一个文件会由多个进程来读写。所以，对 epoll 默认对于多进程监听同一文件不会设置互斥，所以就导致了epoll惊群问题。\n在linux4.5内核之后给epoll添加了一个 EPOLLEXCLUSIVE的标志位，如果设置了这个标志位，那epoll将进程挂到等待队列时将会设置一下互斥标志位，这时实现跟内核原生accept一样的特性，只会唤醒队列中的一个进程。参考资料 感谢这位大神的文章\n修改一下worker2函数:\n1void Worker2(int socketFd, int k) { 2 std::cout \u0026lt;\u0026lt; \u0026#34; Worker\u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#34; run \u0026#34; \u0026lt;\u0026lt; std::endl; 3 4 int eFd = epoll_create(1); 5 if (eFd \u0026lt; 0) { 6 std::cout \u0026lt;\u0026lt; \u0026#34;create epoll fail\u0026#34;; 7 return; 8 } 9 epoll_event epev_{}; 10 //给epoll加上 互斥标志 11 epev_.events = EPOLLIN | EPOLLEXCLUSIVE; 12 epev_.data.fd = socketFd; 13 epoll_ctl(eFd, EPOLL_CTL_ADD, socketFd, \u0026amp;epev_); 14 epoll_event events[EVENT_NUM]; 15 16 while (true) { 17 int eNum = epoll_wait(eFd, events, EVENT_NUM, -1); 18 if (eNum == -1) { 19 std::cout \u0026lt;\u0026lt; \u0026#34;epoll error\u0026#34;; 20 return; 21 } 22 //一定要加上这句,防止事件被瞬间处理,导致看不到结果 23 std::this_thread::sleep_for((std::chrono::seconds(1))); 24 std::cout \u0026lt;\u0026lt; \u0026#34;worker\u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#34; in \u0026#34; \u0026lt;\u0026lt; std::endl; 25 for (int i = 0; i \u0026lt; eNum; ++i) { 26 if (events[i].data.fd == socketFd) { 27 int tfd = 0; 28 sockaddr_in cli_addr{}; 29 socklen_t length = sizeof(cli_addr); 30 tfd = accept(socketFd, (sockaddr *) \u0026amp;cli_addr, \u0026amp;length); 31 if (tfd \u0026lt;= 0) { 32 std::cout \u0026lt;\u0026lt; \u0026#34;accept error\u0026#34; \u0026lt;\u0026lt; std::endl; 33 } else { 34 std::cout \u0026lt;\u0026lt; \u0026#34;worker\u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#34; accept \u0026#34; \u0026lt;\u0026lt; std::endl; 35 } 36 } else { 37 //处理正常的socket读写事件,这里可以忽略,不是这次关注的点 38 } 39 } 40 } 41} 现在来测试一下 现在的epoll已经不会有惊群问题了\n另一种方式 其实解决多线程使用epoll等多路复用导致的惊群问题，还有一个更彻底解决方法，让每个线程分别打开一个socket，并且这些socket绑定在同一个端口，然后accept这个socket。这就像第一种情景那样，内核直接帮我们做了惊群处理。这里会使用到 linux 3.9后 socket提供SO_REUSEPORT标志。使用这个标志后，会允许多个socket绑定和监听同一个端口。 代码如下\n1#include \u0026lt;netinet/in.h\u0026gt; 2#include \u0026lt;iostream\u0026gt; 3#include \u0026lt;sys/epoll.h\u0026gt; 4#include \u0026lt;iostream\u0026gt; 5#include \u0026lt;thread\u0026gt; 6#include \u0026lt;mutex\u0026gt; 7#include \u0026lt;condition_variable\u0026gt; 8 9#define WORKER_THREAD 4 10//创建socket，并返回fd 11int createSocket2() { 12 int fd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); 13 if (fd == -1) { 14 std::cout \u0026lt;\u0026lt; \u0026#34;create socket error\u0026#34; \u0026lt;\u0026lt; std::endl; 15 return 0; 16 } 17 18 int on = 1; 19 if (setsockopt(fd, SOL_SOCKET, SO_REUSEPORT, (const void *) \u0026amp;on, sizeof(on)) \u0026lt; 0) { 20 std::cout \u0026lt;\u0026lt; \u0026#34;set opt error, ret:\u0026#34; \u0026lt;\u0026lt; std::endl; 21 } 22 23 sockaddr_in sockAddr{}; 24 sockAddr.sin_port = htons(PORT); 25 sockAddr.sin_family = AF_INET; 26 sockAddr.sin_addr.s_addr = htons(INADDR_ANY); 27 28 if (bind(fd, (sockaddr *) \u0026amp;sockAddr, sizeof(sockAddr)) \u0026lt; 0) { 29 std::cout \u0026lt;\u0026lt; \u0026#34;bind socket error, port:\u0026#34; \u0026lt;\u0026lt; PORT \u0026lt;\u0026lt; std::endl; 30 return 0; 31 } 32 33 if (listen(fd, 100) \u0026lt; 0) { 34 std::cout \u0026lt;\u0026lt; \u0026#34;listen port error\u0026#34; \u0026lt;\u0026lt; std::endl; 35 return 0; 36 } 37 return fd; 38} 39 40void Worker3(int k) { 41 std::cout \u0026lt;\u0026lt; \u0026#34; Worker\u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#34; run \u0026#34; \u0026lt;\u0026lt; std::endl; 42 43 int socketFd = createSocket2(); 44 int eFd = epoll_create(1); 45 if (eFd == -1) { 46 std::cout \u0026lt;\u0026lt; \u0026#34;create epoll fail\u0026#34; \u0026lt;\u0026lt; std::endl; 47 return; 48 } 49 50 epoll_event epev_{}; 51 epev_.events = EPOLLIN; 52 epev_.data.fd = socketFd; 53 epoll_ctl(eFd, EPOLL_CTL_ADD, socketFd, \u0026amp;epev_); 54 epoll_event events[EVENT_NUM]; 55 56 while (true) { 57 int eNum = epoll_wait(eFd, events, EVENT_NUM, -1); 58 if (eNum == -1) { 59 std::cout \u0026lt;\u0026lt; \u0026#34;epoll error\u0026#34; \u0026lt;\u0026lt; std::endl; 60 return; 61 } 62 std::this_thread::sleep_for((std::chrono::seconds(1))); 63 std::cout \u0026lt;\u0026lt; \u0026#34;worker\u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#34; in \u0026#34; \u0026lt;\u0026lt; std::endl; 64 for (int i = 0; i \u0026lt; eNum; ++i) { 65 if (events[i].data.fd == socketFd) { 66 int tfd = 0; 67 sockaddr_in cli_addr{}; 68 socklen_t length = sizeof(cli_addr); 69 tfd = accept(socketFd, (sockaddr *) \u0026amp;cli_addr, \u0026amp;length); 70 if (tfd \u0026lt;= 0) { 71 std::cout \u0026lt;\u0026lt; \u0026#34;accept error\u0026#34; \u0026lt;\u0026lt; std::endl; 72 } else { 73 std::cout \u0026lt;\u0026lt; \u0026#34;worker\u0026#34; \u0026lt;\u0026lt; k \u0026lt;\u0026lt; \u0026#34; accept \u0026#34; \u0026lt;\u0026lt; std::endl; 74 } 75 } else { 76 //处理正常的socket读写事件 77 } 78 } 79 } 80} 81 82int main() { 83 std::mutex mutex; 84 std::unique_lock\u0026lt;std::mutex\u0026gt; lck(mutex); 85 std::condition_variable cv; 86 87 //第三种,多个线程使用epoll多路复用,每个线程分别bind,listen 同一个端口, accept各自的socket 88 for (int i = 0; i \u0026lt; WORKER_THREAD; ++i) { 89 std::thread th(\u0026amp;Worker3, i + 1); 90 th.detach(); 91 } 92 93 cv.wait(lck); 94 return 0; 95} 结果 也是没有问题的，多个连接来的时候，只会有一个线程被唤醒，相当于在内核级别中实现了一个负载均衡\n总结 简单总结一下，当多个线程或者进程同时阻塞同一个事件的时候，会出现惊群现象，如果不适用epoll等多路复用技术，在linux2.6 以后内核已经帮我们处理了惊群问题。\n如果使用了epoll，就需要额外处理epoll导致的惊群问题，有两种方式\nlinux4.5内核之后，epoll有一个EPOLLEXCLUSIVE特性，可以防止epoll惊群出现 linux 3.9内核之后给 socket 提供SO_REUSEPORT特性，可以允许多个socket绑定在同一个端口上，相当于每个线程都有一个socket，在处理accept时，内核会自动处理惊群问题 1和2两种方式都能有效解决惊群问题，但是目前使用 socket的 SO_REUSEPORT 是最好的方式.。\n我通过查资料得到 EPOLLEXCLUSIVE 标识会保证一个事件发生时候只有一个线程会被唤醒，来避免多惊群问题。不过任一时候只能有一个Worker调用 accept，限制了真正并行的吞吐量。 这个有待验证，等我有时间再去深入了解一下。\n测试demo\n","date":"2021-08-22T00:10:33Z","permalink":"https://lqxhub.github.io/posts/4926d2f3/","title":"linux 多线程或多进程 epoll处理 accept 导致惊群"},{"content":"linux系统中，实现socket多路复用的技术有select 、poll 、epoll 等多种方式。这些不同方式个有优缺点和适用场景，这不是本文讨论的重点，又兴趣的可以自己搜索学习一下。但是在高并发场景下， epoll 性能是最高的， Nginx 都听说过吧，大名鼎鼎的Nginx 底层用的就是 epoll。\n这篇文章主要是写怎么用 epoll，而不是原理分析。这篇文章不是最全的，也不是最深入的，但是绝对是一篇能让普通人看懂的，看完能自己用epoll写出一个tcpserver的文章。全废话不多说，直接开始搞\n首先明确一点，epoll 是linux系统提供的系统调用，也就说，epoll 在Windows系统上是没法使用的，相应的代码也是没法编译的。如果有人知道怎么在Windows中编译，请赐教。\n工具 文中使用的开发环境\n系统: Debian GNU/Linux 10 (buster) linux内核: 4.19.0-14 gcc版本: 8.3.0 准备知识 epoll是linux内核提供的功能，这个功能对外提供系统调用，在C/C++中通过三个函数对用户提供功能\nepoll_create(int __size) 创建一个epoll，_size 参数在linux2.6内核之后就没有什么作用了, 但是要\u0026gt;0，一般直接填 1 就好了。函数返回创建的epoll的文件描述符，如果创建失败，会返回 -1。\nepoll_ctl(nt __epfd, int __op, int __fd,struct epoll_event *__event) 操作已有的epoll,epfdepoll的文件描述符；op操作方式，有添加、删除、修改等等；_fd 要操作对象的描述符，如果是操作tcp连接，也会就是这个连接的描述符。_event epoll 的响应事件，当epoll管理的tcp连接有事件发生时，会通过 _event 这个对象传递出来，所以在添加连接时，要把这个连接包装成一个 epoll_event 对象 op 类型 EPOLL_CTL_ADD 添加一个描述符 EPOLL_CTL_DEL 删除一个描述符 EPOLL_CTL_MOD 修改一个描述符 epoll_wait(int __epfd, struct epoll_event *__events,int __maxevents, int __timeout) 当epoll管理的连接中有响应事件发生时,会回调这个函数。epfdepoll的文件描述符；__events 可以操作的连接数组；__maxevents 一个可以处理的最大事件数量；__timeout 超时时间（单位毫秒），如果填-1，会直到有可操作事件发生时才会返回，因为C++不支持函数多返回值，像Go可以直接返回所有事件和数量了 (╥╯^╰╥)。\nevents 中的常用的类型：\nEPOLLIN ：表示对应的文件描述符可以读（SOCKET正常关闭） EPOLLOUT：表示对应的文件描述符可以写 EPOLLPRI：表示对应的文件描述符有紧急的数据可读（表示有带外数据到来） EPOLLERR：表示对应的文件描述符发生错误(默认注册) EPOLLHUP：表示对应的文件描述符被挂断(默认注册) EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的 EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 是不是很惊奇，这么牛逼的epoll就三个函数，第一次看到的时候我也觉得很奇怪，三个函数就能搞定那么复杂的事情。不过想想也是，把复杂的东西简化，才能体现出大神的实力 epoll的两种模式 epoll 事件有两种模型 Level Triggered (LT) 和 Edge Triggered (ET)：\nLT(level triggered，水平触发模式)是默认的工作方式，并且同时支持 block 和 non-block socket。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。\nET(edge-triggered，边缘触发模式)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，等到下次有新的数据进来的时候才会再次出发就绪事件。\n把socket设置为非阻塞模式的方法\n1int flags = fcntl(fd, F_GETFL, 0); 2fcntl(fd, F_SETFL, flags | O_NONBLOCK); 需要的头文件 #include \u0026lt;fcntl.h\u0026gt;\nepoll原理 简单通过画图解释一下epoll的工作原理 这里没有涉及太底层的东西，因为太底层的我也没研究过，不敢乱讲。知之为知之，不知为不知。 epoll可以看做是一个由操作系统提供的容器，这个容器管理了一些 epoll_event （图中我画成单向链表了，实际上用的是红黑树，因为画树太麻烦了），这个event是我们添加进去的，event中设置了要响应的事件类型，当epoll 检测到具体的 event 有对应的事件发生时，会通过epoll_wait() 通知。\n简单的epoll实现 1#include \u0026lt;iostream\u0026gt;//控制台输出 2#include \u0026lt;sys/socket.h\u0026gt;//创建socket 3#include \u0026lt;netinet/in.h\u0026gt;//socket addr 4#include \u0026lt;sys/epoll.h\u0026gt;//epoll 5#include \u0026lt;unistd.h\u0026gt;//close函数 6#include \u0026lt;fcntl.h\u0026gt;//设置非阻塞 7 8using namespace std; 9 10int main() { 11 const int EVENTS_SIZE = 20; 12 //读socket的数组 13 char buff[1024]; 14 15 //创建一个tcp socket 16 int socketFd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); 17 18 //设置socket监听的地址和端口 19 sockaddr_in sockAddr{}; 20 sockAddr.sin_port = htons(8088); 21 sockAddr.sin_family = AF_INET; 22 sockAddr.sin_addr.s_addr = htons(INADDR_ANY); 23 24 //将socket和地址绑定 25 if (bind(socketFd, (sockaddr *) \u0026amp;sockAddr, sizeof(sockAddr)) == -1) { 26 cout \u0026lt;\u0026lt; \u0026#34;bind error\u0026#34; \u0026lt;\u0026lt; endl; 27 return -1; 28 } 29 30 //开始监听socket,当调用listen之后, 31 //进程就可以调用accept来接受一个外来的请求 32 //第二个参数,请求队列的长度 33 if (listen(socketFd, 10) == -1) { 34 cout \u0026lt;\u0026lt; \u0026#34;listen error\u0026#34; \u0026lt;\u0026lt; endl; 35 return -1; 36 } 37 38 //创建一个epoll,size已经不起作用了,一般填1就好了 39 int eFd = epoll_create(1); 40 41 //把socket包装成一个epoll_event对象 42 //并添加到epoll中 43 epoll_event epev{}; 44 epev.events = EPOLLIN;//可以响应的事件,这里只响应可读就可以了 45 epev.data.fd = socketFd;//socket的文件描述符 46 epoll_ctl(eFd, EPOLL_CTL_ADD, socketFd, \u0026amp;epev);//添加到epoll中 47 48 //回调事件的数组,当epoll中有响应事件时,通过这个数组返回 49 epoll_event events[EVENTS_SIZE]; 50 51 //整个epoll_wait 处理都要在一个死循环中处理 52 while (true) { 53 //这个函数会阻塞,直到超时或者有响应事件发生 54 int eNum = epoll_wait(eFd, events, EVENTS_SIZE, -1); 55 56 if (eNum == -1) { 57 cout \u0026lt;\u0026lt; \u0026#34;epoll_wait\u0026#34; \u0026lt;\u0026lt; endl; 58 return -1; 59 } 60 //遍历所有的事件 61 for (int i = 0; i \u0026lt; eNum; i++) { 62 //判断这次是不是socket可读(是不是有新的连接) 63 if (events[i].data.fd == socketFd) { 64 if (events[i].events \u0026amp; EPOLLIN) { 65 sockaddr_in cli_addr{}; 66 socklen_t length = sizeof(cli_addr); 67 //接受来自socket连接 68 int fd = accept(socketFd, (sockaddr *) \u0026amp;cli_addr, \u0026amp;length); 69 if (fd \u0026gt; 0) { 70 //设置响应事件,设置可读和边缘(ET)模式 71 //很多人会把可写事件(EPOLLOUT)也注册了,后面会解释 72 epev.events = EPOLLIN | EPOLLET; 73 epev.data.fd = fd; 74 //设置连接为非阻塞模式 75 int flags = fcntl(fd, F_GETFL, 0); 76 if (flags \u0026lt; 0) { 77 cout \u0026lt;\u0026lt; \u0026#34;set no block error, fd:\u0026#34; \u0026lt;\u0026lt; fd \u0026lt;\u0026lt; endl; 78 continue; 79 } 80 if (fcntl(fd, F_SETFL, flags | O_NONBLOCK) \u0026lt; 0) { 81 cout \u0026lt;\u0026lt; \u0026#34;set no block error, fd:\u0026#34; \u0026lt;\u0026lt; fd \u0026lt;\u0026lt; endl; 82 continue; 83 } 84 //将新的连接添加到epoll中 85 epoll_ctl(eFd, EPOLL_CTL_ADD, fd, \u0026amp;epev); 86 cout \u0026lt;\u0026lt; \u0026#34;client on line fd:\u0026#34; \u0026lt;\u0026lt; fd \u0026lt;\u0026lt; endl; 87 } 88 } 89 } else {//不是socket的响应事件 90 91 //判断是不是断开和连接出错 92 //因为连接断开和出错时,也会响应`EPOLLIN`事件 93 if (events[i].events \u0026amp; EPOLLERR || events[i].events \u0026amp; EPOLLHUP) { 94 //出错时,从epoll中删除对应的连接 95 //第一个是要操作的epoll的描述符 96 //因为是删除,所有event参数天null就可以了 97 epoll_ctl(eFd, EPOLL_CTL_DEL, events[i].data.fd, nullptr); 98 cout \u0026lt;\u0026lt; \u0026#34;client out fd:\u0026#34; \u0026lt;\u0026lt; events[i].data.fd \u0026lt;\u0026lt; endl; 99 close(events[i].data.fd); 100 } else if (events[i].events \u0026amp; EPOLLIN) {//如果是可读事件 101 102 //如果在windows中,读socket中的数据要用recv()函数 103 int len = read(events[i].data.fd, buff, sizeof(buff)); 104 //如果读取数据出错,关闭并从epoll中删除连接 105 if (len == -1) { 106 epoll_ctl(eFd, EPOLL_CTL_DEL, events[i].data.fd, nullptr); 107 cout \u0026lt;\u0026lt; \u0026#34;client out fd:\u0026#34; \u0026lt;\u0026lt; events[i].data.fd \u0026lt;\u0026lt; endl; 108 close(events[i].data.fd); 109 } else { 110 //正常读取,打印读到的数据 111 cout \u0026lt;\u0026lt; buff \u0026lt;\u0026lt; endl; 112 113 //向客户端发数据 114 char a[] = \u0026#34;123456\u0026#34;; 115 //如果在windows中,向socket中写数据要用send()函数 116 write(events[i].data.fd, a, sizeof(a)); 117 } 118 } 119 } 120 } 121 } 122} 常见的问题和注意事项在注释中，就单解释一下新连接注册事件的问题吧，很多文章中都会把可写事件也注册进去，像这样\n1sockaddr_in cli_addr{}; 2socklen_t length = sizeof(cli_addr); 3//接受来自socket连接 4int fd = accept(socketFd, (sockaddr *) \u0026amp;cli_addr, \u0026amp;length); 5if (fd \u0026gt; 0) { 6\tepev.events = EPOLLIN | EPOLLET | EPOLLOUT; 7\tepev.data.fd = fd; 8\tepoll_ctl(eFd, EPOLL_CTL_ADD, fd, \u0026amp;epev); 9\tcout \u0026lt;\u0026lt; \u0026#34;client on line fd:\u0026#34; \u0026lt;\u0026lt; fd \u0026lt;\u0026lt; endl; 10} 但是经过测试，不注册可写事件，直接往socket中写也是可以的\n经过查资料得知:\nEPOLLIN : 如果状态改变了(比如 从无到有)，只要输入缓冲区可读就会触发 EPOLLOUT : 如果状态改变了(比如 从满到不满)，只要输出缓冲区可写就会触 如果把可写也注册上，会频繁回调，这里会有很多无用的回调，导致性能下降。 有一种思路，当向socket写失败后（write函数返回值 == -1），注册上 EPOLLOUT 当响应了可写事件后，重新往socket中写数据，写成功后，再取消掉 EPOLLOUT。 这里就不给出示例了 客户端测试 这次关注的是服务端实现，客户端就不用C++写了，用Go写了一个client（没别的原因，只是因为Go写起了简单）\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;net\u0026#34; 6\t\u0026#34;sync\u0026#34; 7\t\u0026#34;time\u0026#34; 8) 9 10const ( 11\tMAX_CONN = 10 12) 13 14func main() { 15\tvar wg sync.WaitGroup 16\twg.Add(1) 17\tfor i := 0; i \u0026lt; MAX_CONN; i++ { 18\tgo Conn(\u0026#34;192.168.199.164:8088\u0026#34;, i) 19\ttime.Sleep(time.Millisecond * 100) 20\t} 21\twg.Wait() 22} 23 24func Conn(addr string, id int) { 25\tconn, err := net.Dial(\u0026#34;tcp\u0026#34;, addr) 26\tif err != nil { 27\tfmt.Println(err) 28\treturn 29\t} 30\tfmt.Println(\u0026#34;connect \u0026#34;, id) 31\tgo func() { 32\tbuf := make([]byte, 1024) 33\tfor { 34\tn, err := conn.Read(buf) 35\tif err != nil { 36\tbreak 37\t} 38\tfmt.Println(id, \u0026#34;read: \u0026#34;, string(buf[:n])) 39\t} 40\t}() 41\ttime.Sleep(time.Second * 1) 42\tfor { 43\t_, err := conn.Write([]byte(\u0026#34;hello\u0026#34;)) 44\tif err != nil { 45\tbreak 46\t} 47\ttime.Sleep(time.Second * 10) 48\t} 49} 这只是一个测试用的，写的很粗糙，但是不影响使用\n服务端打印信息 客户端打印信息 总结 epoll是socket多路复用技术的一种，还有select和poll epoll 只能在linux使用(Windows下怎么用我没找到,如果说错了请指正) epoll 事件有 Level Triggered (LT) 和 Edge Triggered (ET) 两种模型，LT是默认模式，ET是高性能模式 另外，我使用面向对象的方式封装了一个epoll的tcpserver 代码有点多，就不贴在这了，已经上传 github 码云\n欢迎给点个star ヾ(o◕∀◕)ﾉヾ\n","date":"2021-03-14T13:58:35Z","permalink":"https://lqxhub.github.io/posts/91655bdf/","title":"linux下 C++ 使用 epoll 多路复用 实现高性能的tcpserver"},{"content":"go 是自带gc的语言，会自动管理内存，不用像C/C++那样，需要程序员手动释放内存，不用手动管理内存，就能少掉很多头发\ngo的GC会自动管理内存，但是这不代表go程序就不会内存泄露了。 go常见产生内存泄露的原因就是goroutine没有结束，简单说就是goroutine 被阻塞了，这样就会导致goroutine引用的内存不被GC回收，也就导致了内存泄露。 当然产生内存泄露的原因还有别的，只是暂时我还没有遇到。不管什么原因产生的内存泄露，最终都是因为异常的引用，导致该被回收的内存没有被gc 回收掉\n起因 说起go内存泄露分析，还要从年前的一次程序压测说起。我用一个测试程序压测我们游戏的一些数据，大约开了3000个tcp连接到游戏。游戏数据没有问题，但是当测试结束后，发现游戏的Gateway内存占用一直没有下降。本能的让我想起了是不是内存泄露了。马上用pprof分析了一下内存，发现果然是内存泄露了。\n因为时公司代码，不方便拿出了分析，大体说一下原因吧\nGateway是一个读写分离的tcp服务，也就是每一个连接都要有两个goroutine，一个读，一个写。\n但是当tcp连接断开时，因为时序问题，导致goroutine阻塞了，一直没有结束，就是导致了相关联的内存没有释放。\n因为时公司代码，不能随便贴出来，这次就自己写个简单的demo模拟一下吧\n因为go 自带的pprof 只能展示文字，不太明显，所有先安装一个可视化插件 graphviz 传送门 linux上可以直接通过 apt 或者 yum 安装就行了。 windows上去网站下一个就好了，我下载 .msi 格式的安装后不能用，重新下了一个 压缩包，解压后把 bin 目录配置到环境变量的 path 中就可以使用了\n开始 写一个简单的demo 模拟一下内存泄露\n1package main 2 3import ( 4\t\u0026#34;math/rand\u0026#34; 5\t\u0026#34;net/http\u0026#34; 6\t_ \u0026#34;net/http/pprof\u0026#34; 7\t\u0026#34;sync\u0026#34; 8) 9 10func main() { 11\tgo func() { 12\thttp.ListenAndServe(\u0026#34;0.0.0.0:8090\u0026#34;, nil) 13\t}() 14 15\tc := make(chan struct{}) 16\tvar wg sync.WaitGroup 17\twg.Add(1) 18\tfor i := 0; i \u0026lt; 10000; i++ { 19\tgo one(c) 20\t} 21\twg.Wait() 22} 23 24func one(c chan struct{}) { 25\tvar a []int64 26\tfor i := 0; i \u0026lt; 10000; i++ { 27\ta = append(a, rand.Int63()) 28\t} 29\t30\t\u0026lt;-c 31} 程序很简单，在 for 循环中开启 1000 个协程，每个协程中往切片中append 1000个数据。 用一个channel模拟协程阻塞，这样就会导致goroutine不会结束。\n使用go再带的pprof查看 代码中监听了 8090 端口，在浏览器中输入 http://127.0.0.1:8090/debug/pprof/ 下面都有解释，就不用详细介绍了，挑一两个说一下\nallocs : 程序运行期间，所有内存分配的样本 heap : 当前活动对象的内存分配采样 guroutine : 当前所有协程的堆栈跟踪 可以看到，当前的程序总共有10005个协程，21次堆内存分配，说明我们的协程是被阻塞的。\n使用graphviz查看 在命令行中，在Windows中可以使用 powerShell 输入 go tool pprof -http :8081 http://127.0.0.1:8090/debug/pprof/heap\n如果要分析CPU占用，使用\ngo tool pprof -http :8081 http://127.0.0.1:8090/debug/pprof/profile?seconds=120\n会在浏览器中打开 这就是当前 heap 采样图 可以在 VIEW 中切换不同的显示方式\n图中方块越大便是占用的内存越多，方块中连线越粗表示耗时越多\n内存泄露误区 我在排查内存泄露时，当我把goroutine阻塞解决后，通过linux 的 top 命令查看Gateway内存占用时，发现内存没有降下来，一时让我陷入困惑，为啥goroutine 都结束了，为啥内存还不释放呢？直到我在网上找到了这篇文章 传送门\n这位大神写的golang 相关的文章，是目前我在网上找到的最牛逼的之一，文章不光有深度，而且通俗易懂。\n重新验证 修改上面的代码\n1package main 2 3import ( 4\t\u0026#34;math/rand\u0026#34; 5\t\u0026#34;net/http\u0026#34; 6\t_ \u0026#34;net/http/pprof\u0026#34; 7\t\u0026#34;sync\u0026#34; 8\t\u0026#34;time\u0026#34; 9) 10 11func main() { 12\tgo func() { 13\thttp.ListenAndServe(\u0026#34;0.0.0.0:8090\u0026#34;, nil) 14\t}() 15 16\tvar wg sync.WaitGroup 17\twg.Add(1) 18\tfor i := 0; i \u0026lt; 10000; i++ { 19\tgo one() 20\t} 21\twg.Wait() 22} 23 24func one() { 25\tvar a []int64 26\tfor i := 0; i \u0026lt; 10000; i++ { 27\ta = append(a, rand.Int63()) 28\t} 29\ttime.Sleep(time.Second * 1) 30} 现在 go 出来的的函数 one 不再一直阻塞，而是只会阻塞5秒\n把程序运行起来看一下\n等一段时间后，发现goroutine数量已经下来了，说明阻塞的协程都已经结束了，如图 但是通过任务管理器中，看到程序还是占用着大量的内存 这时点击 heap 查看具体的堆内存情况，拉到最低下，看到一堆参数\n参数很多，但是重点关注被框出来的那几个就好了，详细的分析在大神的文章中有分析，在go的库文件中也能找到，里面有详细的注释。 路径 src-\u0026gt;runtime-\u0026gt;mstats.go 文件中有 MemStats 的定义和注释\n这些参数的单位都是字节\nTotalAlloc : 所有对象分配的总和，整个程序运行期间，只增不减 HeapAlloc : 分配的堆对象的字节数，包括可访问的对象和未被GC回收的不可访问的对象，这个值会动态变化，分配对象时增加，回收对象后减少 HeapIdle : 闲置的span中的字节数，这些span中已经没有对象了（不用了），但是现在还没有还给操作系统，这些span可以重新用来分配heap和stack。HeapIdle 减去 HeapReleased 的值可以当作 \u0026ldquo;可以返回到操作系统但由运行时保留的内存量\u0026rdquo;，也就是说，go的runtime可以在不像操作系统申请内存的情况下，也可以分配heap空间，这样可以提高程序性能 HeapInuse : 正在使用的span的字节大小 HeapReleased : 是返还给操作系统的物理内存的字节数 回到我们的测试程序中，当所有的goroutine都结束时，GC会开始回收切片，但是被回收的内存不会直接换给操作系统，而是由go的runtime暂时保管（也就是 HeapIdle 值会变大），接下来如果再次需要分配空间，go的runtime可以不向操作系统申请内存，直接从自己保管的闲置内存中分配，这样可以提高程序性能。至于GO的runtime什么时候把这部分内存还给操作系统，不同的分配策略和不同的系统不太一样，这个有点深，我还没有深入研究这些。不过 传送门 的文中有介绍 MADV_FREE 有兴趣可以自己学习一下\n总结 go 虽然有GC，但是使用不当也会导致内存泄露 不同的操作系统和不用策略，会导致go程序的内存已经被回收了，但是没有及时的归还给操作系统 由于水平有限，文中如有谬处，还请在评论区不吝赐教\n","date":"2021-03-14T13:58:27Z","image":"https://cdn.jsdelivr.net/gh/lqxhub/images@master/blog/118dbbd1af54c33c82bdbd4d3297a9709b550205.jpg","permalink":"https://lqxhub.github.io/posts/24bc8405/","title":"go 使用 pprof 排查内存泄露"},{"content":"这次书接上回，前段时间写了一篇《使用cmake构建C/C++项目和动态库》的文章， 传送门。 但是直接通过cmake编译链接后，会有一个问题，那就是需要的.so文件不能更改目录，一旦.so文件目录变了,整个程序就没法运行了，这肯定是不行的。\n原因 后来我查一下一下，linux系统中，程序加载运行需要的.so文件是有顺序的\n环境变量LD_LIBRARY_PATH指定的路径 gcc 编译时指定的运行时库路径-rpath ldconfig 配置文件ld.so.conf指定的路径 系统默认库位置 /lib, /usr/lib 如果没有指定so的位置，gcc会自动把当前so所在的目录作为so的连接目录。知道原因了，问题就好解决了\n解决办法 先看一下现在的 CMakeLists.txt文件\n1cmake_minimum_required(VERSION 3.13.3) 2project(project1 C) 3 4set(CMAKE_C_STANDARD 99) 5 6add_library(shared SHARED library.h library.c) 7 8set(LIBRARY_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/lib) 9 10add_executable(project1 main.c) 11 12target_link_libraries(project1 shared) 我实验了两种办法，一是把.so 文件放到/lib 或者 /usr/lib中，这也是在安装很多软件时的做法，当使用包管理器安装软件时，需要的.so文件大多是安装到这两个目录下。在一种就是在编译时指定 rpath的目录，使用相对目录，这样在复制文件的时候，把.so一起复制就可以了。\n先用最简单的办法，把so目录放到系统目录下 现在的目录结构如下，程序依赖的libshared.so 在 lib 目录下，现在把 libshared.so 复制到 /lib 目录下。这里有个要注意的地方，复制完后要执行 ldconfig 命令，重新生成缓存，要不然程序依然找不到对应的.so文件 命令如下\nsudo mv lib/libshared.so /lib sudo ldconfig 这时候在运行 project1 不会报错\n编译时指定 rpath目录 设置 rpaht 有两种方式\n方式1\n1set(CMAKE_SKIP_BUILD_RPATH FALSE) 2set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE) 3set(CMAKE_INSTALL_RPATH $ORIGIN) 通过修改编译后的 install 路径, 让程序在运行时通过程序的相对目录加载.so文件，其中 $ORIGIN 变量是程序的当前目录\n方式2\n1set_target_properties(project1 PROPERTIES LINK_FLAGS \u0026#34;-Wl,-rpath,./\u0026#34;) 方式2更粗暴，直接设置gcc的编译参数，指定rpaht 是当前目录\n修改 CMakeLists.txt文件\n1cmake_minimum_required(VERSION 3.13.3) 2project(project1 C) 3 4set(CMAKE_C_STANDARD 99) 5 6add_library(shared SHARED library.h library.c) 7 8set(LIBRARY_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/lib) 9 10#方式1 11set(CMAKE_SKIP_BUILD_RPATH FALSE) 12set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE) 13set(CMAKE_INSTALL_RPATH $ORIGIN) 14 15add_executable(project1 main.c) 16 17#方式2 18#set_target_properties(project1 PROPERTIES LINK_FLAGS \u0026#34;-Wl,-rpath,./\u0026#34;) 19target_link_libraries(project1 shared) 重新生成 MakeFile 文件, 然后编译\n编译生成的 libshared.so 还是在 lib目录下，先移动到可执行文件的同级目录下 最终目录如图，现在无论怎么复制文件，只要可执行文件和动态库在一个目录下，都以运行了\n总结 解决linux下 动态编译的程序找不到动态库的问题，有多种解决办法，这次用了两种\n把需要的.so文件放到 /lib 或者 /usr/lib 下， 然后执行 ldconfig命令 通过指定 rpath 来决定加载 .so的目录 ","date":"2021-03-13T17:48:50Z","permalink":"https://lqxhub.github.io/posts/497a7ebf/","title":"linux下通过rpath解决cmake动态编译后找不到动态链接库问题"},{"content":"编译C/C++文件时，很多时候都是直接使用像 gcc main.c 或者 g++ main.cpp 这样的命令编译的。但是代码文件多了后，这样编译就很困难了。这时候 就出现了MakeFile 这个工具。\nMakeFile 解决了多个文件编译难的问题，有了MakeFile，只需要在MakeFile的目录中 运行一下make 命令， 编译就会自动完成。但是编写MakeFile又很啰嗦，于是聪明的程序员们有开发了一个工具，自动生成MakeFile 文件，cmake 的作用就是自动生成MakeFile。毕竟写cmake要比写MakeFile要简单很多\n也许你会说，现在都是用IDE写代码，IDE都会自动自动编译和运行，我还学这些干啥。但是有时候需要服务器上编译项目，或者在没有IDE的机器上编译项目，这时候MakeFile就很有用了。其实很多IDE也是使用cmake完成编译的，比如 clion\ncmake 安装 在linux上可以使用源码安装和包管理安装，一般直接用包管理安装就好了 Ubuntu和Debian sudo apt-get install cmake\nCentOS sudo yum install cmake\n因为cmake只是生成MakeFile，最终组织编译的还是MakeFile，所以还有安装make\nmake 一般都会预装，为了保险，还是装一下\nUbuntu和Debian sudo apt-get install make\nCentOS sudo yum install make\ncmake基本规则 cmake 也没啥神秘的，本质上也是根据一定的规则自动生成MakeFile的，也是有语法的\n# 是注释符号\n预定义变量 PROJECT_NAME项目名称 PROJECT_SOURCE_DIR工程的根目录 PROJECT_BINARY_DIR 执行cmake命令的目录 PROJECT_BINARY_DIR 执行cmake命令的目录 CMAKE_CURRENT_SOURCE_DIR 当前CMakeLists.txt文件所在目录 CMAKE_C_FLAGS设置C编译选项 CMAKE_CXX_FLAGS设置C++编译选项 CMAKE_C_COMPILER设置C编译器 CMAKE_CXX_COMPILER设置C++编译器 EXECUTABLE_OUTPUT_PATH设置编译后可执行文件目录 LIBRARY_OUTPUT_PATH设置生成的库文件目录\n常用规则 cmake_minimum_required(VERSION 3.16) 指令cmake 版本 project(hello_world) 设置工程名 include_directories(${PROJECT_SOURCE_DIR}/include) 添加头文件路径 link_directories(${PROJECT_SOURCE_DIR}/lib) 添加链接库的路径 add_subdirectory(module)添加 module 子目录, 此目录下也要有CMakeLists.txt文件 add_executable(project1 main.c)指定编译的可执行文件 add_library(lib1 SHARED library.c library.h)指定生成的库文件，SHARED是生成动态库，STATIC后生成静态库 add_compile_options() 添加编译选项 target_link_libraries()指定动态链接库 install()指定make install的目录\nset(XXXX YYYYYY)用于设置和修改变量 ${XXXX} 使用变量\n构建一个简单的项目 只有一个 main.c 文件\nCMakeList.txt\n1cmake_minimum_required(VERSION 3.15) 2project(project1 C) 3 4set(CMAKE_C_STANDARD 99) 5 6add_executable(project1 main.c) main.c\n1#include \u0026lt;stdio.h\u0026gt; 2 3int main() { 4 printf(\u0026#34;Hello, CMakeList!\\n\u0026#34;); 5 return 0; 6} 编译一个debug版本 mkdir debug 新建debug目录 cd debug 进入debug目录 cmake -DCMAKE_BUILD_TYPR=debug .. 指定编译模式为debug make 生成可执行文件 此时会生成project1文件\n步骤 3 中 cmake -DCMAKE_BUILD_TYPE=release .. 指定编译模式为release\n构建一个生成动态库的项目 有两个文件library.h和library.c CMakeList.txt\n1cmake_minimum_required(VERSION 3.15) 2project(shared C) 3 4set(CMAKE_C_STANDARD 99) 5 6add_library(shared SHARED library.c library.h) library.h\n1int add(int a, int b); library.c\n1int add(int a, int b) { 2 return a + b; 3} 生成动态库 mkdir lib 新建lib目录 cd lib 进入lib目录 cmake -DCMAKE_BUILD_TYPE=debug .. 指定编译模式为debug make 生成可执行文件 此时会生成 libshared.so文件 在第一个项目中使用动态库 首先把 libshared.so文件和library.h文件复制到第一个项目中\n修改 CMakeList.txt\n1cmake_minimum_required(VERSION 3.15) 2project(project1 C) 3 4set(CMAKE_C_STANDARD 99) 5 6add_executable(project1 main.c) 7 8target_link_libraries(project1 ${PROJECT_SOURCE_DIR}/libshared.so)#指定动态库文件 mkdir debug 新建debug目录 cd debug 进入debug目录 cmake -DCMAKE_BUILD_TYPE=debug .. 指定编译模式为debug make 生成可执行文件 最终目录如图 把两个项目合成一个 能不能在一个项目中生成动态库并在这个项目中使用呢，当然是可以的。\n也就是在这个项目中部分文件编译成动态库 .so 文件， 部分文件编译成 可执行文件\n修改 CMakeList.txt\n1cmake_minimum_required(VERSION 3.13.3) 2project(project1 C) 3 4set(CMAKE_C_STANDARD 99) 5 6add_library(shared SHARED library.h library.c) 7 8set(LIBRARY_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/lib)#设置动态库输出目录 9 10add_executable(project1 main.c) 11 12target_link_libraries(project1 shared) mkdir debug 新建debug目录 cd debug 进入debug目录 cmake -DCMAKE_BUILD_TYPE=debug .. 指定编译模式为debug make 生成可执行文件 最终目录如图\n最后 通过几个简单的例子，介绍了一下cmake的基本使用，文中是使用cmake构建的C项目，换成C++基本没什么区别，就不展示了\ncmake的功能远不止这些，还需要在实战中多学习，多总结\n2021-03-06 补充 通过上面的方式可以编译运行，但是会有一个问题，就是 .so 文件不能更改目录，一旦动态库目录变了，程序就没法加载，程序也就没法运行了。为此又找资料学习一番，另写了一篇，{% post_link linux下cmake动态编译后找不到动态链接库 [传送门] %}\n","date":"2021-03-13T17:45:45Z","permalink":"https://lqxhub.github.io/posts/a20c5e48/","title":"使用cmake构建C/C++项目和动态库"},{"content":"golang中是有指针概念的，但是go中的指针功能被限制了，不像C/C++中那样,可以对指针进行运算\n比如在C/C++中 *p++ 这样是正确的。但是在go中，这样写是错误的。至于go为什么会屏蔽指针的运算，比较多的一种说法是go团队认为指针的运算会带来一些安全问题，再有就是简化语法，所以go直接就不支持指针运算了。\n虽然go语法不支持，但是通过go的 unsafe 包可以间接的实现对指针的运算，就想这个包的名字一样，这个包提供的东西不是安全的，使用不当可能会出现一些问题，所以在go是不推荐使用的，自己玩玩还可以，真正的项目中，还是尽量不要使用。\n在一个知识点，go是通过首字母的大小写在却别 private 和 public 的，不同包中的是无法访问private变量的。其实所谓的private和public只是语法上的限制，到了汇编层，都是地址，哪来的公开和私有的，所以，但是我们通过使用地址（也就是指针）来绕过语法限制，访问其他包中的私有变量。\n说了一堆废话了，开始上真的，先创建有一个project，目录层次如下：\n上代码 one.go 1package one 2 3type One struct { 4\tA int 5\tb int 6\tc *Two 7} two.go 1package one 2 3type Two struct { 4\tD int 5} main.go 1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;pointer/one\u0026#34; 6\t\u0026#34;unsafe\u0026#34; 7) 8 9func main() { 10\to := \u0026amp;one.One{} 11 12\tp := unsafe.Pointer(o) 13\tp2 := (*int)(unsafe.Pointer(uintptr(p) + unsafe.Sizeof(o.A))) 14\t*p2 = 100 15 16\tt := \u0026amp;one.Two{D: 2000} 17\tfmt.Printf(\u0026#34;%p \\n\u0026#34;, t) 18 19\tp3 := (*int)(unsafe.Pointer(uintptr(p) + unsafe.Sizeof(o.A)*2)) 20 21\t*p3 = (int)(uintptr(unsafe.Pointer(t))) 22\t23\tfmt.Println(o) 24 25} 运行结果 可以看到，one中私有变量已经被成功赋值了，\n通过打印的指针可以看到， two 结构体的指针已经赋到 one 结构的私有变量 c 中了\n代码具体是什么意思呢，简单介绍一下\n具体解释 p := unsafe.Pointer(o) 把one结构的指针转换成 unsafe.Pointer 类型。\n这个类型有点像 C/C++ 中的 void*\nuintptr(p) 把指针转换成可以运算的类型\nunsafe.Sizeof(o.A) 是获取A变量在结构体中长度，对应的b就在结构体中的位置，也就是指针\n因为 one中的b变量是 int 类型,所以要强转成 int类型的指针，这时候就可以给private变量b赋值了\n同样，也可以为c赋值，只不过c中是指针类型的，其实指针类型可以看做是int类型，变量中保存的是内存地址罢了\n(*int)(unsafe.Pointer(uintptr(p) + unsafe.Sizeof(o.A)*2)) 同样的方法拿到c的地址\n(int)(uintptr(unsafe.Pointer(t))) 创建的two的指针地址转换成 int 类型\n好了,到现在整个指针的运算过程就结束了\n换个形式 之前我们是通过 unsafe.Sizeof(o.A) 获取指针偏移长度的，其实我们可以根据变量的类型自己推算出来。\n我的电脑是64位的，所有int 变量的长度也是64位，也就是8个字节，修改一下代码\n修改后 1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;pointer/one\u0026#34; 6\t\u0026#34;unsafe\u0026#34; 7) 8 9func main() { 10\to := \u0026amp;one.One{} 11 12\tp := unsafe.Pointer(o) 13\tp2 := (*int)(unsafe.Pointer(uintptr(p) + 8)) 14\t*p2 = 100 15 16\tt := \u0026amp;one.Two{D: 2000} 17\tfmt.Printf(\u0026#34;%p \\n\u0026#34;, t) 18 19\tp3 := (*int)(unsafe.Pointer(uintptr(p) + 16)) 20 21\t*p3 = (int)(uintptr(unsafe.Pointer(t))) 22 23\tfmt.Println(o) 24 25} 运行结果 可以发现结果是一样的\n但是第二种方式不够通用，换个机器可能就报错了，比如在32位的机器上，int长度是32位，程序就出错了\n总结 虽然 go 本身不支持指针的运算，但是有些时候我们需要用到指针的运算，比如获取private变量。但是这种方式有风险，在实际项目中使用要慎重！！！\n","date":"2021-03-13T17:43:57Z","permalink":"https://lqxhub.github.io/posts/560ffd6b/","title":"golang使用unsafe包实现指针运算操作private"},{"content":"近来无事，本着爱折腾的原则，在go原生 http client 的基础上，自己封装了一个go的http client。由于才疏学浅，再加是第一次造轮子，在各位大佬面前献丑了，写的烂的地方，请轻喷。还请各位不吝赐教。\n先放地址\ngethub： https://github.com/lqxhub/easy_http\nGitee： https://gitee.com/lqxlucky/easy_http\n简单介绍一下功能 使用 构造器模式，提供了链式调用和方便使用的接口 支持https自定义服务器证书校验和双向证书校验 支持代理,可以方便的设置代理 封装了multipart 协议, 可以方便的上传文件 具有很强的拓展性,可以在基础上非常方便的定制自己http请求 支持http的 返回结果 异步回调 可以方便的自定义Response 安装库 可以使用github的库,也可使用Gitee的库，两个库的代码都是一样的，因为github网速的原因，所以在gitee上也传了一份\ngithub：go get -u https://github.com/lqxhub/easy_http\ngitee： go get -u https://gitee.com/lqxlucky/easy_http\n使用 引入库 因为github和gitee拉下来的库目录不同，所以以github的为准\n1import \u0026#34;github.com/lqxhub/easy_http\u0026#34; 具体使用 全部配置 1func main() { 2\t//得到一个http client的构造器 3\tbuilder := easy_http.NewClientBuilder() 4 5\t//是否跳过服务器证书校验 6\tbuilder.SkipVerify(false) 7 8\t//设置超时时间 9\tbuilder.TimeOut(time.Second * 5) 10 11\t//设置代理 12\tbuilder.ProxyUrl(\u0026#34;http://127.0.0.1:10809\u0026#34;) 13 14\t//设置根证书 15\tvar certPool [1]string 16\tcertPool[0] = \u0026#34;D:\\\\server.pem\u0026#34; 17\tbuilder.Cert(certPool[:]) 18\t19\t//设置双向校验证书 20\tvar tlsPath [1]*easy_http.TlsPath 21\ttlsPath[0] = \u0026amp;easy_http.TlsPath{ 22\tCertFile: \u0026#34;D:\\\\client.pem\u0026#34;, 23\tKeyFile: \u0026#34;D:\\\\client.key\u0026#34;, 24\t} 25\tbuilder.Tls(tlsPath[:]) 26 27\t//设置http请求header 28\theader := make(map[string]string) 29\theader[\u0026#34;Accept-Language\u0026#34;] = \u0026#34;Accept-Language: en,zh\u0026#34; 30\tbuilder.Header(header) 31 32\t//设置http请求cookie 33\tcookie := make(map[string]string) 34\tcookie[\u0026#34;name\u0026#34;] = \u0026#34;value\u0026#34; 35\tbuilder.Cookie(easy_http.EasyCookie(cookie)) 36 37\t//开启cookie jar 38\tbuilder.Jar(nil) 39 40\t//设置 Response 处理函数 41\tbuilder.BuildResponse(easy_http.EasyBuildResponse) 42 43\t//构造client 44\tclient, err := builder.Build() 45\tif err != nil { 46\tfmt.Println(\u0026#34;aa\u0026#34;, err) 47\treturn 48\t} 49} 这样就初始化一个http的客户端\n当然，上面的例子是设置了所有配置的，也可以全部使用默认配置\n使用默认配置 1func DefaultClient() { 2\tbuilder := easy_http.NewClientBuilder() 3\tclient, err := builder.Build() 4\tif err != nil { 5\tfmt.Println(err) 6\treturn 7\t} 8\tclient.Get(\u0026#34;http://baidu.com\u0026#34;) 9} 这样同样是可以的\neasy 函数 使用 库中提供了一些函数，可以方便的构造http请求相关的结构\n1func EasyFunction() { 2 3\turl := \u0026#34;http://baidu.com\u0026#34; 4 5\t//合成http get的url和参数 6\tvalues := make(map[string]string) 7\tvalues[\u0026#34;v\u0026#34;] = \u0026#34;123456\u0026#34; 8\teasy_http.EasyGet(url, values) 9 10\t//构造cookie 11\tcookie := make(map[string]string) 12\tcookie[\u0026#34;name\u0026#34;] = \u0026#34;value\u0026#34; 13\teasy_http.EasyCookie(cookie) 14 15\t//合成 http post 的参数 16\teasy_http.EasyPost(values) 17 18\t//构造 上传文件的multipart 19\tmultipartBuilder := easy_http.NewMultipartBuilder() 20\tmultipartBuilder.AddFile(\u0026#34;file1\u0026#34;,\u0026#34;D:\\\\a.txt\u0026#34;) 21\tmultipartBuilder.AddFromDate(\u0026#34;name\u0026#34;,\u0026#34;value\u0026#34;) 22\tmultipartBuilder.AddBytes(\u0026#34;name2\u0026#34;,[]byte(\u0026#34;aaaaa\u0026#34;)) 23\tmultipart, err := multipartBuilder.Builder() 24\t25} 异步回调使用 库封装了 异步回调功能，请求会在一个新的goroutine中进行。当http请求完成时，会回调函数。回调函数可用形参使用传入函数和实现接口两种方式\n1 2func Call(response easy_http.IResponse) { 3\tfmt.Println(response.Error()) 4\tfmt.Println(response.StatusCode()) 5\tfmt.Println(string(response.Content())) 6} 7 8type Get struct { 9} 10 11func (g Get) EasyResponseCallback(response easy_http.IResponse) { 12\tfmt.Println(response.Error()) 13\tfmt.Println(response.StatusCode()) 14\tfmt.Println(string(response.Content())) 15} 16 17func AsynchronousRequest() { 18\turl := \u0026#34;http://baidu.com\u0026#34; 19\tclient, err := easy_http.NewClientBuilder().Build() 20\tif err != nil { 21\tfmt.Println(err) 22\treturn 23\t} 24 25\t//函数异步回调 26\tclient.GetAsyn(url, Call) 27 28\t//接口异步回调 29\tclient.GetAsynWithCallback(url, \u0026amp;Get{}) 30} 自定义请求 因为库中只封装了 GET和POST这两种方式，向PUT，DELETE等这些方式需要自己去实现。所以，可以使用下面的函数来实现\n1func Call(response easy_http.IResponse) { 2\tfmt.Println(response.Error()) 3\tfmt.Println(response.StatusCode()) 4\tfmt.Println(string(response.Content())) 5} 6 7func CustomizeRequest() { 8\turl := \u0026#34;http://baidu.com\u0026#34; 9\tclient, err := easy_http.NewClientBuilder().Build() 10\tif err != nil { 11\tfmt.Println(err) 12\treturn 13\t} 14\tresponse := client.SendWithMethod(url, http.MethodPut, nil, func(request *http.Request) { 15\t//修改Request 16\t}) 17\tfmt.Println(response.Error()) 18\tfmt.Println(response.StatusCode()) 19 20\t//异步方式 21\tclient.SendWithMethodCallBack(url, http.MethodPut, nil, func(request *http.Request) { 22\t//习惯Request 23\t}, Call) 24} 使用go http默认的函数请求 当需要有一些特殊的请求，这个库无法满足时，可以使用go http原生的方式来请求\n1func Primitive() { 2\turl := \u0026#34;http://baidu.com\u0026#34; 3\tclient, err := easy_http.NewClientBuilder().Build() 4\tif err != nil { 5\tfmt.Println(err) 6\treturn 7\t} 8\t//获取Request 9\trequest, err := http.NewRequest(http.MethodGet, url, nil) 10\tif err != nil { 11\tfmt.Println(err) 12\treturn 13\t} 14\t//得到http的原生Response 15\tresponse, err := client.DoRequest(request) 16\tif err != nil { 17\tfmt.Println(err) 18\treturn 19\t} 20\tfmt.Println(response) 21} 自定义Response 库中返回的Response是一个接口类型，只要实现了这个接口，都可作为返回值返回，自定义的Response，在构造client的设置就可以了\n1type MyResponse struct { 2} 3 4func (m MyResponse) Error() error { 5\treturn nil 6} 7 8func (m MyResponse) StatusCode() int { 9\treturn 0 10} 11 12func (m MyResponse) Header() http.Header { 13\treturn nil 14} 15 16func (m MyResponse) ContentLength() int64 { 17\treturn 0 18} 19 20func (m MyResponse) Content() []byte { 21\treturn nil 22} 23 24func (m MyResponse) Resp() *http.Response { 25\treturn nil 26} 27 28func (m MyResponse) Request() *http.Request { 29\treturn nil 30} 31 32func (m MyResponse) Cookie(name string) *http.Cookie { 33\treturn nil 34} 35 36//构造HTTP response的函数 37func MyBuildResponse(resp *http.Response, err error) easy_http.IResponse { 38\tresponse := new(MyResponse) 39 //做处理 40\treturn response 41} 42func CustomizeResponse() { 43\tclient, err := easy_http.NewClientBuilder(). 44\tBuildResponse(MyBuildResponse). 45\tBuild() 46\tif err != nil { 47\tfmt.Println(err) 48\treturn 49\t} 50} 结构体 MyResponse 实现了 easy_http.IResponse 这个接口。然后在MyBuildResponse这个函数中，new 一个 MyResponse的对象，再根据自己的需要，做相应的处理就可以了。 在clientBuilder.BuildResponse(MyBuildResponse)设置就可以了\n最后 整个库的基本功能就是这些了。第一造轮子，写的很烂。写这篇文章时，还发现了好几个因为首字母小写导致的问题。\n有问题的地方，还请不吝赐教\n","date":"2021-03-13T17:40:55Z","permalink":"https://lqxhub.github.io/posts/19d697e6/","title":"golang造轮子 封装一个简单的http client"},{"content":"工作中经常需要写shell脚本来处理一些重复的东西，使用脚本自动编译，使用脚本多机器传输文件。\n因为不是天天写shell，只是用到的时候写一个，再加上脚本中的if的判断条件有点多，容易忘记，所以做个备忘录，以备不时之需\n先说一下 if 表达式的基本语法 1if [ command ]; then 2 符合该条件执行的语句 3fi 1if [ command ];then 2 符合该条件执行的语句 3elif [ command ];then 4 符合该条件执行的语句 5else 6 符合该条件执行的语句 7fi 注意：\nif 条件 要以 fi 结束 [] if语句中 和 表达式要注意空格 then 和 fi 是分开的语句。如果要在同一行里面输入，则需要用分号将他们隔开 使用 -z 或者 -n 来检查长度的时候，没有定义的变量也为0 下面是常用表达式 数字判断 表达式 含义 int1 -eq int2 两数相等为真 int1 -ne int2 两数不等为真 int1 -gt int2 int1大于int2为真 int1 -ge int2 int1大于等于int2为真 int1 -lt int2 int1小于int2为真 int1 -le int2 int1小于等于int2为真 逻辑相关 表达式 含义 -a 与 -o　或 ! 非 字符串相关 表达式 含义 STRING　当串str1为非空时为真 -z STRING “STRING” 的长度为零则为真 -n STRING “STRING” 的长度为非零 non-zero则为真 STRING1 == STRING2 如果2个字符串相同则为真 STRING1 != STRING2 如果字符串不相等则为 文件相关 表达式 含义 -a FILE 如果 FILE 存在则为真 -b FILE 如果 FILE 存在且是一个块特殊文件则为真 -c FILE 如果 FILE 存在且是一个字特殊文件则为真 -d FILE 如果 FILE 存在且是一个目录则为真 -e FILE 如果 FILE 存在则为真 -f FILE 如果 FILE 存在且是一个普通文件则为真 -g FILE 如果 FILE 存在且已经设置了SGID则为真 -h FILE 如果 FILE 存在且是一个符号连接则为真 -k FILE 如果 FILE 存在且已经设置了粘制位则为真 -p FILE 如果 FILE 存在且是一个名字管道(F如果O)则为真 -r FILE 如果 FILE 存在且是可读的则为真 -s FILE 如果 FILE 存在且大小不为0则为真 -t FD 如果文件描述符 FD 打开且指向一个终端则为真 -u FILE 如果 FILE 存在且设置了SUID (set user ID)则为真 -w FILE 如果 FILE 如果 FILE 存在且是可写的则为真 -x FILE 如果 FILE 存在且是可执行的则为真 -O FILE 如果 FILE 存在且属有效用户ID则为真 -G FILE 如果 FILE 存在且属有效用户组则为真 -L FILE 如果 FILE 存在且是一个符号连接则为真 -S FILE 如果 FILE 存在且是一个套接字则为真 FILE1 -ot FILE2 如果 FILE1 比 FILE2 要老, 或者 FILE2 存在且 FILE1 不存在则为真 FILE1 -ef FILE2 如果 FILE1 和 FILE2 指向相同的设备和节点号则为真 -o OPTIONNAME 如果 shell选项 “OPTIONNAME” 开启则为真 ","date":"2021-03-13T11:27:54Z","permalink":"https://lqxhub.github.io/posts/6cd27815/","title":"linux shell 脚本 常用的if判断条件"},{"content":"使用go查询数据库时，有时候会遇到 **scan error sql: Scan error on column index XXXXX unsupported Scan, storing driver.Value type **这个错误，\n这个错误产生的原因是，查询的结果中有的值是NULL ， 导致在读查询结果时，遇到NUL 类型的数值，无法正确读出数值 现在通过一个简单的例子复现一下 先创建一个简单的表\n1CREATE TABLE `user` ( 2 `id` int(11) NOT NULL, 3 `name` varchar(255) DEFAULT NULL, 4 PRIMARY KEY (`id`) 5) ENGINE=InnoDB DEFAULT CHARSET=utf8; 其中 name这个字段默认是NULL 的，现在插入几条数据\n1 insert into user(`id`,`name`) values(1,\u0026#39;A\u0026#39;); 2 insert into user(`id`,`name`) values(2,\u0026#39;B\u0026#39;); 3 insert into user(`id`,`name`) values(3,NULL); go代码\n1package main 2 3import ( 4\t\u0026#34;database/sql\u0026#34; 5\t\u0026#34;fmt\u0026#34; 6\t_ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; 7) 8 9type User struct { 10\tid uint32 11\tname string 12} 13 14func main() { 15\tdb := Conn() 16\tif db == nil { 17\treturn 18\t} 19\tresult := make([]*User, 0, 10) 20\tq := \u0026#34;SELECT `id`, `name` FROM `user`\u0026#34; 21\tif rows, err := db.Query(q); err == nil { 22\tfor rows.Next() { 23\tid := uint32(0) 24\tname := \u0026#34;\u0026#34; 25\tif err := rows.Scan(\u0026amp;id, \u0026amp;name); err == nil { 26\tresult = append(result, \u0026amp;User{ 27\tid: id, 28\tname: name, 29\t}) 30\t} else { 31\tfmt.Println(\u0026#34;rows scan error\u0026#34;, err) 32\t} 33\t} 34\t} else { 35\tfmt.Println(\u0026#34;query error\u0026#34;, err) 36\t} 37\tfor _, v := range result { 38\tfmt.Println(v) 39\t} 40} 41 42func Conn() *sql.DB { 43\tdb, err := sql.Open(\u0026#34;mysql\u0026#34;, \u0026#34;root:123456@tcp(127.0.0.1)/go_test\u0026#34;) 44\tif err != nil { 45\tfmt.Print(\u0026#34;sql open error\u0026#34;, err) 46\treturn nil 47\t} 48\terr2 := db.Ping() 49\tif err2 != nil { 50\tfmt.Print(\u0026#34;sql pin error\u0026#34;, err2) 51\treturn nil 52\t} 53\treturn db 54} 运行后，报错 这个错误有两种解决办法\n从数据层面解决，把name字段设置为非空字段，并且默认值设置为**\u0026quot;\u0026quot;**空字符串，问题就解决了 改一下表 1CREATE TABLE `user` ( 2 `id` int(11) NOT NULL, 3 `name` varchar(255) NOT NULL DEFAULT \u0026#39;\u0026#39;, 4 PRIMARY KEY (`id`) 5) ENGINE=InnoDB DEFAULT CHARSET=utf8; 查询结果是正常的 对于一些特殊的查询，结果中难免会有NULL值，比如连接查询等等，这时候需要用第二种方式来解决 2. 使用go 提供的 sql.NullString类型值来结局，这个是string类型的， go 还提供了其他类型的，还有NullBoolbool类型的，NullFloat64float64类型的，NullInt64 int64类型的\n为了方便，还是把表改回最开始，name默认是NULL类型的 修改一下代码\n1\tresult := make([]*User, 0, 10) 2\tq := \u0026#34;SELECT `id`, `name` FROM `user`\u0026#34; 3\tif rows, err := db.Query(q); err == nil { 4\tfor rows.Next() { 5\tid := uint32(0) 6\tvar name sql.NullString 7\tif err := rows.Scan(\u0026amp;id, \u0026amp;name); err == nil { 8\tu := \u0026amp;User{ 9\tid: id, 10\t} 11\tif name.Valid { 12\tu.name = name.String 13\t} else { 14\tu.name = \u0026#34;\u0026#34; 15\t} 16\tresult = append(result, u) 17\t} else { 18\tfmt.Println(\u0026#34;rows scan error\u0026#34;, err) 19\t} 20\t} 21\t} else { 22\tfmt.Println(\u0026#34;query error\u0026#34;, err) 23\t} 把 name 的类型改为 sql.NullString 并且在查询完成后，判断一下name是否有效\n看一下结果 没有问题\n到这问题解决了\n","date":"2020-06-21T11:27:54Z","permalink":"https://lqxhub.github.io/posts/5c491bc1/","title":"go数据库查询 unsupported Scan"},{"content":"golang这门语言，有个比较好的特性，就是支持函数的多返回值。想C，C++，Java等这些语言，是不支持函数多返回的。但是C，C++可以使用传递指针，实现函数多返回。但是，你有没有想过，golang是怎样实现函数多返回值的呢？ 我们知道，C，C++是通过寄存器实现函数返回值的，也就是先把返回值写入到一个寄存器中，然后再从寄存器中，读到函数的返回值。golang也是这样实现的吗？\n伟大的思想家孔子曾说过，在源码面前一切都如同裸奔。后来，鲁迅先生，总结了孔子的思想，说出了，在汇编面前，一切语法都是纸老虎。\n下面我们通过golang的汇编指令，来看一下golang是怎样实现函数的多返回值的\n在看汇编之前，我们先用go的debug函数看下函数的栈信息 代码很简单，不用解释了\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;runtime/debug\u0026#34; 6) 7 8func main() { 9\tone(3) 10} 11 12func one(a int) (int, int) { 13\tfmt.Println(string(debug.Stack())) 14\treturn a, a + 5 15} 我标红的这一行，就是one 函数的栈信息，第一个参数 0x3 很好理解，就是我们传入的参数3， 但是后面这两个是啥？还有，我明明只传了一个参数，为啥会传入三个参数？\n到这里，我也就不卖关子了，直接说了，后面这两个参数，就是one函数返回值的地址，也就是说，one函数返回值地址不在one函数中，而是在调用one函数的mian函数中。golang的函数返回值，和C，C++的不同，golang的返回值是通过栈内地址实现的（返回值的地址是由函数调用者提供）。\n1package main 2 3func main() { 4\tvar b, c *int 5\tone(3, b, c) 6} 7 8func one(a int, b, c *int) { 9} 也就是说，刚开始的那段代码，和这段在功能实现上，没有什么差别，只是golang编译器提供的一个语法糖。\n下面通过汇编来看一下 这次我们不是对深入分析golang的汇编，只是从汇编层面，验证我们之前结论（golang函数多返回问题） 所以，不会死磕plan9汇编语法，说实话，plan9的很多知识我也不懂，大学没开过汇编的课程，这些东西都是因为兴趣自学的。\ngolang用的是plan9汇编，看plan9之前，先了解一下plan9的几个概念\ngo汇编中有4个伪寄存器\nFP: Frame pointer，指向栈底位置，一般用来引用函数的输入参数，用来访问函数的参数 PC: Program counter: 程序计数器，用于分支和跳转 SB: Static base pointer: 一般用于声明函数或者全局变量 SP: Stack pointer：指向当前栈帧的局部变量的开始位置(栈顶位置)，一般用来引用函数的局部变量 我们用这段代码进行汇编\n1package main 2 3func main() { 4\tone(3) 5} 6 7func one(a int) (int, int) { 8\treturn a, a + 5 9} 使用 go tool compile -N -l -S main.go 得到汇编代码\n1\u0026#34;\u0026#34;.main STEXT nosplit size=2 args=0x0 locals=0x0 2 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:3) TEXT \u0026#34;\u0026#34;.main(SB), NOSPLIT|ABIInternal, $0-0 3 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:3) FUNCDATA $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 4 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:3) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 5 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:3) FUNCDATA $3, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 6 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:4) PCDATA $2, $0 7 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:4) PCDATA $0, $0 8 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:4) XCHGL AX, AX 9 0x0001 00001 (\u0026lt;unknown line number\u0026gt;) RET 10 0x0000 90 c3 .. 11\u0026#34;\u0026#34;.one STEXT nosplit size=20 args=0x18 locals=0x0 12 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:7) TEXT \u0026#34;\u0026#34;.one(SB), NOSPLIT|ABIInternal, $0-24 13 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:7) FUNCDATA $0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 14 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:7) FUNCDATA $1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 15 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:7) FUNCDATA $3, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 16 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:8) PCDATA $2, $0 17 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:8) PCDATA $0, $0 18 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:8) MOVQ \u0026#34;\u0026#34;.a+8(SP), AX 19 0x0005 00005 (C:\\Users\\bruce\\Desktop\\go\\main.go:8) MOVQ AX, \u0026#34;\u0026#34;.~r1+16(SP) 20 0x000a 00010 (C:\\Users\\bruce\\Desktop\\go\\main.go:8) ADDQ $5, AX 21 0x000e 00014 (C:\\Users\\bruce\\Desktop\\go\\main.go:8) MOVQ AX, \u0026#34;\u0026#34;.~r2+24(SP) 22 0x0013 00019 (C:\\Users\\bruce\\Desktop\\go\\main.go:8) RET 23 0x0000 48 8b 44 24 08 48 89 44 24 10 48 83 c0 05 48 89 H.D$.H.D$.H...H. 24 0x0010 44 24 18 c3 D$.. 我只截取了和main，one函数相关的部分 TEXT \u0026quot;\u0026quot;.one(SB), NOSPLIT|ABIInternal, $0-24这行最后， $0-24 的含义，0代表one函数的栈帧大小(局部变量+可能需要的额外调用函数的参数空间的总大小)， 因为one函数中没有额外开销，所有大小是0，24是传入参数和返回值的大小，单位是字节。传入的参数和返回值都是int，在64位机器上，大小是8个字节，64位。\n简单画一下栈的示意图\n看一下这句 0x0000 00000 (C:\\Users\\bruce\\Desktop\\go\\main.go:8) MOVQ \u0026quot;\u0026quot;.a+8(SP), AX\nSP 寄存器指向的是栈顶的位置，AX 是一个通用寄存器 MOVQ 指令 把 参数a 也就是(SP+8)的值搬到AX中\n0x0005 00005 (C:\\Users\\bruce\\Desktop\\go\\main.go:8) MOVQ AX, \u0026quot;\u0026quot;.~r1+16(SP)\n同样，把AX中的值搬到r1（返回值b）\n0x000a 00010 (C:\\Users\\bruce\\Desktop\\go\\main.go:8) ADDQ $5, AX ADDQ指令把AX值+5\n0x000e 00014 (C:\\Users\\bruce\\Desktop\\go\\main.go:8) MOVQ AX, \u0026quot;\u0026quot;.~r2+24(SP) 最后把AX的值搬到r2(返回值c)\n0x0013 00019 (C:\\Users\\bruce\\Desktop\\go\\main.go:8) RET 最后RET指令，one函数结束\n总结\n通过对golang进行汇编，真实了之前的结论\ngolang函数的多返回值不是通过寄存器传递，使用过使用调用值提供的地址，赋值实现的\n先写这些吧，我也是刚接触golang的汇编，文中如有不正确的地方，还请在评论区指出\n","date":"2020-06-21T11:27:54Z","permalink":"https://lqxhub.github.io/posts/1c1c3bd5/","title":"通过汇编看golang函数的多返回值"},{"content":"ansible是一个基于python开发自动化的运维工具，这个工具强大的地方是，被操作的机器上不需要安装任何软件，只需要在发起操作的机器上安装就可以使用了。 而且ansible支持很多模块，还可以基于ansible二次开发，添加自己的功能\nansible功能和模块很多，这次我们只讲其中的一个。在命令行中，直接把要操作主机的用户名和密码传入。别的东西等以后有时间会继续写的，毕竟996太累了\n正常使用ansible一般都是 在 /ect/ansible/hosts 中配置远程主机的用户和密码 一般写法\n1[test] 2one ansible_ssh_host=192.168.199.209 ansible_ssh_port=22 ansible_ssh_user=root ansible_ssh_pass=123456 然后使用命令行 ansible test -m ping 看到截图，说明已经ping通，说明配置是没问题的\n有时候，需要单独指定连接一台主机，或者只是临时连接一次，这时候没必要在hosts文件中配置，可以直接在命令行中传入主机ip和连接用户名和密码 ansible all -i \u0026quot;192.168.199.209:22,\u0026quot; -m ping -e\u0026quot;ansible_user=root ansible_password=123456\u0026quot; 注意：ip后面一定要有一个\u0026quot;,\u0026quot; 截图中，说明没问题\n好了先写这些，ansible模块跟多，功能很多。尤其是playbook这个东西，更是牛逼，以后有时间继续写\n","date":"2020-06-13T17:06:53Z","permalink":"https://lqxhub.github.io/posts/f6596db0/","title":"ansible 在参数中传入密码"},{"content":"之前使用docker安装过mysql，使用的是别人制作好的镜像。今天使用Dockerfile自己打包一个docker的镜像。这个镜像是一个web的镜像，使用go编写。\ngo非常适合用来写docker的镜像程序，因为go编译后的二进制程序不依赖外外部库（划重点，后面会用到这个知识点），可以非常方便的打包进docker中。 这次打包镜像会用到docker的端口映射和目录挂载这两个特性，后面用到会指出 我的编译和打包是在linux中完成的，文中所有的介绍都是以linux系统为基础\n先上web程序的代码\n1package main 2 3import ( 4\t\u0026#34;net/http\u0026#34; 5\t\u0026#34;os\u0026#34; 6\t\u0026#34;strconv\u0026#34; 7\t\u0026#34;time\u0026#34; 8) 9 10const BASE_DIR = \u0026#34;./data/\u0026#34; 11 12func main() { 13\thttp.HandleFunc(\u0026#34;/\u0026#34;, Hand) 14\thttp.ListenAndServe(\u0026#34;0.0.0.0:8088\u0026#34;, nil) 15} 16 17func Hand(w http.ResponseWriter, r *http.Request) { 18\tquery := r.URL.Query() 19\tone := query.Get(\u0026#34;one\u0026#34;) 20\tnow := time.Now().Unix() 21\tfileName := strconv.FormatInt(now, 10) 22 23\tfile, err := os.OpenFile(BASE_DIR+fileName+\u0026#34;.txt\u0026#34;, os.O_RDWR|os.O_CREATE, 0666) 24\tif err == nil { 25\tfile.WriteString(one) 26\tfile.Close() 27\tw.Write([]byte(\u0026#34;ok\u0026#34;)) 28\t} else { 29\tw.Write([]byte(\u0026#34;open file error,\u0026#34;)) 30\tw.Write([]byte(err.Error())) 31\t} 32} 简单说一下逻辑，web会监听 8080 端口，当收到客户端的请求时，会在当前目录的 /data/ 下创建一个 当前时间戳.txt 文件，并把获取到的数据写入到文件中，并把结果返回到网页中\n先把代码编译成可执行文件，执行 go build -ldflags \u0026quot;-w -s\u0026quot; main.go，-ldflags \u0026ldquo;-w -s\u0026rdquo; 这个参数会自动优化代码，这样编译出来的可执行文件体积会变小。 先在本地运行一下看一下效果\n浏览器显示正确，再看一下data目录下有没有对应的文件\n文件也正常写入了，说明程序是没有问题的\n下面开始打包docker\n开始编写Dockerfile文件\n1FROM scratch 2 3WORKDIR /app 4 5VOLUME /app/data 6 7ADD main /app 8 9COPY data /app 10 11EXPOSE 8088 12 13CMD [\u0026#34;/app/main\u0026#34;] 打包docker镜像需要在一个镜像的基础上打包，scratch这个镜像是一个很特殊的镜像，是一个空的镜像，大小是0，这样我们打包出来的镜像会很小，如果使用Ubuntu作为基础镜像，打包出来的镜像体积会很大，因为Ubuntu镜像就要有60M+了。更多关于scratch可以查看这里。 用到的Dockerfile命令\nFROM 指定以哪个镜像为基础开始构建镜像 WROKDIR 指定我们docker中的工作目录，如果这个目录不存在，会自动创建 VOLUME 指定对外映射的目录 ADD 将本地的文件添加到docker中 COPY 和ADD命令相似也是将本地的文件添加到docker中 EXPOSE 指定对外映射的端口 CMD 在docker中执行命令，如果有多个CMD，只有最有一个生效 别的命令没什么特殊的，简单说一下ADD和COPY的区别，相同点都是讲文件复制到docker中，不同的是ADD命令功能更多，如果复制到文件是tar，zip等压缩文件时，ADD命令会自动解压缩，ADD还可以从网络上加载文件\nDockerfile文件写好了，下一步开始构建了 使用 docker build -t goweb .命令构建 goweb 是指定构建后镜像的名字 没有报错,说明构建完成\n可以在本地的镜像中看到刚才构建的镜像了，大小只有5.4M\n有了镜像开始创建容器 现在用户目录下新建一个 go_web 目录 使用docker run -idt --name goweb -v ~/go_web:/app/data -p 8088:8088 goweb命令创建容器 之前的文章已经介绍过了，不在赘述了，文章 传送门 看一下容器的运行情况\nwhat，为啥容器退出了，应该是出错了，看一下错误\n还记得前面画的重点吗，go编译后的二进制程序不依赖外外部库，其实这句话是错误的 看一下刚才编译的程序依赖那些外部库\n现在的main文件依赖4个外部文件，因为我们是基于scratch打包的，scratch是一个空白的镜像，没有这些文件，所以运行就报错了。有两种解决办法\n使用Ubuntu等有这些库的基础镜像，但是这样会增加打包后镜像的体积，很显然不划算 使用静态编译，把这些库编译进main文件中 重新编译go文件 先把原来的main改一个名字mv main main2 重新编译CGO_ENABLED=0 go build -ldflags \u0026quot;-w -s\u0026quot; main.go CGO_ENABLED=0 指定为静态编译 现在看一下main的外部依赖\n现在的main不依赖外部文件了 把之前的docker镜像和容器都删掉，重新打包docker，重新生成容器\n现在看一下 容器已经运行了，并且完成了端口映射 在浏览器中试一下\n看一下go_web目录\n在go_web目录中已经创建了文件，并且内容也正确写入了\n到这，自己打包docker镜像就完成了。\n","date":"2020-04-12T21:24:55Z","permalink":"https://lqxhub.github.io/posts/c3d3e563/","title":"docker学习3-打包一个docker镜像"},{"content":"操作docker容器，和操作linux差不多，都是使用命令行操作。不同的是，操作docker需要使用docker的命令。docker的命令和linux的命令很多相似的，也有一些不同。废话不多说，开始学习。docker命令分为镜像相关，容器生命周期相关，容器操作相关，仓库相关等一系列命令。是用docker命令时，前要加上 docker ，比如查看docker版本，在终端输入 docker version\n版本相关 version 查看docker的版本，能看到docker的client和server的版本 info 显示 Docker 系统信息，包括镜像和容器数。 可以看到，有两个容器，一个运行中一个停止。本地还有两个镜像\n本地镜像相关操作 images 查看本地所有镜像 rmi 删除本地一个或多少镜像。这个命令和linux的rm命令很像，可以使用 -f 强制删除\ntag 为本地镜像打一个标签，可以理解为重命名。 可以看到，使用tag命令给mysql加了一个标签，两个镜像的id是相同的，说明还是同一个镜像。使用rmi命令删除一个，另一个不受影响。\nbuild 命令用于使用 Dockerfile 创建镜像。这个命令比较复杂，有很多参数，而且需要配合Dockerfile文件使用\nhistory 查看指定镜像的创建历史。\n-H :以可读的格式打印镜像大小和日期，默认为true； \u0026ndash;no-trunc :显示完整的提交记录； -q :仅列出提交记录ID。 save 将本地的容器保存为一个文件。 已经把本地的redis 镜像保存到了当前目录\nload 导入使用 save 命令导出的镜像。 我们先把本地的redis镜像删除，再通过load命令把刚才导出的redis镜像再导入\nimport 也是从本地文件导入镜像。和load 不同的是，import 命令需要指定导入后的镜像的name和tag 先把原有的redis镜像删掉，再使用import命名导入镜像，并指定name和tag。一般import命令配合export命令使用\n容器仓库相关 search 在远程仓库中搜索相关的镜像。 在远程仓库中搜索mysql相关的镜像\npull 从远程仓库拉取镜像到本地，比如拉取mysql命令， docker pull mysql\n容器生命周期相关 run 创建一个新的容器并运行；run命令有很多参数，挑几个常用的介绍一个\n-d: 后台运行容器，并返回容器ID; -i: 以交互模式运行容器，通常与 -t 同时使用； -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用； \u0026ndash;name=\u0026ldquo;nginx-lb\u0026rdquo;: 为容器指定一个名称；注意这个前面是 \u0026ndash; -e: 设置环境变量；在用docker启动mysql的时候，会用到环境变量设置mysql的密码 -P: 随机端口映射，容器内部端口随机映射到主机的高端口，大写的P； -p: 指定端口映射，格式为：主机(宿主)端口:容器端口；比如使用docker运行nginx时，将容器的nginx80端口映射到主机的8080端口；-p 8080:80 -m :设置容器使用内存最大值； \u0026ndash;volume , -v: 将主机上的目录挂载到容器内；格式为：主机目录:容器内的目录 以运行mysql为例， 运行一个mysql容器，重命名为my_mysql，将容器的3306端口映射到主机的3366端口，并将mysql的存储目录*/var/lib/mysql* 挂载到用户目录的mysql_data目录下 start 启动一个容器，可以使用容器的id也可以使用容器的name\nstop 停止一个容器\nrestart 重启一个容器\nkill 杀死一个容器，和linux的kill命令很像，可以使用容器的name操作\npause 暂停容器中所有的进程。\nunpause 恢复容器暂停的进程。\ncreate 创建一个容器,但是不启动这个容器\nexec 在运行的容器中执行命令。可以看做是进入到这个容器中。\n-d :分离模式: 在后台运行 -i :默认打开，没有附加也保持STDIN 打开 -t :分配一个伪终端 使用命令 docker exec -it redis 进入name为redis 的容器中 容器操作相关 ps 列出当前机器上的容器\n-a:列出所有的容器，包括没有运行的容器 -f :根据条件过滤显示的内容 -n :列出最近创建的n个容器 -q :静默模式，只显示容器编号 top 查看容器中运行的进程信息，支持 ps 命令参数。\nlogs 获取容器的日志\n-f : 跟踪日志输出，和linux的 tail 的-f效果相同 \u0026ndash;since :显示某个开始时间的所有日志 -t : 显示时间戳 \u0026ndash;tail :仅列出最新N条容器日志 **port ** 列出指定的容器的端口映射，或者查找将PRIVATE_PORT NAT到面向公众的端口。\nexport 将容器导出为一个文件，和save命令相似，但是save命令操作的是镜像，export操作的是容器。save保存的文件没有丢失镜像的历史，可以回滚到之前。export 保存的文件再导入时会丢失镜像所有的历史，所以无法进行回滚 使用命令 docker export name \u0026gt; filename\ncommit 从指定容器创建一个新的镜像。\n-a :提交的镜像作者 -c :使用Dockerfile指令来创建镜像 -m :提交时的说明文字 -p :在commit时，将容器暂停 将mariadb 容器生成一个新的镜像 cp 在宿主机和容器之间复制文件。 将 a.txt 复制到 name为 mysql 容器的 var 目录 docker cp a.txt redis:/var\n","date":"2020-04-04T18:03:39Z","permalink":"https://lqxhub.github.io/posts/dff1cc87/","title":"docker学习2-docker基本命令"},{"content":"docker是当下是用的最多的虚拟化技术，那必须要学习一波。学习之前先搞清楚三个问题\n什么是docker docker解决了工作中的那些问题 理清楚docker中的几个概念 什么是docker 先解决第一个问题，docker到底是个啥玩意。docker是一种虚拟化技术，通俗的讲，docker类似一个虚拟机，可以虚拟出一个主机。在docker中，每个容器相互隔离，容器内的程序不能跨容器直接交互。容器之间可以通过网络或者共享文件交互。但是docker不是虚拟机，docker与虚拟机相比，docker是轻量级的，可以做到秒级启动，docker占用的系统开销也是很低的。用过虚拟的都知道，虚拟机启动很慢，而且会占用宿主机很大的内存和cpu资源。使用docker，几乎感觉不到docker的存在。\ndocker解决了工作中的那些问题 docker解决了工作中的那些问题。很多时候，由于开发环境和线上环境是不同的，比如在windows下开发，程序最终部署到linux上。很多时候，会因为依赖库的问题，导致程序运行报错。java，php，C++等这些程序，在开发环境中是正常的。但是在运行环境中，由于缺失运行所依赖的库，导致程序报错或者无法运行。当你费劲九牛二虎之力配置好运行环境时，老板告诉你，还有100台服务器需要配置，你是不是瞬间就奔溃了。\n使用docker就可以解决这个问题。只需要把要部署的程序打包成一个docker的镜像，然后在用docker把镜像生成容器，使用容器运行。再也不用配置运行环境了，不管有多少台机器，只需要把docker镜像导入，就可以非常简单的部署一台机器。docker为啥能做到呢，其实这个打包成镜像的过程，已经把运行程序必备的一些库，全都打包进镜像中了，当程序在容器中运行时，就不会因为环境的问题导致报错了。\ndocker中的几个概念 镜像(Images)：镜像是一个文件，是用镜像文件可以创建容器。比如我们装系统时，会用到windows的系统镜像，一般是一个**.iso** 文件，docker中的镜像这就是一个类似的文件。 容器(Container)： 容器是一个可以通过docker运行的实例，像我们装机完成后的系统一样。 仓库(Repository)：仓库是一个存放docker镜像的网站，类似一个网盘，这里保存着很多镜像，可以通过网络下载这些镜像 主机(Host)：一个物理机或者虚拟机，比如我们的电脑、云服务器。用于执行 Docker 守护进程和容器 客户端(CLient)：Docker 客户端通过命令行与 Docker 的守护进程通信。就是我们操作docker的工具 总结一下，镜像可以看做是面向对象中的 类，容器就是 对象，同样的，一个镜像也可以创建多个容器\n至于怎么安装docker，网上教程太多了，就不赘述了。建议在linux上安装docker，没有linux的可以在windows中装一个虚拟机，虚拟机装linux，然后在装docker。我就是这样弄的。\n","date":"2020-04-02T19:56:27Z","permalink":"https://lqxhub.github.io/posts/79efdaf8/","title":"docker学习1-基本概念"},{"content":"在排序中，经常遇到变量相同情况下的排序问题。在MySQL中可以使用 ORDER BY 约束多个字段。但是在redis中，使用sorted set排序时，score只能设置一个变量。这样在score相同时，只能使用字典序了（这个是从文档上看到的，具体没验证） 这就会出现一些问题了，最简单，在游戏排行榜中，我原来是排第一的，突然来了个人，分数和我相同，但是排到我前面了，我成第二了，玩家肯定不干了。但是redis只能使用一个值作为排序条件，这就需要我们在一个值里既能记录原有的分数，还要记录另一个值。\n比较常见的是用时间作为第二个排序条件，谁先达到这个分数，谁排在前面。 要实现这个功能，要满足 可逆 ，稳定排序 两个要求。\n可逆：把数值处理后还能到的原来的值（分数和时间） 稳定排序：添加时间后不能影响原来的排序结果，添加的时间只是在分数相同的情况下才起作用 简单的对数值进行加减乘除是没法实现的了，简单的数值加减乘除一是不能恢复原来的数据，二是会影响到原有的排序。\n不卖关子了，使用**‘或’运算，可以实现这个需求。把两个数值进行或**运算，生成一个数。简单说一下原理。 或 运算的规则是在二进制位上，有1 或 运算后还是1，两个都是0 或运算后是 0。 例：1或2 二进制表示 01|10 = 11。但是现在却发现，无法实现数据还原，这就需要移位了。就是两个8位长的数据，或 运算后要成为16位的数据。 还是上个例子：为了简单起见，假设原数据是2位长，先把原来2位长的数据转成4位长，然后左移2位，1就从原来的01变成了0111。2只变成4位，不移位。2从10变成0010。0100|0010 = 0110。这样就能还原数据了。前两位01是原来的1，后两位10就是原来的2。 下面通过代码来实现一下。 代码用golang实现\n1package main 2 3import ( 4\t\u0026#34;fmt\u0026#34; 5\t\u0026#34;math/rand\u0026#34; 6\t\u0026#34;sort\u0026#34; 7) 8 9func main() { 10\tarr := make([]uint64, 10) 11\tb := rand.Perm(10) 12\tfor i := 0; i \u0026lt; 10; i++ { 13\tvar a uint32 14\tif i%2 == 0 { 15\ta = 10 16\t} else { 17\ta = 5 18\t} 19\tarr[i] = uint64(a)\u0026lt;\u0026lt;32 | uint64(b[i]) 20\tfmt.Println(a, b[i], arr[i]) 21\t} 22\tsort.Sort(Myuint64(arr)) 23 24\tfmt.Println(\u0026#34;排序后\u0026#34;) 25\tfor _, v := range arr { 26\tfmt.Println(v, v\u0026gt;\u0026gt;32, uint32(v)) 27\t} 28} 29 30type Myuint64 []uint64 31 32func (this Myuint64) Len() int { 33\treturn len(this) 34} 35func (this Myuint64) Less(i, j int) bool { 36\treturn this[i] \u0026gt; this[j] 37} 38 39func (this Myuint64) Swap(i, j int) { 40\tthis[i], this[j] = this[j], this[i] 41} 简单说一下代码，第一排序条件用了间隔使用了5和是这两个数，第二条件随机生成了10个不重复的随机数，不用时间戳的原因是，程序运行的时间很短，取到的时间戳基本是一个数，看不出区别，本质思想都是一样的。 排序使用了go自带的排序接口\n代码中fmt.Println(v, v\u0026gt;\u0026gt;32, uint32(v)) 就是解数据，或 运算后，前32位是一个数，后32位是另一个数据。 取前面的数据只需要把计算后的数据右移32位就行了，取后面的数据，更简单了，直接强转成32位的类型就行了。 看一下运行结果：\n可以看到，排序前，10和5交替出现，第二条件没有规律 排序后，先使用第一个数排序，第一个数相同时，使用第二条件排序。而且我们也成功还原了原来的数据。 好了，这样就实现了用一个数值实现第二条件排序了。在存入redis时只需要把计算后的数据存入redis就行了，显示数据的时候，只需要解一下数据就行了。 好了，到这就介绍完了，有问题欢迎评论区讨论\n","date":"2019-11-24T22:07:45Z","permalink":"https://lqxhub.github.io/posts/f329a22f/","title":"使用一个字段实现第二条件排序"},{"content":"在面向对象编程的思想中，接口是一个非常重要的概念。按书上介绍的，使用接口，可以实现运行时多态、易维护、易拓展等等优点。拥有多年编程经验的人应该能理解这些话的含义，对于一个初学编程的萌新来说，看完这段话完全不知所云。那今天我用《英雄联盟》为背景，详细的分析一下接口在面向对象编程中的作用，以及使用接口的优势。\n这次使用java作为编写demo的语言，主要原因有两个：\njava是最流行的编程语言，基本上学过编程的都会java语言； java是一门对面向对象特性支持比较好的语言； 还记得我刚开始学习java的时候，就很不理解接口的作用，感觉接口有点多余。\n例如我定义了一个接口，但是我在实现这个接口的类中还要写接口的实现方法，那我不如直接就在这个类中写实现方法岂不是更便捷，还省去了定义接口\n相信不止我一个人有过这样的疑惑吧。 后来随着写代码，看阅读别人的代码，逐渐开始理解接口的作用了，慢慢觉得接口是一个非常方便和牛逼的东西。 教材上，网上解释接口的例子大多数使用定义一个Animal接口，然后Dog实现了这个接口，Cat实现了这个接口；还有一种用USB接口举例。大多数人看完还是一脸懵逼。 现在用一种新的方式——《英雄联盟》为背景介绍一下。 说了这么半天，开始进入正题吧。\n先圈两个重点： Java之所以要有接口，是因为java不支持多继承，使用接口，可以间接的实现多继承的一些特性；像C++就不存在接口这个东西，因为C++支持多继承 在面向对象的概念中，子类（派生类）可以自动转换为父类（基类）类型；也就是说，A类实现了接口B，那么A的实例化对象可以自动转换为B类型 1public class Main { 2 public static void main(String[] args) { 3 B a = new A(); 4 } 5} 6 7interface B { 8 9} 10 11class A implements B { 12 13} 这样的代码是正确的。\n开始demo部分，我们定义一个Skill接口，里面有 Q、W、E、R 四个方法，代表英雄的四个技能。为了简单，被动技能和召唤师技能就不写了。 然后从五个位置上单、打野、中单、ADC、辅助中各挑选一个英雄，作为例子。上路中我最喜欢的是锐雯，打野我玩的最多，纠结了半天选了盲僧。中单里必须选亚索，ADC里选择了暴走萝莉，辅助里选择了锤石。\n先上代码再解释：\n1//技能接口 2interface Skill { 3 void Q(); 4 5 void W(); 6 7 void E(); 8 9 void R(); 10} 11 12//放逐之刃-锐雯 13class RuiWen implements Skill { 14 15 public RuiWen() { 16 System.out.println(\u0026#34;断剑重铸之日,骑士归来之时\u0026#34;); 17 } 18 19 @Override 20 public void Q() { 21 System.out.println(\u0026#34;折翼之舞\u0026#34;); 22 } 23 24 @Override 25 public void W() { 26 System.out.println(\u0026#34;震魂怒吼\u0026#34;); 27 } 28 29 @Override 30 public void E() { 31 System.out.println(\u0026#34;勇往直前\u0026#34;); 32 } 33 34 @Override 35 public void R() { 36 System.out.println(\u0026#34;放逐之锋\u0026#34;); 37 } 38} 39 40//盲僧-李青 41class LiQing implements Skill { 42 43 public LiQing() { 44 System.out.println(\u0026#34;我用双手成就你的梦想\u0026#34;); 45 } 46 47 @Override 48 public void Q() { 49 System.out.println(\u0026#34;天音波/回音击\u0026#34;); 50 } 51 52 @Override 53 public void W() { 54 System.out.println(\u0026#34;金钟罩/铁布衫\u0026#34;); 55 } 56 57 @Override 58 public void E() { 59 System.out.println(\u0026#34;天雷破/摧筋断骨\u0026#34;); 60 } 61 62 @Override 63 public void R() { 64 System.out.println(\u0026#34;猛龙摆尾\u0026#34;); 65 } 66} 67 68//疾风剑豪-亚索 69class YaSuo implements Skill { 70 71 public YaSuo() { 72 System.out.println(\u0026#34;死亡如风,常伴吾生\u0026#34;); 73 } 74 75 @Override 76 public void Q() { 77 System.out.println(\u0026#34;斩钢闪\u0026#34;); 78 } 79 80 @Override 81 public void W() { 82 System.out.println(\u0026#34;风之障壁\u0026#34;); 83 } 84 85 @Override 86 public void E() { 87 System.out.println(\u0026#34;踏前斩\u0026#34;); 88 } 89 90 @Override 91 public void R() { 92 System.out.println(\u0026#34;狂风绝息斩\u0026#34;); 93 } 94} 95 96//暴走萝莉-金克斯 97class JinKeSi implements Skill { 98 99 public JinKeSi() { 100 System.out.println(\u0026#34;规则就是用来打破的\u0026#34;); 101 } 102 103 @Override 104 public void Q() { 105 System.out.println(\u0026#34;枪炮交响曲！\u0026#34;); 106 } 107 108 @Override 109 public void W() { 110 System.out.println(\u0026#34;震荡电磁波！\u0026#34;); 111 } 112 113 @Override 114 public void E() { 115 System.out.println(\u0026#34;嚼火者手雷！\u0026#34;); 116 } 117 118 @Override 119 public void R() { 120 System.out.println(\u0026#34;超究极死神飞弹！\u0026#34;); 121 } 122} 123 124//魂锁典狱长-锤石 125class ChuiShi implements Skill { 126 127 public ChiShi() { 128 System.out.println(\u0026#34;我们要怎样进行这令人愉悦的折磨呢\u0026#34;); 129 } 130 131 @Override 132 public void Q() { 133 System.out.println(\u0026#34;死亡判决\u0026#34;); 134 } 135 136 @Override 137 public void W() { 138 System.out.println(\u0026#34;魂引之灯\u0026#34;); 139 } 140 141 @Override 142 public void E() { 143 System.out.println(\u0026#34;厄运钟摆\u0026#34;); 144 } 145 146 @Override 147 public void R() { 148 System.out.println(\u0026#34;幽冥监牢\u0026#34;); 149 } 150} 代码有点多，但是很简单，写了5类，对应5个英雄。每个类的构造方法中，打印了这个英雄在排位中被选中时的台词。每个类都实现了skill这个接口，并重写了QWER这4个方法，在方法中打印了这个英雄技能的名称。 在main方法中初始化这5个英雄，并调用每个英雄的QWER这四个技能，代码：\n1public class Main { 2 public static void main(String[] args) { 3 //初始化锐雯释，放技能 4 Skill ruiWen = new RuiWen(); 5 ruiWen.Q(); 6 ruiWen.W(); 7 ruiWen.E(); 8 ruiWen.R(); 9 10 //初始化李青，释放技能 11 Skill liQing = new LiQing(); 12 liQing.Q(); 13 liQing.W(); 14 liQing.E(); 15 liQing.R(); 16 17 //初始化亚索，释放技能 18 Skill yaSuo = new YaSuo(); 19 yaSuo.Q(); 20 yaSuo.W(); 21 yaSuo.E(); 22 yaSuo.R(); 23 24 //初始化金克斯，释放技能 25 Skill jinKeSi = new JinKeSi(); 26 jinKeSi.Q(); 27 jinKeSi.W(); 28 jinKeSi.E(); 29 jinKeSi.R(); 30 31 //初始化锤石，释放技能 32 Skill chuiShi = new ChuiShi(); 33 chuiShi.Q(); 34 chuiShi.W(); 35 chuiShi.E(); 36 chuiShi.R(); 37 } 38} 注意一点： 我们在实例化这5个英雄时，这5个英雄都是Skill类型的\n看一下运行结果：\n可以看到，这5个英雄依次被实例化，并释放了QWER这4个技能。\n可能到这有的同学没看懂，这和接口有什么关系？接口带来了哪些好处？\n简单分析一下: 接口这个概念，其实就是定义了一种规范。在 Skill 这个接口中，定义了Q、W、E、R这四个方法，只要是实现了这个接口的类，一定会有这四个方法。 接口可以看做是实现多继承的一种方式（这样说可能不严谨）。java中没有多继承这种机制，失去了一些灵活性。但是去掉多继承后，语法简单了很多，像C++中，因为有多继承，又引入了虚继承的概念。说多了，回到正题。一个类实现一个接口后，可以看做是这个接口的子类，所以，我们在实例化英雄时（new Ruiwen()等），可以直接实例化为 Skill 类型的。 结合这两点，所以我们每一个Skill类型的对象，都可以调用 Q、W、E、R 这四个方法。 有人会提出疑问，我在每个类中都定义 Q、W、E、R 这四个方法不就行了。但是如何保证每个类里都有这四个方法呢？通过接口约束，可以保证，所有实现这个接口的类中，一定有这四个方法。\n再通过下面这个用法，看一下接口怎样实现多态的：\n1import java.util.Scanner; 2public class Main { 3 public static void main(String[] args) { 4 Skill hero; 5 Scanner scanner = new Scanner(System.in); 6 switch (scanner.nextInt()) { 7 case 1: 8 hero = new RuiWen(); 9 break; 10 case 2: 11 hero = new LiQing(); 12 break; 13 case 3: 14 hero = new YaSuo(); 15 break; 16 case 4: 17 hero = new JinKeSi(); 18 break; 19 case 5: 20 hero = new ChuiShi(); 21 break; 22 default: 23 hero = new RuiWen(); 24 } 25 26 hero.Q(); 27 hero.W(); 28 hero.E(); 29 hero.R(); 30 } 31} 简单看一下代码，定义了一个Skill类型的变量hreo。通过输入不同的值，来判断实例化哪一个英雄。最后调用英雄的 Q、W、E、R 方法。\n先输入 1 看一下，输入 1 应该是实例化锐雯这个英雄\n没有问题，输入1成功实例化了锐雯这个英雄，并调用了锐雯的四个技能。\n再换一个输入值看一下：\n这次输入了 2 ，实例化了李青这个英雄，并调用了李青的四个技能。\n使用了接口后的优势： 使用接口后，实现了运行时多态，也就是 hero 具体是哪个类的对象，在编译阶段我们是不知道的，只有当程序运行时，通过我们输入的值才能确定 hero 是哪个类的对象。\n使用了接口后，所有实现了 Skill 接口的类，都可以实例化为 Skill 类型的对象。如果不是这样，那有多少个英雄（类）就要定义多少个变量。现在英雄联盟有145个英雄，那就要定义145个变量，这。。。。\n总结： 接口的作用是定义了定义了一些规范（也就是定义了一些方法），所有实现了这个接口的类，必须要遵守这些规范（类中一定有这些方法） 一个类实现了一个接口， 可以看做 是这个接口的子类，注意是可以看做。子类类型可以自动转换为父类类型，所以任何出现接口的地方，都可以使用实现这个接口的类的对象代替。最常见的就是方法中传参，定义一个接口类型的变量，传入一个实现了接口的对象。 最后：文章是下班后半夜写的，加上自身能力有限，文中如有不正确的地方，欢迎评论区探讨，共同提高。\n","date":"2019-08-27T23:23:14Z","permalink":"https://lqxhub.github.io/posts/a96f0ff3/","title":"用《英雄联盟》解释一下面向对象中接口的作用"},{"content":"在看golang 的http服务部分代码时，被golang 中的 type func()写法难住了，一时没看懂代码。后来查资料后，有了一点理解。\n在golang中可以通过这样简单实现一个http服务\n1package main 2 3import \u0026#34;net/http\u0026#34; 4 5func mHttp() { 6\thttp.HandleFunc(\u0026#34;/\u0026#34;, h) 7\thttp.ListenAndServe(\u0026#34;0.0.0.0:8888\u0026#34;,nil) 8} 9func h(w http.ResponseWriter, r *http.Request) { 10 11} http.HandleFunc()是一个注册函数，传一个string类型的路由，和一个函数，函数的参数为(http.ResponseWriter, *http.Request)。跟踪进入函数，在golang 源码net/http/server.go文件中\n1func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { 2\tDefaultServeMux.HandleFunc(pattern, handler) 3} 在HandleFunc调用了 DefaultServeMux.HandleFunc(pattern, handler) 至于这些函数是干啥的先不做探讨，这不是本文的重点。 再次跟进函数\n1func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { 2\tif handler == nil { 3\tpanic(\u0026#34;http: nil handler\u0026#34;) 4\t} 5\tmux.Handle(pattern, HandlerFunc(handler)) 6} 在mux.Handle(pattern, HandlerFunc(handler)) 的第二个参数HandlerFunc(handler)是什么鬼。 跟进看一下\n1type HandlerFunc func(ResponseWriter, *Request) 2 3func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { 4\tf(w, r) 5} 原来HandlerFunc 是用 type 定义的函数，而函数的类型就是最开始传入的类型func(ResponseWriter, *Request) ServeHTTP是HandlerFunc的一个方法（注意一下，golang中方法和函数不是一回事）。并且HandlerFunc实现了 Handler接口 Handler接口定义:\n1type Handler interface { 2\tServeHTTP(ResponseWriter, *Request) 3} 回到HandleFunc方法中，mux.Handle(pattern, HandlerFunc(handler))的第二个参数是把传入的函数 handler 强转成 HandlerFunc类型，这样handler就实现了Handler接口。 到这我们明白HandlerFunc(handler) 是把普通函数强转成type定义的函数。 现在写一个简单的demo验证一下：\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tone(2, callback) 7} 8 9//需要传递函数 10func callback(i int) { 11\tfmt.Println(\u0026#34;i am callBack\u0026#34;) 12\tfmt.Println(i) 13} 14 15//main中调用的函数 16func one(i int, f func(int)) { 17\ttwo(i, fun(f)) 18} 19 20//one()中调用的函数 21func two(i int, c Call) { 22\tc.call(i) 23} 24 25//定义的type函数 26type fun func(int) 27 28//fun实现的Call接口的call()函数 29func (f fun) call(i int) { 30\tf(i) 31} 32 33//接口 34type Call interface { 35\tcall(int) 36} 先看一下程序的运行结果: 我们在 main() 函数中调用了 one() 函数，并传入了 callback() 函数，最终调用了我们传入的 callback() 函数。\n理一下思路： 使用 type 定义函数 func(int) 定义 Call 接口，Call中有一个函数 call(int) 在 main() 中调用 one(2, callback)，在 one() 中调用 two()，传入two() 函数前，对callback函数实现了类型转换，从普通函数转换成type定义的函数。 在 two() 中调用传入的 c 因为 c 实现了 Call 接口，所以可以调用 call() 函数，最终调用了我们传入的 callback() 函数。\n关于golang中 type func() 用法先分析到这吧，有不同的见解，欢迎评论区探讨 ","date":"2019-08-25T18:50:33Z","permalink":"https://lqxhub.github.io/posts/20b9663a/","title":"golang中 type func() 用法"},{"content":"今天在编译golang项目时,遇到了一个错误。编译器提示 cannot assign to m[1][1]\n原项目太大了，不贴了代码大体是这样的\n1package main 2 3func main() { 4\tm := make(map[int][2]int) 5\ta := [2]int{1, 2} 6\tm[1] = a 7 8\tm[1][1] = 3 9} 编译器提示，不能取到m[1][1]的地址。 但是使用 fmt 能打印出数值\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tm := make(map[int][2]int) 7\ta := [2]int{1, 2} 8\tm[1] = a 9 10\t// m[1][1] = 3 11\tfmt.Println(m[1][1]) 12} 打印结果 想了一下，go中的数组和切片(Slice)的和数组(Array)是不一样的，slice是引用传递，array是值传递。把 a 换成slice试一下 代码如下：\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tm := make(map[int][]int) 7\ta := []int{1, 2} 8\tm[1] = a 9 10\tm[1][1] = 3 11\tfmt.Println(m[1][1]) 12} 编译通过，没有问题。\n问题找到了，是因为值传递导致的问题，解决办法有三种 1 . 像上面一样，使用slice代替array。 2 . 不直接修改数组的值，修改值时，重新创建数组：\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tm := make(map[int][2]int) 7\ta := [2]int{1, 2} 8\tm[1] = a 9\tfmt.Println(m) 10 11\tb := [2]int{3, 4} 12\tm[1] = b 13\tfmt.Println(m) 14} 结果如下： 3 .使用指向数组的指针：\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tm := make(map[int]*[2]int) 7\ta := \u0026amp;[2]int{1, 2} 8\tm[1] = a 9\tfmt.Println(m[1]) 10 11\tm[1][1] = 3 12\tfmt.Println(m[1]) 13} 结果如下： 没有问题，可以修改值 在网上搜索没有找到深入点分析的文章，最终在stack overflow中找到了一个挺好的分析传送门 原文：\np[\u0026quot;HM\u0026quot;] isn\u0026rsquo;t quite a regular addressable value: hashmaps can grow at runtime, and then their values get moved around in memory, and the old locations become outdated. If values in maps were treated as regular addressable values, those internals of the map implementation would get exposed. 英文比较渣，大体看懂了一点意思。我理解的，应该是在程序执行过程中map的长度会变化，为了map值的正确，go语言不允许直接修改map中的值类型结构。\n在想另一种情况:\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tm := make(map[int]T) 7\tt := T{ 8\tOne: 1, 9\tTwo: 2, 10\t} 11\tm[1] = t 12\tfmt.Println(m) 13\tm[1].Two = 3 14\tfmt.Println(m[1]) 15} 16 17type T struct { 18\tOne int 19\tTwo int 20} 运行： 编译器提示同样的错误 换成指针后：\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tm := make(map[int]*T) 7\tt := \u0026amp;T{ 8\tOne: 1, 9\tTwo: 2, 10\t} 11\tm[1] = t 12\tfmt.Println(m[1]) 13\tm[1].Two = 3 14\tfmt.Println(m[1]) 15} 16 17type T struct { 18\tOne int 19\tTwo int 20} 运行： 先总结到这把，996确实有点累。早睡早起多搬砖 ","date":"2019-08-19T22:42:43Z","permalink":"https://lqxhub.github.io/posts/f0f408a8/","title":"golang cannot assign to XXX 错误"},{"content":"golang是一种强类型语言，虽然在代码中经常看到这种写法，i:=10这其实这是编译器自动做了类型推断在编译期间。编译器会对数据进行类型检查。不同类型的数据不能赋值,不能在函数中传参。强类型语言有一些优势，很多的错误会在编译期间被检查出来，不想php和python等弱类型语言，很多错误只有运行到才能被发现。同样，强类型也有一些缺点，写代码的时候要考虑数据类型了，失去了一些灵活性。\n言归正传，开始golang的类型转换问题 golang的类型转换和C/C++ java等语言的类型转换还有点区别\nC/C++等语言有隐式类型转换，golang中没有 golang中的类型转换分强制类型转换和类型断言 在C/C++中 1int main() 2{ 3 int a=5; 4 float b=3.5; 5 printf(\u0026#34;%f\u0026#34;,a*b); 6} 这样的代码是没有问题的,编译器隐式的把a向上转为float类型。 但是在golang中\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tvar a float32 = 5.6 7\tvar b int = 10 8\tfmt.Println (a * b) 9} 这样的代码会报错，因为类型不匹配 这时候需要强制类型转换\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tvar a float32 = 5.6 7\tvar b int = 10 8\tfmt.Println (a * float32(b)) 9} 这样就不会报错了 普通变量类型int,float,string 都可以使用 type (a)这种形式来进行强制类型转换,比如\n1var a int32 = 10 2var b int64 = int64(a) 3var c float32 = 12.3 4var d float64 =float64(c) golang中 指针也是有类型的,\n1package main 2 3func main() { 4\tvar a int = 10 5\tvar p *int =\u0026amp;a 6\tvar c *int64 7\tc= (*int64)(p) 8} 这样的代码是错误的,编译器会提示cannot convert p (type *int) to type *int64 指针的强制类型转换需要用到unsafe包中的函数实现\n1package main 2 3import \u0026#34;unsafe\u0026#34; 4import \u0026#34;fmt\u0026#34; 5 6func main() { 7 var a int =10 8 var b *int =\u0026amp;a 9\tvar c *int64 = (*int64)(unsafe.Pointer(b)) 10\tfmt.Println(*c) 11} golang中还有一中类型判断,类型断言\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tvar a interface{} =10 7\tswitch a.(type){ 8\tcase int: 9\tfmt.Println(\u0026#34;int\u0026#34;) 10\tcase float32: 11\tfmt.Println(\u0026#34;string\u0026#34;) 12\t} 13} 程序输出结果是int\n类型断言还有一种用法\n1package main 2 3import \u0026#34;fmt\u0026#34; 4 5func main() { 6\tvar a interface{} =10 7\tt,ok:= a.(int) 8\tif ok{ 9\tfmt.Println(\u0026#34;int\u0026#34;,t) 10\t} 11\tt2,ok:= a.(float32) 12\tif ok{ 13\tfmt.Println(\u0026#34;float32\u0026#34;,t2) 14\t} 15} t,ok:= a.(int)有两个返回值,第一个是对应类型的值,第二个是bool类型的,类型判断是否正确。\n好了，golang的强制类型转换写写到这，半夜困了，想到啥在补充吧。下次写一下golang中数字和字符串之间的转换\n","date":"2019-07-01T23:36:03Z","permalink":"https://lqxhub.github.io/posts/7395675/","title":"golang强制类型转换"},{"content":"在PHP日常开发中,经常需要处理前端上传来的图片,最简单的就是保存一下,有时候需要进行一些处理,比如压缩图片,生成缩略图等等 这些还好说,更坑的是,有时候前端上传的图片,服务端转存后,莫名其妙的旋转了90度,旋转了180度。关键是有的时候这些图片在前端显示是正常的,到服务端转存后,就出问题了,前端的同学表示不背这锅,这是你后端的问题!\n没办法,自己解决吧 PHP中有处理图片旋转的拓展exif，要处理图片旋转问题,必须安装这个拓展，exif拓展依赖php_mbstring这个拓展，所以要安装这两个拓展。 在phpinfo中能看到这两个拓展,就OK了。 如果没有安装，就需要手动安装一下了，只说Linux上怎么安装，Windows上一般都用WAMP，WAMP可以一键安装的。\nLinux推荐使用源码安装\n首先下载拓展的源码，可以去官网下载，我用的php7.2，可以在这里下载https://pan.baidu.com/s/1RmgFY3bAkyK_Yu636zrx3g 提取码: pm7y 编译安装 进入源码的目录 使用/usr/local/php/bin/phpize命令,生成configure（假设php安装在/usr/local/php目录下） 使用./configure --with-php-config=/usr/local/php/bin/php-config命令生成 Makefile文件 使用make \u0026amp;\u0026amp; make install命令编译安装 去修改php.ini文件(可能在**/usr/local/php/etc目录或者/etc/php/目录下),找到 extension 把 extension=mbstring和 extension=exif前面的;**去掉没有的加上这两句，把extension=mbstring放在extension=exif前面，保存退出 重启Apache或者nginx，查看phpinfo，有没有这两个拓展 准备工作OK了,可以开始写代码了，只写一下简单的逻辑代码吧\n1 $str = \u0026#39;文件路径\u0026#39;; 2 $savePath=\u0026#39;保存路径\u0026#39;; 3 $image = imagecreatefromstring(file_get_contents($str)); 4 $exif = exif_read_data($str); 5 6 if (!empty($exif[\u0026#39;Orientation\u0026#39;])) { 7 switch ($exif[\u0026#39;Orientation\u0026#39;]) { 8 case 8: 9 $image = imagerotate($image, 90, 0); 10 break; 11 case 3: 12 $image = imagerotate($image, 180, 0); 13 break; 14 case 6: 15 $image = imagerotate($image, -90, 0); 16 break; 17 } 18 imagejpeg($image, $savePath); 19 imagedestroy($image); 20 } Orientation中的值代表什么含义,我还没查到,等查到再补充吧，欢迎大佬评论区补充\n说一下遇到的坑 获取图片信息，在php7之前，用exif_imagetype()函数，在php7以后用exif_read_data()函数 一定要判断是获取到图片信息的数组中否存在Orientation字段，因为很多图片中没有没有这个属性，或者属性为空，一点要判断 ","date":"2019-03-29T10:53:57Z","permalink":"https://lqxhub.github.io/posts/9dd71679/","title":"PHP处理图片(orientation)旋转问题"},{"content":"HTTP协议中的POST 方法有多中格式的数据协议,在HTTP的head中用不同的Content-type标识.常用的有\napplication/x-www-form-urlencoded,这是最常见的,就是from表单的格式.在HTTP的head中是Content-Type: application/x-www-form-urlencoded.\nmultipart/form-data,这个是用来上传文件的,在HTTP的head中是Content-Type: multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW\nRaw 这个不是特别常用,传输的数据在HTTP的body中只有一段,不是以键值对的形式存放.在HTTP的head中是Content-Type: application/json,Content-Type: text,Content-Type: application/xml,Content-Type: text/xml,等等形式\n对于Content-Type: application/x-www-form-urlencoded这种form表单的数据,在php中,使用$_POST['name']可以直接获取, 没有什么特别的\nContent-Type: multipart/form-data; 这种格式的数据,在php中使用$_POST['name']可以获取字符数据,使用$_FILES['file']可以获取.\n对于Raw这种格式的数据,使用以上两种办法没有办法获取到,需要使用别的手段. 1.使用file_get_contents(\u0026quot;php://input\u0026quot;)获取;写一个简单php文件测试一下\n1\u0026lt;?php 2$test=file_get_contents(\u0026#34;php://input\u0026#34;); 3echo $test; 用postman测试一下 没问题,可以接收到\n2.使用$GLOBALS['HTTP_RAW_POST_DATA']接收\n1\u0026lt;?php 2$test=$GLOBALS[\u0026#39;HTTP_RAW_POST_DATA\u0026#39;]; 3echo $test; 用postman测试一下 卧槽,竟然出错了,提示没有发现HTTP_RAW_POST_DATA这个数组索引,什么鬼.Google一番,在php的官网看到了这样一段话 原来HTTP_RAW_POST_DATA这个在php5.6中已经被废弃了,在php7.0以后的版本中已经被删除了,我用的php版本为7.2,肯定就出错了\n好吧,那就老老实实的用file_get_contents(\u0026quot;php://input\u0026quot;)获取吧\n在实际开发中,一般都是使用框架的,我用thinkphp用比较多,在tp5.0中可以使用Request的getInput()函数获取Raw中的数据\n1\u0026lt;?php 2 3namespace app\\index\\controller; 4 5use think\\Request; 6 7class Index 8{ 9 public function index(Request $request) 10 { 11 echo $request-\u0026gt;getInput(); 12 } 13} 测试一下 没有问题,可以正常获取\n关于php获取HTTP POST数据的方法先介绍到这里\n","date":"2018-12-27T13:39:26Z","permalink":"https://lqxhub.github.io/posts/ba4d9bad/","title":"php 获取HTTP POST中不同格式的数据"},{"content":"在mysql中,多表连接查询是很常见的需求,在使用多表查询时,可以from多个表,也可以使用join连接连个表 这两种查询有什么区别?哪种查询的效率更高呢? 带着这些疑问,决定动手试试\n1.先在本地的mysql上先建两个表one和two one表\n1CREATE TABLE `one` ( 2 `id` int(0) NOT NULL AUTO_INCREMENT, 3 `one` varchar(100) NOT NULL, 4 PRIMARY KEY (`id`) 5) ENGINE = InnoDB CHARACTER SET = utf8; two表\n1CREATE TABLE `two` ( 2 `id` int(0) NOT NULL AUTO_INCREMENT, 3 `two` varchar(100) NOT NULL, 4 PRIMARY KEY (`id`) 5) ENGINE = InnoDB CHARACTER SET = utf8; 先随便插入几条数据,查询看一下;\n1select one.id,one.one,two.id,two.two from one,two where one.id=two.id; 1select one.id,one.one,two.id,two.two from one join two on one.id=two.id; 对比这两次的查询,查询时间几乎没有区别,查看sql运行分析,也没有区别\n为了突出两种查询的性能差异,往one表中插入100w条数据,往two表中插入10w条数据,在大量数据面前,一丝一毫的差别也会被无限放大;这时候在来比较一下差异\n先使用python往数据库中插入数据,为啥用python,因为python写起了简单 上代码\n1import pymysql 2 3db = pymysql.connect(\u0026#34;127.0.0.1\u0026#34;, \u0026#39;root\u0026#39;, \u0026#34;123456\u0026#34;, \u0026#34;bruce\u0026#34;) 4cursor = db.cursor() 5 6sql = \u0026#34;INSERT INTO one (one) values (%s)\u0026#34; 7for i in range(1000000): 8 cursor.executemany(sql, [\u0026#39;one\u0026#39; + str(i)]) 9 if i % 10000 == 0: 10 db.commit() 11 print(str(i) + \u0026#39;次 commit\u0026#39;) 12db.commit() 13 14print(\u0026#39;insert one ok\u0026#39;) 15sql2 = \u0026#34;INSERT INTO two (two) values (%s)\u0026#34; 16for i in range(100000): 17 cursor.executemany(sql2, [\u0026#39;two\u0026#39; + str(i)]) 18 if i % 10000 == 0: 19 db.commit() 20 print(str(i) + \u0026#39;次 commit\u0026#39;) 21db.commit() 22print(\u0026#39;insert two ok\u0026#39;) 耐心等待一会,插入需要一些时间;\n等数据插入完成,来查询一些看看 先使用FROM两个表查询\n1select one.id,one.one,two.id,two.two from one,two where one.id=two.id; 用时大约20.49;\n再用JOIN查询看一下\n1select one.id,one.one,two.id,two.two from one join two on one.id=two.id; 用时19.45,在10w条数据中,1秒的误差并不算大, 查看一下使用id作为条件约束时的查询 查询时间没有差别\n再看一下sql执行分析 结果还是一样的\n总结 在mysql中使用FROM查询多表和使用JOIN连接(LEFT JOIN,RIGHT JOIN除外),查询结果,查询效率是一样的\n","date":"2018-12-27T11:29:19Z","permalink":"https://lqxhub.github.io/posts/63c229e6/","title":"mysql使用 from两表查询与join两表查询区别"},{"content":"最近和学弟在调试一个GPRS通信模块,需求是通过GPRS模块通过http协议发送数据到服务器,但是http协议一直失败,服务器返回400,通过查询http状态码得知,http400错误是请求无效,因为GPRS模块没有实现http协议的封装,需要在TCP协议的基础上,手动拼装http格式的报文.所以初步猜测是http协议格式错误导致的.\n这时候,最简单有效的调错方式就是通过抓包分析,查看数据格式,然后修改.但是在GPRS模块上没法安装抓包工具,只能在服务器上抓包,服务器是centos的,虽然有tcpdump工具,但是没有界面,没法具体分析数据包. 直接使用tcpdump抓到的数据包,根本没法分析好不.\n在windows上,有wireshark这个工具,可以很方便的分析网络数据包,这个软件有多牛鼻就不用多说了,所有经过网卡数据都能抓到,配合图形界面,可以很方便的查看分析数据.不知能查看应用层协议的数据,网络中的五层协议都能查看. 有没有办法把tcpdump和wireshark这两个软件结合起来使用呢??? 办法当然是有的,把tcpdump抓取的数据转存文件,然后用wireshark打开文件,分析数据.\n1.开启tcpdump抓包,并将结果转存为文件 tcpdump tcp -s 0 port 80 -w ./http.cap 说一下这几个参数 tcp是指定抓取那种协议的数据,因为我们要抓取http协议,但是tcp不能指定http协议,但是http协议是基于TCP协议的,所以抓取TCP协议数据. -s 0 tcpdump 抓取数据包时默认抓取长度为68字节。加上-S 0 后可以抓到完整的数据包 port 80 我的服务器监听的80端口,所以只抓取80端口的数据. -w ./http.cap 指定tcpdump转存数据时的文件 ./http.cap是当前目录下的http.cap文件\n发起请求 在终端中使用 ctrl+c组合键结束抓包,然后会在当前目录下生成一个http.cap文件 3.把文件下载下来,使用tcpdump分析数据 在wireshark中,通过文件\u0026gt;打开 找到从服务器下载的http.cap文件,并打开 到这已经成功打开了,剩下的就是分析数据包了 在协议http的那一行右键,选择追踪流,然后选择http 到这,整个抓包就完成了,是不是很简单呢\n经过抓包分析,终于解决了http400的问题\n","date":"2018-12-16T10:54:33Z","permalink":"https://lqxhub.github.io/posts/a3fd02f/","title":"使用tcpdump+wireshark抓包分析网络数据包"},{"content":"为什么要加锁 多核计算机的出现,计算机实现真正并行计算,可以在同一时刻,执行多个任务。在多线程编程中，因为线程执行顺序不可控导致的数据错误。比如，多线程的理想状态是这样的 但是实际情况是这样的: 在网络编程中，在同一时刻，多个客户端同时请求同一个资源，如果不做控制，也会带来数据错误。比如在同一时间有10000人去抢10张火车票，10张火车票有可能会买给100个人，这显然是不符合要求的。 在多线程编程中,为了解决线程执行不可控带来的问题,通常情况下都是通过加锁来实现数据同步的。在网络编程中，也可以通过加锁机制来控制。\n在网络编程中，可以通过给数据库加锁，达到控制并发的目的。在php开发时，基本都是使用mysql作为数据库。所以，就会给mysql加锁控制网络并发引起数据错误问题。\nMySQL的存储引擎 不是要说MySQL的锁吗,怎么说上存储引擎了?因为MySQL存储引擎不同,锁也会不同。MySQL有MyISAM 和InnoDB两种存储引擎，现在主要使用InnoDB,所以主要介绍InnoDB下锁的使用。\nInnoDB引擎支持事务操作，使用事务可以保证多条sql语句执行的完整性(要不都成功,要不都失败)\n事务是由一组SQL语句组成的逻辑处理单元，事务具有4属性 原子性（Actomicity）：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。 一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以操持完整性；事务结束时，所有的内部数据结构（如B树索引或双向链表）也都必须是正确的。 隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然。 持久性（Durable）：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。 多个事务并发执行会带来新的问题 更新丢失（Lost Update）：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个 事务都不知道其他事务的存在，就会发生丢失更新问题——最后的更新覆盖了其他事务所做的更新。例如，两个编辑人员制作了同一文档的电子副本。每个编辑人员独立地更改其副本，然后保存更改后的副本，这样就覆盖了原始文档。最后保存其更改保存其更改副本的编辑人员覆盖另一个编辑人员所做的修改。如果在一个编辑人员完成并提交事务之前，另一个编辑人员不能访问同一文件，则可避免此问题 脏读（Dirty Reads）：一个事务正在对一条记录做修改，在这个事务并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”的数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做“脏读”。 不可重复读（Non-Repeatable Reads）：一个事务在读取某些数据已经发生了改变、或某些记录已经被删除了！这种现象叫做“不可重复读”。 幻读（Phantom Reads）：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。 曾经年少无知的我,以为使用事务就能保证并发情况下数据同步问题,后来的一次惨痛经历才明白了,事务不能保证并发情况的数据同步问题,需要事务和锁同时使用才能保证。\n锁的种类 乐观锁 机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。相对悲观锁而言，乐观锁更倾向于开发运用。 悲观锁 具有强烈的独占和排他特性。它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。 MySQL中锁的种类 乐观锁和悲观锁是一种思想,不是具体实现,在MySQL中,有锁的具体的实现方式 (文中的线程在MySQL中可以视作MySQL的连接)\n共享锁 一个线程在持有锁时,其他的线程可以查询被锁的数据,但是不能修改,不能删除。实现方式 SELECT * FROM table_name WHERE id =? lock in share mode; 排它锁 一个线程在持有锁时,其他的线程不能查询,不能更新,不能删除被锁的数据,直到锁被释放. \u0026gt; SELECT * FROM table_name WHERE id =? for update 总结一下:共享锁类似于java中的读锁,一个线程在持有乐观锁的时候,其他的线程也可以对被锁的数据进行读操作,但是不能对被锁的数据进行删除和更新操作;排他锁类似于java的写锁,一个线程持有写锁的时候,其他的线程不能再对被锁的数据进行任何查询,更新,删除操作。 重点 InnoDB的行锁是基于索引实现的,如果在查询中不使用索引,会锁表。 MySQL锁粒度 表级锁 是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MyISAM与InnoDB都支持表级锁定。表级锁分为表共享读锁与表独占写锁。 行级锁 是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。 共享锁的使用 注意: 下面的操作,都是行锁操作,MySQL为InnoDB引擎,id为自增主键 先创建一个测试表\n1CREATE TABLE `test` ( 2 `id` int(0) NOT NULL AUTO_INCREMENT, 3 `name` varchar(20) NOT NULL, 4 `number` bigint(0) NOT NULL, 5 `age` int(0) NULL, 6 PRIMARY KEY (`id`) 7) ENGINE = InnoDB; 看一下随便插入的几条数据 没有问题,使用共享锁看一下效果:\n开启事务 begin; 给id为1的数据加共享锁 mysql\u0026gt; select * from test where id=1 lock in share mode; 分别使用加锁和不加锁查询id为1 的数据 \u0026gt;都可以查询到数据 修改id为1 的数据看看 sql语句会一直停在这里,直到超时或者锁释放(事务提交或者回滚) 左边的事务提交后,右边的sql会执行,完成更新操作。\n同样,删除操作也会等待锁释放才能操作,这里就不演示了。\n再看一下另一种情况,左边锁住id为5的数据,右边更新id为1 的数据,不受影响。这就是行级锁，只会锁住相关的一行数据 排他锁的使用 还是使用test这张表\n开启事务begin; 给id1的数据加排他锁select * from test where id = 1 for update; 在右边查询id为1的数据 查询语句会一直等待,直到超时或者锁释放(左边commit或者rollback) 左边commit后 使用排它锁对id为5的数据加锁后,更新id为5的数据 sql语句同样会等待,直到超时或者锁释放,删除操作也是一样\n看一下对id为1的数据加锁,然后操作id不为1的数据的情况 没有问题,MySQL只是锁住了id为5的数据,其他的数据都可以操作。\n看一下InnoDB引擎锁表的情况 我们常常说InnoDB是行锁，但是这里介绍一下它锁表的情况。因为name列没有索引,所以,在加行锁的时候,MySQL不能加正常加行锁,会锁住整张表。 InnoDB行锁是通过索引上的索引项来实现的，这一点ＭySQL与Oracle不同，后者是通过在数据中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味者：只有通过索引条件检索数据，InnoDB才会使用行级锁，否则，InnoDB将使用表锁！ 在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。\n再看另一种情况 使用排它锁对id为1的数据加锁时,使用不加锁的查询和没有约束的查询时,一样可以立刻查询到数据。只有使用加锁的查询或者更新和删除时才会等待锁释放。\n总结 InnoDB的锁配合事务使用 MySQL有共享锁和排它锁 使用共享锁时,其他线程(连接)可以查询数据,但是不能更新和删除数据,使用排它锁时,不能查询数据不能更新数据,不能删除数据 MySQL的InnoDB引擎支持行级锁和表级锁,行级锁 InnoDB的行级锁是基于索引的,加锁是对索引加锁,加锁时没有索引时会锁住整张表 以上是我对MySQL锁的理解,文中如果有不正确的地方,还请各位大哥批评指正。\n","date":"2018-11-23T17:17:26Z","permalink":"https://lqxhub.github.io/posts/a8083c8/","title":"使用mysql中的锁解决高并发问题"},{"content":"mysql单表中数据量到达一定数量后,查询效率会变得很低,使用索引可以有效地提高mysql的查询效率.但是索引使用不当,会使索引失效,起不到提升效率的作用,在实际项目中,要做好索引的优化,合理的使用索引。关于索引的优化，可以参考这篇文章，传送门\n为了分析sql语句执行效率,使用explain 分析sql语句 使用explain关键字可以模拟优化器执行sql查询语句，从而得知MySQL 是如何处理sql语句。\n1+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------------+ 2| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | 3+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------------+ id select 查询的序列号，包含一组可以重复的数字，表示查询中执行sql语句的顺序。一般有三种情况： 第一种：id全部相同，sql的执行顺序是由上至下； 第二种：id全部不同，sql的执行顺序是根据id大的优先执行； 第三种：id既存在相同，又存在不同的。先根据id大的优先执行，再根据相同id从上至下的执行。\nselect_type select 查询的类型，主要是用于区别普通查询，联合查询，嵌套的复杂查询 **simple：**简单的select 查询，查询中不包含子查询或者union **primary：**查询中若包含任何复杂的子查询，最外层查询则被标记为primary **subquery：**在select或where 列表中包含了子查询 **derived：**在from列表中包含的子查询被标记为derived（衍生）MySQL会递归执行这些子查询，把结果放在临时表里。 **union：**若第二个select出现在union之后，则被标记为union，若union包含在from子句的子查询中，外层select将被标记为：derived **union result：**从union表获取结果的select\npartitions 表所使用的分区，如果要统计十年公司订单的金额，可以把数据分为十个区，每一年代表一个区。这样可以大大的提高查询效率。\ntype 这是一个非常重要的参数，连接类型，常见的有：all , index , range , ref , eq_ref , const , system , null 八个级别。 性能从最优到最差的排序：system \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; range \u0026gt; index \u0026gt; all 在代码中,若保证查询至少达到range级别或者最好能达到ref则算是一个优秀而又负责的程序员。 all：（full table scan）全表扫描无疑是最差，若是百万千万级数据量，全表扫描会非常慢。 index：（full index scan）全索引文件扫描比all好很多，毕竟从索引树中找数据，比从全表中找数据要快。 **range：**只检索给定范围的行，使用索引来匹配行。范围缩小了，当然比全表扫描和全索引文件扫描要快。sql语句中一般会有between，in，\u0026gt;，\u0026lt; 等查询。 **ref：**非唯一性索引扫描，本质上也是一种索引访问，返回所有匹配某个单独值的行。比如查询公司所有属于研发团队的同事，匹配的结果是多个并非唯一值。 **eq_ref：**唯一性索引扫描，对于每个索引键，表中有一条记录与之匹配。比如查询公司的CEO，匹配的结果只可能是一条记录， **const：**表示通过索引一次就可以找到，const用于比较primary key 或者unique索引。因为只匹配一行数据，所以很快，若将主键至于where列表中，MySQL就能将该查询转换为一个常量。 **system：**表只有一条记录（等于系统表），这是const类型的特列，平时不会出现，了解即可\npossible_keys 显示查询语句可能用到的索引(一个或多个或为null)，不一定被查询实际使用。仅供参考使用。\nkey 显示查询语句实际使用的索引。若为null，则表示没有使用索引。\nkey_len 显示索引中使用的字节数，可通过key_len计算查询中使用的索引长度。在不损失精确性的情况下索引长度越短越好。key_len 显示的值为索引字段的最可能长度，并非实际使用长度，即key_len是根据表定义计算而得，并不是通过表内检索出的。\nref 显示索引的哪一列或常量被用于查找索引列上的值。\nrows 根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数，值越大越不好。\nfiltered 一个百分比的值，和rows 列的值一起使用，可以估计出查询执行计划(QEP)中的前一个表的结果集，从而确定join操作的循环次数。小表驱动大表，减轻连接的次数。\nextra Using filesort： 说明MySQL会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。MySQL中无法利用索引完成的排序操作称为“文件排序” 。出现这个就要立刻优化sql。 **Using temporary：**使用了临时表保存中间结果，MySQL在对查询结果排序时使用临时表。常见于排序 order by 和 分组查询 group by。 出现这个更要立刻优化sql。 Using index： 表示相应的select 操作中使用了覆盖索引（Covering index），避免访问了表的数据行，效果不错！如果同时出现Using where，表明索引被用来执行索引键值的查找。如果没有同时出现Using where，表示索引用来读取数据而非执行查找动作。 **Covering Index：**覆盖索引也叫索引覆盖，就是select 的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select 列表中的字段，而不必根据索引再次读取数据文件。 Using index condition： 在5.6版本后加入的新特性，优化器会在索引存在的情况下，通过符合RANGE范围的条数 和 总数的比例来选择是使用索引还是进行全表遍历。 Using where： 表明使用了where 过滤 Using join buffer： 表明使用了连接缓存 impossible where： where 语句的值总是false，不可用，不能用来获取任何元素 distinct： 优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作。\n在查询中使用索引 先创建两个表\n1CREATE TABLE user 2( 3 id int(11) UNSIGNED AUTO_INCREMENT 4 PRIMARY KEY, 5 name char(10) NOT NULL, 6 age int NOT NULL 7) 8 ENGINE = InnoDB; 1CREATE TABLE phone 2( 3 id int(11) UNSIGNED AUTO_INCREMENT 4 PRIMARY KEY, 5 uid int(11) UNSIGNED NOT NULL, 6 phone char(10) NOT NULL 7) 8 ENGINE = InnoDB; mysql的主键带有一个主键索引,在创建表的时候已经建立 在简单地查询中使用索引\n1EXPLAIN SELECT name FROM user 这时候并没有使用索引,因为我们没有加限制条件\n1EXPLAIN SELECT name FROM user WHERE id=1 这时候索引已经起作用了,是const类型 再来看另一种情况\n1EXPLAIN SELECT id FROM user WHERE id+1 =2 这时候虽然使用了索引,但是索引类型是index类型,效果大打折扣\n给user表中的name字段加上索引\n1ALTER TABLE `user` ADD INDEX `_name`(`name`) USING BTREE; 使用LIKE模糊查询\n1EXPLAIN SELECT name FROM user WHERE name LIKE \u0026#39;王%\u0026#39; 可以看到,使用了索引,类型为range 换个匹配方式试试\n1EXPLAIN SELECT name FROM user WHERE name LIKE \u0026#39;%王\u0026#39; 这时候,虽然使用了索引,但是索引类型是index,全局索引扫描,效率是很低的.\n再来试一下OR连接查询\n1EXPLAIN SELECT id,uid FROM phone WHERE id=1 or id =2 使用了索引,是range类型 再来试一下 IN约束查询,这两次查询结果是相同的\n1EXPLAIN SELECT id,uid FROM phone WHERE id IN (1,2) 同样,使用了索引,是range类型\n再来试一下 OR查询的另一种情况\n1EXPLAIN SELECT id,uid FROM phone WHERE id = 1 OR uid=2 这时候会发现,竟然没有使用索引,type是ALL,因为这次OR的连个字段只有id有索引,uid没有索引,所以在查询的时候就会放弃使用索引,使用全局扫描. 这种情况是可以使用union 连接查询优化的\n1EXPLAIN SELECT id 2 FROM phone 3 WHERE id = 1 4 UNION ALL 5 SELECT uid 6 FROM phone 7 WHERE uid = 2 我们可以看到,在查询id时使用里索引,查询uid时,因为uid没有索引,所以没有使用索引. 再来看一下很常用的连接查询,\n1EXPLAIN SELECT user.id, name, uid, phone 2 FROM user 3 JOIN phone ON user.id = 1 AND uid = 2 (在使用连接查询的时候尽量使用join,不要使用left join 和 right join,在使用join查询的时候,mysql解析器会自动选择用小表驱动大表,这样可以提高查询效率,如果使用left join或者right join会指定驱动表,有时候会降低查询效率) 这时候只有在查询user表时使用了索引,在查询phone表时没有使用索引.因为在ON的约束条件中,id是有索引的,而uid没有索引,所以在查询的时候不会使用索引. 这时候给uid字段加上索引,看看效果. 添加索引\n1ALTER TABLE `phone` ADD INDEX `_uid`(`uid`) USING BTREE; 跟刚才一样,使用连接查询\n1EXPLAIN SELECT user.id, name, uid, phone 2 FROM user 3 JOIN phone ON user.id = 1 AND uid = 2 这时候可以看到,查询user表和phone表时,都使用了索引。\n总结 在有限制条件(WHERE,ON)的的查询中,对约束字段尽量都加上索引.在数据量很大的时候,提升查询效率特别明显 不要在约束条件上进行运算,在查询中对索引字段进行运算,会使用index索引,效果大打折扣 在使用LIKE 模糊匹配时,尽量用 'XXX%',不要使用'%XXX' 在经常删除、更新数据的字段和数据量不大的时候(网上说小于百万,因为我没有试验过,不能确定),没有必要使用索引,因为索引会占据磁盘空间,而且也会降低插入和更新数据的效率。 在查询中不会使用约束条件的字段也不用加索引,比如在例子中,从来没有对phone表中的phone字段使用过 WHERE和ON条件,所以没有必要给phone字段加索引。 查询中,使用OR约束条件时,OR两边的字段都必须有索引,如果只有一边的字段有索引,可以使用union连接查询提高效率。 在连接查询中，对两个表的关联字段加上索引，可以有效地提高查询效率。 NULL会导致索引形同虚设，所以在设计表结构时应避免NULL 的存在（用其他方式表达你想表达的NULL，比如 -1？） 最后感谢在网上无私分享的前辈们 我也是刚刚在学习mysql优化方面的知识,一边学习,一边总结,文中如果有错误的地方,还请各位大神批评指正\n","date":"2018-10-25T09:50:04Z","permalink":"https://lqxhub.github.io/posts/82773ef8/","title":"mysql使用索引提高查询效率"},{"content":"索引是一种特殊的文件(InnoDB 数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里的所有记录的引用指针。更通俗的说，数据库索引就好比一本书的目录，能够加快数据库的查询速度。 首先感谢网上的那些前辈和大神们的无私分享 最近在学习mysql的优化问题,在查询中正确使用索引,对查询效率的提升有非常大的帮助,使用不当会使索引失效,起不到索引该有的作用。把这两天学到的知识记录一下。\n使用索引的优势 提高数据的检索速度，降低数据库IO成本：使用索引的意义就是通过缩小表中需要查询的记录的数目从而加快搜索的速度。 降低数据排序的成本，降低CPU消耗：索引之所以查的快，是因为先将数据排好序，若该字段正好需要排序，则真好降低了排序的成本。 使用索引带来的问题 1.占用存储空间：索引实际上也是一张表，记录了主键与索引字段，一般以索引文件的形式存储在磁盘上。 2. 降低更新表的速度：表的数据发生了变化，对应的索引也需要一起变更，从而减低的更新速度。否则索引指向的物理数据可能不对，这也是索引失效的原因之一。\n索引的类型 1.normal： 表示普通索引,它没有任何限制，MyISAM 中默认的 B-tree 类型的索引 2.unique： 表示唯一的，不允许重复的索引，但是允许有空值。如果该字段信息保证不会重复例如身份证号用作索引时，可设置为unique。 3.full textl: 表示全文搜索的索引。 FULLTEXT 用于搜索很长一篇文章的时候，效果最好。注意仅 MyISAM 引擎支持 4.组合索引（最左前缀） 平时用的SQL查询语句一般都有比较多的限制条件，所以为了进一步榨取MySQL的效率，就要考虑建立组合索引。使用组合索引时注意最左匹配原则。 比如新建索引ALTER TABLE testADD INDEX 'id_name_age' ('id','name','age')。 在查询的时SELECT * FROM user WHERE id =1 AND name='bruce'索引起作用。 但是查询时SELECT * FROM user WHERE name='bruce' AND age = 18这时候索引不起作用。 至于原因,因为辅助索引是B+树实现的，虽然可以指定多个列，但是每个列的比较优先级不一样，写在前面的优先比较。一旦出现遗漏，在B+树上就无法继续搜索了（通过补齐等措施解决的除外），因此是按照最左连续匹配来的。既然是在B+树上搜索，对于条件的比较自然是要求精确匹配（即\u0026quot;=\u0026ldquo;和\u0026quot;IN\u0026rdquo;）。不过顺序倒是可以颠倒，因为查询优化器重排序一下就好了。\n索引的优化 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num is null,可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： select id from t where num=0 应尽量避免在 where 子句中使用!=或\u0026lt;\u0026gt;操作符，否则将引擎放弃使用索引而进行全表扫描。优化器将无法通过索引来确定将要命中的行数,因此需要搜索该表的所有行。 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num=10 or num=20 尽量避免在索引过的字符数据中，使用非打头字母搜索。这也使得引擎无法利用索引。 见如下例子： SELECT * FROM T1 WHERE NAME LIKE ‘%L%’ SELECT * FROM T1 WHERE SUBSTING(NAME,2,1)=’L’ SELECT * FROM T1 WHERE NAME LIKE ‘L%’ 应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描 应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引 总结 哪些情况需要建索引：\n1 主键，唯一索引 2 经常用作查询条件的字段需要创建索引 3 经常需要排序、分组和统计的字段需要建立索引 4 查询中与其他表关联的字段，外键关系建立索引\n哪些情况不要建索引：\n1 表的记录太少，百万级以下的数据不需要创建索引,数据量很少的时候,索引带来的提升不够明显 2 经常增删改的表不需要创建索引(在修改表的内容时，索引必须进行更新，有时可能需要重构，因此，索引越多，所花的时间越长。) 3 数据重复且分布平均的字段不需要创建索引，如 true,false 之类。(体现不出索引带来的价值) 4 频发更新的字段不适合创建索引(和2同理) 5 where条件里用不到的字段不需要创建索引(索引起不到作用)\n使用注意:\n性能优化过程中，选择在哪个列上创建索引是最重要的步骤之一。可以考虑使用索引的主要有两种类型的列：在where子句中出现的列，在join子句中出现的列。 考虑列中值的分布，索引的列的基数越大，索引的效果越好。 使用短索引，如果对字符串列进行索引，应该指定一个前缀长度，可节省大量索引空间，提升查询速度。 不要过度索引，只保持所需的索引。每个额外的索引都要占用额外的磁盘空间，并降低写操作的性能。 在修改表的内容时，索引必须进行更新，有时可能需要重构，因此，索引越多，所花的时间越长。 MySQL只对一下操作符才使用索引：\u0026lt;,\u0026lt;=,=,\u0026gt;,\u0026gt;=,between,in, 以及某些时候的like(不以通配符%或_开头的情形)。 再次感谢前辈们的无私分享 我也是在学习中,文中如有错误的地方,欢迎在评论区指出,方便共同学习\n","date":"2018-10-25T09:46:12Z","permalink":"https://lqxhub.github.io/posts/82773ef8/","title":"mysql索引的使用和优化"},{"content":"最近在做项目的时候用到了webSocket协议,而且是在微信小程序中用到了webSocket,微信小程序中使用wss协议的时候不能设置端口,只能使用默认的443端口。 我擦，我的https已经监听了443端口，webSocket再去监听443，肯定不行啊。要想办法解决，老大把这个问题交给我了，我愉快（手动懵逼）的接收了这个任务。想到了两种办法解决。 一种解决办法是把webSocket部署到另一台服务器上，这样成本也太高了。另一种办法，就是使用nginx反向代理。\n因为webSocket协议是基于http协议升级的（见下图），所以可以使用nginx反向代理webSocket. 从这张图片上可以看出，webSocket连接的建立是在http协议的基础上。\n1GET /chat HTTP/1.1 2Host: server.example.com 3Upgrade: websocket 4Connection: Upgrade 5Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw== 6Sec-WebSocket-Protocol: chat, superchat 7Sec-WebSocket-Version: 13 8Origin: http://example.com 熟悉HTTP的童鞋可能发现了，这段类似HTTP协议的握手请求中，只是多了几个东西。\n1Upgrade: websocket 2Connection: Upgrade 3这个就是Websocket的核心了，告诉Apache、Nginx等服务器：我发起的是Websocket协议。 4Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw== 5Sec-WebSocket-Protocol: chat, superchat 6Sec-WebSocket-Version: 13 首先，Sec-WebSocket-Key 是一个Base64 encode的值，这个是浏览器随机生成的，告诉服务器：泥煤，不要忽悠窝，我要验证尼是不是真的是Websocket助理。 最后，Sec-WebSocket-Version 是告诉服务器所使用的Websocket Draft（协议版本），在最初的时候，Websocket协议还在 Draft 阶段，各种奇奇怪怪的协议都有，而且还有很多期奇奇怪怪不同的东西，什么Firefox和Chrome用的不是一个版本之类的，当初Websocket协议太多可是一个大难题。。不过现在还好，已经定下来啦大家都使用的一个东西\n然后服务器会返回下列东西，表示已经接受到请求， 成功建立Websocket啦！\n1HTTP/1.1 101 Switching Protocols 2Upgrade: websocket 3Connection: Upgrade 4Sec-WebSocket-Accept: HSmrc0sMlYUkAGmm5OPpG2HaGWk= 5Sec-WebSocket-Protocol: chat 这里开始就是HTTP最后负责的区域了，告诉客户，我已经成功切换协议啦~\n1Upgrade: websocket 2Connection: Upgrade 依然是固定的，告诉客户端即将升级的是Websocket协议。至此，HTTP已经完成它所有工作了，接下来就是完全按照Websocket协议进行了。\n明白协议的原理了就可以下一步了\n首先nginx先配置好https的证书 服务器的证书是老大配置好的，我就直接用了。\n在nginx配置文件的service节点中添加如下配置\n1location /wss 2 { 3 proxy_pass http://127.0.0.1:8888; 4 proxy_http_version 1.1; 5 proxy_set_header Upgrade $http_upgrade; 6 proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; 7 proxy_set_header X-Real-IP $remote_addr; 8 } 解释一下参数 /wss这个是随便起的,告诉Nginx要代理的url,现在我的设置为wss,当我访问的我的服务器https://abc.com/wss时,Nginx会把我的请求映射到本机的8888端口。 proxy_pass 要代理到的url,我的代理到本机的8888端口。 proxy_http_version 代理时使用的 http版本。 重点来了: 代理webSocket的关键参数 proxy_set_header Upgrade 把代理时http请求头的Upgrade 设置为原来http请求的请求头,wss协议的请求头为websocket proxy_set_header Connection 因为代理的wss协议,所以http请求头的Connection设置为Upgrade proxy_set_header X-Real-IP 给代理设置原http请求的ip,填写$remote_addr 即可 至于websocket协议的response的参数，在反向代理的时候不用管。 到这里,Nginx反向代理webSocket的配置就完成了,重启Nginx,用websocket连接试试，在原来wss地址的地方填写wss://abc.com/wss。如果websocket成功连接,说明Nginx反向代理websocket已经成功了。\n总结 现在的配置只是反向代理到本机时的配置,如果要反向代理到别的主机,在代理时可能会跨域问题,需要在Nginx的反向代理中做跨域的配置。\n思考 在Nginx的配置文件中能看到这一段\n1location ~ .php$ { 2 root html; 3 fastcgi_pass 127.0.0.1:9000; 4 fastcgi_index index.php; 5 fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; 6 include fastcgi_params; 7} 这是Nginx中php的配置文件,我擦,怎么这么眼熟,这个配置清单跟刚才的websocket的反向代理这么像。通过上网查资料才知道，原来Nginx在处理php类型的请求时，把请求发fastcgi管理进程处理，fascgi管理进程选择cgi子进程处理结果并返回被nginx,而php-fpm是一个PHP FastCGI管理器,nginx本身不能处理PHP，它只是个web服务器，当接收到请求后，如果是php请求,则发给php解释器处理，并把结果返回给客户端。所以说Nginx在处理php类型的请求时,本质上也是通过反向代理功能实现的。 我们可以把思维展开，用Nginx反向代理可以实现更多的功能，比如代理Tomcat\n1location /Tomcat 2 { 3 proxy_pass http://127.0.0.1:8080; 4 proxy_http_version 1.1; 5 proxy_set_header X-Real-IP $remote_addr; 6 } 当然，也可以用Nginx反向代理实现负载均衡,这个我还没有试过,等以后用到了,再来补充\n","date":"2018-10-21T15:57:21Z","permalink":"https://lqxhub.github.io/posts/83c41ef3/","title":"nginx反向代理webSocket配置"},{"content":"最近想抓取手机上app的数据包,在电脑上抓包可选的工具有很多, 比如wireshark,Linux命令行下有tcpdump等等工具。可是在这些工具在手机上都没法使用，这怎么搞!\n后来想了想能不能用网络代理抓包呢,说干就干。从网上查到，用fiddler可以代理手机的网络。\n第一步下载fiddler 去下载一个fiddler，建议去官网下载传送门。 勾选协议,填写邮箱,然后下载就可以\n第二步安装fiddler 双击下载的.exe文件,然后选择目录,next,next,完成安装 ##第三步安装CertMaker插件 fiddler默认生成的证书不能满足Android和iOS系统的要求,需要使用这个插件 传送门 往下找,找到图片的地方,点击下载,下载后,双击安装\n第四步配置fiddler代理 想要抓HTTPS的数据包,必须安装证书, 点击tools-\u0026gt;options,然后出现这个界面,按照我标注的1,2,3,4都勾选,中间会出现一些提示,都点 yes 最后出现这个对话框说明证书已经安装成功。\n第五步配置代理(手机和电脑在同一个网络中) 重启fiddler，开始手机的配置。查看电脑的IP地址,我的是192.168.31.56然后打开手机的浏览器(苹果手机一定要用Safari),输入IP地址:端口号 我的是192.168.31.56:8888 这个根据具体情况设置 下载证书,点击允许,安装证书.\n重点、重点、重点 这时候一定要把安装的证书设置为信任的证书 去手机的设置-\u0026gt;通用-\u0026gt;关于本机-\u0026gt;证书新人设置,把刚才安装的证书设置为信任的证书。再去网络设置中,给WiFi设置代理(电脑和手机一定在同一个网络中) 然后打开手机上的app,在fiddler中就可以看到,http的数据了,打开一个HTTPS的连接,可以看到,数据是没有加密的 这时候如果没有抓到数据包,或者错误,应该是证书配置有问题,把之前的证书清除,按照步骤重新配置一遍.重启fiddler,重新在手机安装证书. 总结 fiddler代理可以抓到大多数的数据包,但不是所有的数据包都能抓到。fiddler并不支持全部协议，目前已知的有http2、tcp、udp、websocket等，如果应用走了以上协议，那么fiddler肯定是抓不到的。因为fiddler是基于.net framework实现的，因为.net framework不支持http2，所以fiddler无法抓取http2。 还有一种情况,app使用自带的证书,我们给手机安装的证书,app不信任.这样也是无法抓到的。fiddler抓包的原理是中间人攻击，也就是说，两头瞒，欺骗客户端\u0026amp;\u0026amp;欺骗服务器端，如果https证书写死在app里，app只信任自己的证书，fiddler没法瞒客户端了，因此fiddler也就抓取不到包了。\n","date":"2018-10-21T15:55:05Z","permalink":"https://lqxhub.github.io/posts/46c7ea4a/","title":"使用fiddler在手机上抓HTTPS包"},{"content":"看到标题是不是有点懵，在Android手机上搭建一个http服务器？？？ 没错，我们就是要在Android手机上搭建一个http服务器。提到http服务器一般第一反应是Apache，nginx Android上也能运行Apache，nginx了？？？ Android手机上当然不能运行这些服务器了，这次在Android上运行的是用Golang写的一个简单的http服务器。因为Golang可以跨平台编译，我尝试着把系统选择成Linux，CPU架构选择arm，然后在手机上运行，然后Android手机上真的运行起了一个http服务器! 惊喜 回到正题，要想开发编写golang，首先要配置好golang的开发环境\n我是在Ubuntu下开发的，新建service.go文件\n1package main 2 3import ( 4 \u0026#34;net/http\u0026#34; 5 ) 6 7func main() { 8 http.HandleFunc(\u0026#34;/\u0026#34;,myResponse) 9 http.ListenAndServe(\u0026#34;127.0.0.1:8888\u0026#34;,nil) 10} 11 12func myResponse(w http.ResponseWriter,r* http.Request) { 13 w.Write([]byte(\u0026#34;\u0026lt;html\u0026gt;\u0026lt;center\u0026gt; \u0026lt;font size=\\\u0026#34;40\\\u0026#34;\u0026gt;hello I am go service\u0026lt;/font\u0026gt;\u0026lt;/center\u0026gt;\u0026lt;/html\u0026gt;\u0026#34;)) 14} 不熟悉go的同学注意下，不要随意回车换行 不要随意回车换行 不要随意回车换行 因为go有点像Python，不是用 “;” 结束的 简单解释一下\nhttp.HandleFunc(\u0026quot;/\u0026quot;,myResponse) 第一个参数是注册http服务的URL，这里我们填写 \u0026quot;/\u0026quot;, 在访问的时候直接 localhost:8888 就行了，如果填 \u0026quot;/test\u0026quot; 访问的时候URL为localhost/test:8888\u0026quot;\nhttp.ListenAndServe(\u0026quot;127.0.0.1:8888\u0026quot;,nil) 第一个参数是要监听的ip和端口，第二个填 nil 就好了\n然后编译运行试试，在本机上运行的程序用默认的编译参数就行 go build service.go\n然后运行 ./service 在浏览器中输入URL，成功访问到 下一步我们把这个程序移植到Android上，Android手机必须要有root权限，手机没有root，而又不想root的同学可以用模拟器，只要CPU的指令集参数改一下就行，先在手机上运行一下，我的手机是荣耀6，CPU是海思920，百度到海思920的指令集是arm32的，好的，编译一个 在编译之前我们先修改一下刚才编译的程序的名\n执行 GOOS=\u0026quot;linux\u0026quot; GOARCH=\u0026quot;arm\u0026quot; go build service.go 得到一个可执行文件，用 file 命令看一下 file service\n1service: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV), statically linked, not stripped 我们看到这个文件是一个32位的arm程序。ok，复制的Android手机上试试 需要用到的软件\n“juiceSSH” 是用来模拟Linux的shell命令的，“RE文件管理器” 用来修改文件的权限，在Android上chmod命令不起作用。 先复制到根目录，然后修改文件的权限\n然后在juiceSSH里运行，然后去浏览器输入URL看看，\n没问题 接下来编译一个模拟器上的，我用的genymotion，运行的是Google nexus5手机系统，我百度了一下，nexus5用的是高通骁龙800CPU，然后坑来了，骁龙800是arm32的指令集，按理说直接把那个程序复制进去就可以运行了，但是提示 /system/bin/sh: ./service_arm32: not executable: 32-bit ELF file\n后来想了想CPU用的是电脑上的，那编译成 X64 的试试。还是不行，换成 X86 的试试。终于成功了。原来是指令要用电脑CPU的，多少位需要模拟器的。\n执行 GOOS=\u0026quot;linux\u0026quot; GOARCH=\u0026quot;386\u0026quot; go build service.go\n复制到模拟器中，然后跟在手机一样，复制到根目录，添加权限。然后用adb shell运行，然后在模拟器的浏览器中发现可以访问 好了，我们已经在Android上运行一个http服务器了，是不是比较简单\n","date":"2018-04-08T19:48:03Z","permalink":"https://lqxhub.github.io/posts/b60bc963/","title":"Android手机上搭建一个http服务器"},{"content":"因为想玩Linux，遂装了Ubuntu和win10的双系统，安装还好，一切顺利，两个系统都能正常启动，但是有一点让我非常不爽。就是启动的时候Ubuntu是默认启动项，开电脑一不注意就进Ubuntu了。额，重启吧\u0026hellip;\u0026hellip;\n默认的启动项顺序(图片是我盗的，因为我的已经改了) 有没有办法能改一下启动顺序呢？方法当然有了。因为用的是grub2引导，所以上网查了这方面的资料，没找到合适的，要不就是grub1的资料，要不就是治标不治本。所以本着大不了重装系统的心态，自己捣鼓\n第一种方法，只更改默认选项 首先进入 /etc/default 目录，执行sudo vim grub 正常的话你看到的是这个 1 6 GRUB_DEFAULT=\u0026#34;0\u0026#34; 2 7 #GRUB_HIDDEN_TIMEOUT=\u0026#34;0\u0026#34; 3 8 GRUB_HIDDEN_TIMEOUT_QUIET=\u0026#34;true\u0026#34; 4 9 GRUB_TIMEOUT=\u0026#34;10\u0026#34; 5 10 GRUB_DISTRIBUTOR=\u0026#34;`lsb_release -i -s 2\u0026gt; /dev/null || echo Debian`\u0026#34; 6 11 GRUB_CMDLINE_LINUX_DEFAULT=\u0026#34;quiet splash\u0026#34; 7 12 GRUB_CMDLINE_LINUX=\u0026#34;\u0026#34; 这是我们关注的内容，只需要把第6行的GRUB_DEFAULT=\u0026quot;0\u0026quot;改成你想要默认选中的序号减去1就行，比如第一张图中，想要默认选中Windows boot manger，修改GRUB_DEFAULT=\u0026quot;2\u0026quot;保存，退出 然后执行关键的一步sudo update-grub 这样，下次开机的时候默认选中的启动项就是Windows了。\n这样的操作对于我这种强迫症晚期的人来说是绝对不能忍的。必须把Windows boot manger 放到第一位，下面就是第二种方法\n第二种方法，彻底解决 首先进入*/boot/grub目录，先把grub.cfg文件复制一份出来，以免搞坏了没法恢复。然后查看 grub.cfg文件的读写权限，默认是只读的。先给grub.cfg文件加上可写的权限。 执行sudo chmod u+w grub.cfg 这样能修改这个文件了。 然后sudo vim grub.cfg打开这个文件。然后你会发现这个文件有300多行，这怎么修改，不要慌在vim里搜索menuentry* (搜索menuentry的命令是“/menuentry”) 我的在134行。上图 这时候再往下找直到找到\n1276 menuentry \u0026#39;Windows Boot Manager (on /dev/sda1)\u0026#39; --class windows --class os $menuentry_id_option \u0026#39;osprober-efi-78EE-BE29\u0026#39; { 2277 insmod part_gpt 3278 insmod fat 4279 set root=\u0026#39;hd0,gpt1\u0026#39; 5280 if [ x$feature_platform_search_hint = xy ]; then 6281 search --no-floppy --fs-uuid --set=root --hint-bios=hd0,gpt1 --hint-efi=hd0,gpt1 --hint-baremetal=ahci0,gpt1 78EE-BE29 7282 else 8283 search --no-floppy --fs-uuid --set=root 78EE-BE29 9284 fi 10285 chainloader /EFI/Microsoft/Boot/bootmgfw.efi 11286 } 12287 set timeout_style=menu 13288 if [ \u0026#34;${timeout}\u0026#34; = 0 ]; then 14289 set timeout=10 15290 fi 然后把这一段剪切，放到刚才134那个menuentry前边。这时保存，退出。 OK，完成了，下次开机就会发现Windows boot manger 成为第一启动项了\n这里千万不要 千万不要 千万不要 执行sudo update-grub\n下次开机就是这样了 ","date":"2018-03-25T12:39:52Z","permalink":"https://lqxhub.github.io/posts/fcd83655/","title":"修改Ubuntu和win10双系统启动顺序"},{"content":"指针无疑是C/C++语言的精髓所在，用好了是把利剑，用不好就是一颗炸弹。指针出BUG了，分分钟会让你写程序崩溃 今天被C++的指针搞混了，翻阅了很多资料，有点懂了。赶快来做一下笔记。\n先来使用一个最简单的指针\n1\tint a = 10; 2\tint *p=\u0026amp;a; 这个没啥难度不会出错，接下来来个难点的\n1\tint a = 10; 2\tint *p = \u0026amp;a; 3\tint **p1 = \u0026amp;p; 这个指针的指针是不是已经头皮发麻了，别急，还有更变态的——指针数组，数组指针，函数指针，指针函数。这回是不是彻底懵了。 现在就开始一个个使用这些指针 首先要明确一点，指针数组和数组指针不是一个概念\nint *p3[10]; 这就定义了一个指针数组， [] 优先级高，先与p结合成为一个数组，再由int*说明这是一个整型指针数组，它有10个指针类型的数组元素\nint (*p4)[10]; 这是一个数组指针，因为()优先级高，首先说明p是一个指针，指向一个整型的一维数组，这个一维数组的长度是10\nint* fun(int a); 这样就声明了一 个指针函数，就是返回指针的函数，函数可以不返回任何值，也可以返回整型值，实型值，字符型值，当然也可以返回指针值。函数fun需要在函数体中返回一个int型的指针。\nint (*fun)(int a); 这样就定义了一个指向函数的指针，可以通过这个指针来调用函数，注意，这个指针不能指向任意的函数，只能指向返回值是int，并且只有一个形参的函数。 这些都是C中指针的使用，到了C++中，指针遇到类和对象，遇到new和delete这两个运算符，稍有不慎就会内存泄漏。 说了这么多，现在开始研究C++中指针的使用问题 先来新建一个Test类 Test.h\n1#pragma once 2class Test 3{ 4public: 5\tTest(); 6\tTest(int _a); 7\t~Test(); 8\tint a; 9}; Test.cpp\n1#include \u0026#34;stdafx.h\u0026#34; 2#include \u0026#34;Test.h\u0026#34; 3#include \u0026lt;iostream\u0026gt; 4using std::cout; 5using std::endl; 6 7 8Test::Test():Test(0)//委托构造函数 9{ 10\tcout \u0026lt;\u0026lt; \u0026#34;调用委托构造函数给a赋值 0\u0026#34;\u0026lt;\u0026lt;endl; 11} 12 13Test::Test(int _a=10):a(_a)//构造初始化,形参默认值=10 14{ 15\tcout \u0026lt;\u0026lt; \u0026#34;call function Test(int _a) \u0026#34;\u0026lt;\u0026lt;endl; 16} 17 18 19Test::~Test() 20{ 21\tcout \u0026lt;\u0026lt; \u0026#34;delete Test \u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; 22} main.cpp\n1// main.cpp: 定义控制台应用程序的入口点。 2// 3 4#include \u0026#34;stdafx.h\u0026#34; 5#include \u0026#34;Test.h\u0026#34; 6#include \u0026lt;stdlib.h\u0026gt; 7 8int main() 9{ 10\t/*1 11\t创建Test的实例，指针t1指向实例*/ 12\tTest *t1 = new Test(6); 13 14\tdelete t1; 15\tt1 = nullptr; 16 17 18\t/*2 19\t创建3个test实例数组 指针t2指向数组的第一个元素, 20\t此时只能调用Test类的无参构造函数*/ 21\tTest *t2 = new Test[3]; 22 23\tdelete[] t2;//释放 test的三个实例 24\tt2 = nullptr; 25 26\t/*3 27\t在堆中创建3个（Test）类型的指针数组，t3指向这个数组；*/ 28\tTest* *t3 = new Test*[3]; 29\tfor (int i = 0; i \u0026lt; 3; i++) 30\t{ 31\t/*创建3个Test的实例，让t3数组中的元素（指针）指向创建的对象*/ 32\tt3[i] = new Test(i + 10); 33\t} 34 35\tfor (int i = 0; i \u0026lt; 3; i++) 36\t{ 37\t/*释放 在堆中创建的三个Test的实例*/ 38\tdelete t3[i]; 39\t} 40 41\tdelete[] t3;//释放动态创建的指向Test实例的指针数组 42 43 44\tsystem(\u0026#34;pause\u0026#34;); 45\treturn 0; 46} 先来开一下最简单的一种对象指针Test *t1 = new Test(6); 这时定义了一个Test类型的指针t1，并让这个指针指向从堆中申请的内存（Test的实例）运行以下看看\n没意外，Test的实例正常创建，正常释放了。 再来看一下第二种情况\n1Test *t2 = new Test[3]; 2 3delete[] t2; 现在定义了一个Test的指针t2，并且在堆中创建了3个Test的实例，放在一个数组中，指针t2指向了这个数组。运行看一下 这时有一点要注意一下，这样new创建对象时只能调用Test类的默认无参构造函数，其他的函数不能调用。我们为了给a赋值，使用了委托构造函数（不太熟悉的同学可以忽略），从打印的结果来看，程序正常创建了Test的实例，也正常释放内存。 现在来看一下最复杂的一种情况\n1/*3 2在堆中创建3个（Test）类型的指针数组，t3指向这个数组；*/ 3Test* *t3 = new Test*[3]; 4\tfor (int i = 0; i \u0026lt; 3; i++) 5\t{ 6\t/*创建3个Test的实例，让t3数组中的元素（指针）指向创建的对象*/ 7\tt3[i] = new Test(i + 10); 8\t} 9 10\tfor (int i = 0; i \u0026lt; 3; i++) 11\t{ 12\t/*释放 在堆中创建的三个Test的实例*/ 13\tdelete t3[i]; 14\t} 15 16\tdelete[] t3; 是不是已经晕倒在电脑前了0.0 莫慌,先看一下运行结果 一步步来分析以下代码，首先看一下Test* *t3 = new Test*[3];t3是一个指针，它指向了堆中的一个数组，这个数组的类型是Test*的。 new Test*[3]在堆内存中创建了一个长度为3的Test*的数组。重点t3指向的是堆中的一个数组 第一个for循环中的t3[i] = new Test(i + 10);是给t3所指向的数组中的元素赋值，因为数组是Test*类型的，所以可以指向Test类的实例。 第二个for循环中delete t3[i];是把在堆内存中创建的Test 类的实例释放。因为t3[i]是一个指针，而且是指针数组，也就是说t3[i]，是t3指针指向的数组（在堆内存中）的一个元素，所以要把t3指向的数组释放delete[] t3;\n好了先总结到这吧。项目我已经上传到码云，需要的可以下载。\n","date":"2017-11-09T17:10:42Z","permalink":"https://lqxhub.github.io/posts/4835beb2/","title":"花式使用C/C++的指针"},{"content":"工欲善其事，必先利其器。要想进行Android NDK开发首先我们载NDK的开发包，配置NDK开发环境，就像配置SDK差不多。配置NDK环境的方法有很多，可以去官网下载，也可以用SDK manger下载安装，还可以用Androidstudio的SDK管理下载。\n下图是在AS下安装NDK 红色标记的选项，可能排列的顺序不同，找到然后勾选，点击OK，等待下载完成。说一下这三个工具是干啥的吧。\nCMake是一个跨平台的编译工具，可以用简单的语句来描述所有平台的编译过程。 LLDB是用来调试C++代码的工具 NDk 不用多说了，用来编译和打包C++的一整套工具 这里要说一个坑，AS的下载是不支持断点的，一定要在良好的网络环境下载，要不然。。。。说多了都是泪，让校园网害苦了，最后用下载工具下载的压缩包。网络不好的情况下可以把下载链接提取出来，用下载工具下载，这样就不怕断网了。 AS下载完成会自动解压，自己下载的要解压到SDK的目录下，新建ndk-bundle文件夹。只要setting中的SDKTools下这三项打钩了就说明环境搭建成功了。\nLinux NDK压缩包下载地址 https://dl.google.com/android/repository/android-ndk-r15c-linux-x86_64.zip\n我用的是Ubuntu系统，没找到SDK manger，就不介绍了，我记得Windows里有这个东西，界面和as里差不多，大同小异。 还有就是去官网下载，选择适合自己系统的版本下载，然后解压到指定目录就行了 网速好的话还是推荐使用AS去安装NDK，毕竟简单，下载完成会自己解压到指定目录。自己下载压缩包如果没有解压到指定目录是无法使用的。 等一切都弄好以后，打开界面看到CMake，LLDB ，NDK都勾选了就说明配置成功了。 还有就是CMake，LLDB 只能通过AS下载，别的还没找到，这两个比较小，很快就下完了。\n到此环境搭建就算完成了。\n","date":"2017-09-10T19:03:48Z","permalink":"https://lqxhub.github.io/posts/ddb43708/","title":"Android NDK开发之环境搭建"},{"content":"这两天在Android中用到了自定义view，在自定义view时也顺便使用了下自定义属性。自定义属性以前只是耳闻 未曾谋面，这次借机会对自定义属性进行了一番学习，顺便总结了一下自定义属性的使用。 下面扫盲班老司机要开车了，小白快刷卡上车，大神拒载。\nAndroid中经常用到自定义view，既然用了自定义view那就不得不提自定义属性。你是否思考过为什么我们在xml文件中进行布局时可以直接通过android:layout_width=\u0026quot;match_parent\u0026quot;就可以设置控件的宽度呢？不只是宽度，几乎控件的所有属性都可以在xml文件中进行设置，这是怎样实现的呢，this is a question 我们自定义view时能不能也像系统提供的控件一样在xml文件中设置属性呢。答案是当然可以了，用到的就是今天要说的自定义属性。废话不多说 直接开干。 1，首先在res 的values文件夹下新建一个attrs.xml文件，就是这样 2，开始编写我们需要的属性。\n1\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; 2\u0026lt;resources\u0026gt; 3 \u0026lt;declare-styleable name=\u0026#34;burce\u0026#34;\u0026gt; 4 \u0026lt;attr name=\u0026#34;mHeight\u0026#34; format=\u0026#34;integer\u0026#34;/\u0026gt; 5 \u0026lt;attr name=\u0026#34;mWidth\u0026#34; format=\u0026#34;integer\u0026#34;/\u0026gt; 6 \u0026lt;attr name=\u0026#34;mName\u0026#34; format=\u0026#34;string\u0026#34;/\u0026gt; 7 \u0026lt;attr name=\u0026#34;sex\u0026#34; format=\u0026#34;enum\u0026#34;\u0026gt; 8 \u0026lt;enum name=\u0026#34;man\u0026#34; value=\u0026#34;0\u0026#34;/\u0026gt; 9 \u0026lt;enum name=\u0026#34;woman\u0026#34; value=\u0026#34;1\u0026#34;/\u0026gt; 10 \u0026lt;/attr\u0026gt; 11 \u0026lt;attr name=\u0026#34;student\u0026#34; format=\u0026#34;boolean\u0026#34;/\u0026gt; 12 \u0026lt;/declare-styleable\u0026gt; 13\u0026lt;/resources\u0026gt; 说一下用到的东西 \u0026lt;declare-styleable name=\u0026quot;burce\u0026quot;\u0026gt;其中的name的值随便定义一个，不要与系统的起冲突。 \u0026lt;attr name=\u0026quot;mHeight\u0026quot; format=\u0026quot;integer\u0026quot;/\u0026gt;name就是自定义的属性的名字（比如系统控件的android:layout_width） format 就是属性的类型，这里支持10种类型，常用的有string，integer，boolean等等，这次我们用到了整形，枚举和布尔 注意：我们在自定义属性的名字的时候不能与系统的名字冲突，否则会报错\n3，新建一个类继承View类，实现3个构造方法，然后获取我们自定义的属性\n1public class MyView extends View { 2 private static final String TAG = \u0026#34;MyView\u0026#34;; 3 private int heiget; 4 private int width; 5 private String name; 6 private int sex; 7 private boolean student; 8 public MyView(Context context) { 9 this(context,null); 10 } 11 12 public MyView(Context context, AttributeSet attrs) { 13 this(context, attrs,0); 14 } 15 16 public MyView(Context context, AttributeSet attrs, int defStyleAttr) { 17 super(context, attrs, defStyleAttr); 18 TypedArray array=context.obtainStyledAttributes(attrs, R.styleable.burce); 19 heiget=array.getInt(R.styleable.burce_mHeight,0); 20 width=array.getInt(R.styleable.burce_mWidth,0); 21 name=array.getString(R.styleable.burce_mName); 22 sex=array.getInt(R.styleable.burce_sex,0); 23 student=array.getBoolean(R.styleable.burce_student,true); 24 array.recycle(); 25 26 Log.i(TAG, \u0026#34;height: \u0026#34;+heiget); 27 Log.i(TAG, \u0026#34;width: \u0026#34;+width); 28 Log.i(TAG, \u0026#34;name: \u0026#34;+name); 29 Log.i(TAG, \u0026#34;sex: \u0026#34;+sex); 30 Log.i(TAG, \u0026#34;student: \u0026#34;+student); 31 32 } 33} TypedArray array=context.obtainStyledAttributes(attrs, R.styleable.burce);\n这是Google官方给的解释，就简单说一下两个参数怎么填吧，第一个填形参的attrs，第二个填 R.styleable是固定写法，bruce是\u0026lt;declare-styleable name=\u0026quot;burce\u0026quot;\u0026gt;中的name的值。 4，回到MainActivity的布局文件中使用我们的自定义view\n1\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; 2\u0026lt;RelativeLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; 3 xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; 4 xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; 5 android:layout_width=\u0026#34;match_parent\u0026#34; 6 android:layout_height=\u0026#34;match_parent\u0026#34; 7 tools:context=\u0026#34;com.myviewtest.MainActivity\u0026#34;\u0026gt; 8 \u0026lt;com.myviewtest.MyView 9 android:layout_width=\u0026#34;match_parent\u0026#34; 10 android:layout_height=\u0026#34;match_parent\u0026#34; 11 app:mName=\u0026#34;bruce\u0026#34; 12 app:sex=\u0026#34;man\u0026#34; 13 app:mHeight=\u0026#34;100\u0026#34; 14 app:mWidth=\u0026#34;100\u0026#34; 15 app:student=\u0026#34;true\u0026#34;/\u0026gt; 16\u0026lt;/RelativeLayout\u0026gt; 注意：如果Android studio没有加上命名空间的话需要自己加上 xmlns:app=\u0026quot;http://schemas.android.com/apk/res-auto\u0026quot; 只有声明了命名空间才能使用自定义属性，不懂啥是命名空间的同学呢自己Google学习一下吧（最近在学C++，我就安C++中的命名空间理解的，如果不正确还请大神赐教） 这里的我们在这用了app命名空间，所有所有的自定义属性的开头都加上了“app:”。\n准备工作都做好了接下来我们吧应用跑起来看看吧，这里我们通过打印log查看自定义属性的值。\n通过log可以得知 我们在自定义view中成功的获取到了属性的值。好的老司机平安到站，小白有序下车。 由于你遇到了一个假的老司机，文章中如果有不正确的地方还请各位大神在评论区指正，老司机在这里抱拳了。\n","date":"2017-03-08T18:27:24Z","permalink":"https://lqxhub.github.io/posts/25a04712/","title":"自定义属性"},{"content":"本例是我在年前的项目中用到的一个小例子，使用Android自带的HttpURLConnection实现文件上传。网上的资料对这方面的讲解不太多，有两个实例也不太详细，我在开发中用到了，觉得挺实用的，分享出来，希望能对各位朋友有所帮助，受水平所限，实例中如有谬处，还望各位大神批评指正，这个实例个人认为适用于项目中的文件上传比较少的情况，当文件上传比较多的时候还是用框架吧（例如okhtp）。 本来想在刚放寒假就整理一下，由于年前回家比较晚了，年前年后的事有点多，直到现在才有时间整理。废话不多说 直接上代码：(代码是我从项目中剪出来的，可能会有报错，问题不会太大，很好改)\n1import android.os.Handler; 2import android.os.Message; 3import android.util.Log; 4import org.json.JSONException; 5import org.json.JSONObject; 6 7import java.io.BufferedReader; 8import java.io.DataOutputStream; 9import java.io.FileInputStream; 10import java.io.IOException; 11import java.io.InputStreamReader; 12import java.net.HttpURLConnection; 13import java.net.MalformedURLException; 14import java.net.URL; 15public class ArrivateUpload extends Thread { 16 17 private final String BOUNDARYSTR = \u0026#34;--------aifudao7816510d1hq\u0026#34;; 18 private final String END = \u0026#34;\\r\\n\u0026#34;; 19 private final String LAST = \u0026#34;--\u0026#34;; 20 21 private String data;//表单数据 22 private FileInputStream fis;//文件输入流 23 private Handler handler; 24 25 public ArrivateUpload(String data, FileInputStream fis, Handler handler) { 26 this.data = data; 27 this.handler = handler; 28 this.fis=fis; 29 } 30 31 @Override 32 public void run() { 33 try { 34 URL httpUrl=new URL(urlStr); 35 HttpURLConnection connection= (HttpURLConnection) httpUrl.openConnection(); 36 connection.setRequestMethod(\u0026#34;POST\u0026#34;);//必须为post 37 connection.setDoInput(true); 38 connection.setDoOutput(true); 39 connection.setRequestProperty(\u0026#34;Content-type\u0026#34;, \u0026#34;multipart/form-data;boundary=\u0026#34; + BOUNDARYSTR);//固定格式 40 DataOutputStream dos=new DataOutputStream(connection.getOutputStream()); 41 StringBuffer sb=new StringBuffer(); 42 /** 43 * 写入文本数据 44 */ 45 46 sb.append(LAST+BOUNDARYSTR+END); 47 sb.append(\u0026#34;Content-Disposition: form-data; name=\\\u0026#34;data\\\u0026#34;\u0026#34;+END+END); 48 sb.append(data+END);//内容 49 /** 50 * 循环写入文件 51 */ 52sb.append(LAST+BOUNDARYSTR+END); 53sb.append(\u0026#34;Content-Disposition:form-data;Content-Type:application/octet-stream;name=\\\u0026#34;file\\\u0026#34;;\u0026#34;); 54 sb.append(\u0026#34;filename=\\\u0026#34;\u0026#34;+\u0026#34;map_image.png\u0026#34;+\u0026#34;\\\u0026#34;\u0026#34;+END+END); 55 dos.write(sb.toString().getBytes(\u0026#34;utf-8\u0026#34;)); 56 if (fis != null) { 57 byte[] b=new byte[1024]; 58 int len; 59 while ((len=fis.read(b))!=-1){ 60 dos.write(b,0,len); 61 } 62 dos.write(END.getBytes()); 63 } 64 dos.write((LAST+BOUNDARYSTR+LAST+END).getBytes()); 65 dos.flush(); 66 sb=new StringBuffer(); 67 if (connection.getResponseCode()==200) {//请求成功 68 BufferedReader br=new BufferedReader(new InputStreamReader(connection.getInputStream())); 69 String line; 70 while ((line=br.readLine())!=null){ 71 sb.append(line); 72 } 73 Message msg=Message.obtain(); 74 JSONObject object=new JSONObject(sb.toString()); 75 handler.sendMessage(msg); 76 } 77 } catch (MalformedURLException e) { 78 e.printStackTrace(); 79 } catch (IOException e) { 80 e.printStackTrace(); 81 } catch (JSONException e) { 82 e.printStackTrace(); 83 } 84 } 85} 说一下实现思路：用Android系统中提供的HttpURLConnection，利用http中的multipart协议实现文件上传。httpUrlConnection应该不用多说了（不太熟悉的同学去Google学习一下HttpURLConnection和http协议吧），就说几个注意点吧，请求模式设置为POST，打开输入输出流（这个好像默认是开启的，还是设置为true比较放心） 重点说一下multipart协议吧，因为普通的http post协议使用的分隔符太简单，上传文件会造成文件分割歧义，所以必须使用multipart协议。 写一个简单的HTML表单文件上传的例子，对照学习。\n1\u0026lt;!DOCTYPE html\u0026gt; 2\u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; 3\u0026lt;head\u0026gt; 4 \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; 5 \u0026lt;title\u0026gt;upload\u0026lt;/title\u0026gt; 6\u0026lt;/head\u0026gt; 7\u0026lt;body\u0026gt; 8\u0026lt;form action=\u0026#34;a.php\u0026#34; method=\u0026#34;post\u0026#34; enctype=\u0026#34;multipart/form-data\u0026#34;\u0026gt; 9 \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;data\u0026#34;/\u0026gt; 10 \u0026lt;input type=\u0026#34;file\u0026#34; name=\u0026#34;file\u0026#34;\u0026gt; 11 \u0026lt;input type=\u0026#34;submit\u0026#34;\u0026gt; 12\u0026lt;/form\u0026gt; 13\u0026lt;/body\u0026gt; 14\u0026lt;/html\u0026gt; 在浏览器中通过调试我们可以对照浏览器来拼出multipart协议，浏览器会报404,a.php 没有找到，不用管它，这不是我们关注的重点。下图就是浏览器中的详细信息\n在1处定义了分隔符，分隔符尽量复杂一点，避免造成与文件中的字符产生冲突。注意了，前方有大坑，注意脚下油门，老司机一不留神也会翻车。仔细对比你会发现2,3,4处和1处是不同的，2,3,4处比1处多了两个“-”,一定要留神，这也就是为什么我们在使用boundary时要加上“\u0026ndash;”的原因了。sb.append(LAST+BOUNDARYSTR+END); 在4处，整个body的结束处要加上一个“\u0026ndash;”，没有why，协议就是这样规定的。\n每一行结束都要有一个\u0026quot;\\r\\n\u0026quot;，第二行结束时（数据文件开始前）要有两个\u0026quot;\\r\\n\u0026quot;。对比图中会发现数据文件前有一个空行。还有非常重要的一点，千万注意引号(“ ”)的转义问题，如果引号出问题就会导致上传失败，而且这个错误还不容易发现。文件写入需要用输入流循环写入\n1sb.append(\u0026#34;Content-Disposition:form-data;Content-Type:application/octet-stream;name=\\\u0026#34;file\\\u0026#34;;\u0026#34;); //name 之前是固定写法， 这里的name是服务端接收时需要用到的， 2sb.append(\u0026#34;filename=\\\u0026#34;\u0026#34;+\u0026#34;map_image.png\u0026#34;+\u0026#34;\\\u0026#34;\u0026#34;+END+END); // 这里的filename的值随便写，无所谓，但是一定要有，没有会导致上传失败。 3dos.write(sb.toString().getBytes(\u0026#34;utf-8\u0026#34;)); 4 if (fis != null) { 5 byte[] b=new byte[1024]; 6 int len; 7 while ((len=fis.read(b))!=-1){ 8 dos.write(b,0,len); 9 } 10 dos.write(END.getBytes()); 11 } 12 dos.write((LAST+BOUNDARYSTR+LAST+END).getBytes()); 13 dos.flush(); 再分享一个调试技巧，我们的程序是跑在Android上的，我们是无法像在浏览器中那样调试的，所以开抓包是非常必要的（genymation自带抓包器，熟悉linux的可以直接使用），在模拟器上运行程序，电脑开启抓包器，每次上传都抓取一个数据包，分析数据包，如果出错了与浏览器的格式对比，这样调试不要太酸爽。有次上传的内容有点复杂，一直调试不正确，最后用抓包对比搞定了。我用的是wireshark，这个功能太强大了，直接在网卡安装驱动，只要经过网卡的数据都能抓到（想象力丰富的同学可以用它来干点坏事情 此处略去一千字……）。还有一个地方需要注意一下，wireshark不能抓ip为127.0.0.1的数据包（用本地电脑做服务器），因为这时的数据不经过网卡，所以无法抓取。 由于水平有限，加之时间匆忙，如有谬处，还请各位大神批评指正\n","date":"2017-02-15T09:50:53Z","permalink":"https://lqxhub.github.io/posts/3c55041d/","title":"在Android中实现文件上传"}]